// cmd/qff-cli/main.go
package main

import (
	"context"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"net/url"
	"os"
	"os/exec"
	"strconv"
	"strings"
	"time"
)

const (
	Version         = "1.0.0"
	DefaultAPIBase  = "http://localhost:8080"
	ServiceName     = "qff"
	DefaultTimeout  = 30 * time.Second
	DefaultLogLines = 50
)

// CLI represents the command-line interface
type CLI struct {
	client *APIClient
	config *CLIConfig
}

// CLIConfig holds configuration for the CLI
type CLIConfig struct {
	APIBase string
	Timeout time.Duration
	Verbose bool
}

// APIClient handles HTTP communication with the QFF API
type APIClient struct {
	baseURL string
	client  *http.Client
}

// Command represents a CLI command
type Command struct {
	Name        string
	Description string
	Handler     func(*CLI, []string) error
	Subcommands map[string]*Command
}

func main() {
	config := &CLIConfig{
		APIBase: getEnvOrDefault("QFF_API_BASE", DefaultAPIBase),
		Timeout: DefaultTimeout,
		Verbose: os.Getenv("QFF_VERBOSE") == "1",
	}

	cli := &CLI{
		client: NewAPIClient(config.APIBase, config.Timeout),
		config: config,
	}

	if err := cli.Run(os.Args[1:]); err != nil {
		fmt.Fprintf(os.Stderr, "Error: %v\n", err)
		os.Exit(1)
	}
}

func NewAPIClient(baseURL string, timeout time.Duration) *APIClient {
	return &APIClient{
		baseURL: strings.TrimRight(baseURL, "/"),
		client: &http.Client{
			Timeout: timeout,
		},
	}
}

func (cli *CLI) Run(args []string) error {
	if len(args) == 0 {
		return cli.showUsage()
	}

	commands := cli.getCommands()

	command := args[0]
	cmd, exists := commands[command]
	if !exists {
		return fmt.Errorf("unknown command: %s", command)
	}

	return cmd.Handler(cli, args[1:])
}

func (cli *CLI) getCommands() map[string]*Command {
	return map[string]*Command{
		"status": {
			Name:        "status",
			Description: "Show firewall status",
			Handler:     (*CLI).handleStatus,
		},
		"metrics": {
			Name:        "metrics",
			Description: "Show system metrics",
			Handler:     (*CLI).handleMetrics,
		},
		"logs": {
			Name:        "logs",
			Description: "Show recent logs",
			Handler:     (*CLI).handleLogs,
		},
		"reload": {
			Name:        "reload",
			Description: "Reload configuration",
			Handler:     (*CLI).handleReload,
		},
		"enable": {
			Name:        "enable",
			Description: "Enable and start service",
			Handler:     (*CLI).handleEnable,
		},
		"disable": {
			Name:        "disable",
			Description: "Stop and disable service",
			Handler:     (*CLI).handleDisable,
		},
		"whitelist": {
			Name:        "whitelist",
			Description: "Manage IP whitelist",
			Handler:     (*CLI).handleWhitelist,
		},
		"blacklist": {
			Name:        "blacklist",
			Description: "Manage IP blacklist",
			Handler:     (*CLI).handleBlacklist,
		},
		"ips": {
			Name:        "ips",
			Description: "IPS management commands",
			Handler:     (*CLI).handleIPS,
		},
		"ports": {
			Name:        "ports",
			Description: "Port management commands",
			Handler:     (*CLI).handlePorts,
		},
		"version": {
			Name:        "version",
			Description: "Show version information",
			Handler:     (*CLI).handleVersion,
		},
	}
}

func (cli *CLI) showUsage() error {
	fmt.Println("QFF CLI - qFibre Firewall Manager")
	fmt.Printf("Version: %s\n\n", Version)
	fmt.Println("Usage: qff-cli <command> [options]")
	fmt.Println("\nCommands:")

	commands := cli.getCommands()
	for _, cmd := range commands {
		fmt.Printf("  %-12s %s\n", cmd.Name, cmd.Description)
	}

	fmt.Println("\nEnvironment Variables:")
	fmt.Println("  QFF_API_BASE    API base URL (default: http://localhost:8080)")
	fmt.Println("  QFF_VERBOSE     Enable verbose output (set to '1')")
	fmt.Println("\nExamples:")
	fmt.Println("  qff-cli status")
	fmt.Println("  qff-cli ips status")
	fmt.Println("  qff-cli whitelist add 192.168.1.100")
	fmt.Println("  qff-cli ports add 8080 tcp in allow")

	return nil
}

// API Client methods
func (ac *APIClient) makeRequest(ctx context.Context, method, endpoint string, body io.Reader) ([]byte, error) {
	url := ac.baseURL + endpoint

	req, err := http.NewRequestWithContext(ctx, method, url, body)
	if err != nil {
		return nil, fmt.Errorf("creating request: %w", err)
	}

	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("User-Agent", fmt.Sprintf("qff-cli/%s", Version))

	resp, err := ac.client.Do(req)
	if err != nil {
		return nil, fmt.Errorf("making request: %w", err)
	}
	defer resp.Body.Close()

	data, err := io.ReadAll(resp.Body)
	if err != nil {
		return nil, fmt.Errorf("reading response: %w", err)
	}

	if resp.StatusCode >= 400 {
		return nil, fmt.Errorf("API error %d: %s", resp.StatusCode, string(data))
	}

	return data, nil
}

func (ac *APIClient) Get(ctx context.Context, endpoint string) ([]byte, error) {
	return ac.makeRequest(ctx, "GET", endpoint, nil)
}

func (ac *APIClient) Post(ctx context.Context, endpoint string, body io.Reader) ([]byte, error) {
	return ac.makeRequest(ctx, "POST", endpoint, body)
}

func (ac *APIClient) Delete(ctx context.Context, endpoint string) ([]byte, error) {
	return ac.makeRequest(ctx, "DELETE", endpoint, nil)
}

// Command handlers
func (cli *CLI) handleStatus(args []string) error {
	ctx, cancel := context.WithTimeout(context.Background(), cli.config.Timeout)
	defer cancel()

	data, err := cli.client.Get(ctx, "/status")
	if err != nil {
		return err
	}

	var status StatusResponse
	if err := json.Unmarshal(data, &status); err != nil {
		return fmt.Errorf("parsing status response: %w", err)
	}

	cli.printStatus(&status)
	return nil
}

func (cli *CLI) handleMetrics(args []string) error {
	ctx, cancel := context.WithTimeout(context.Background(), cli.config.Timeout)
	defer cancel()

	data, err := cli.client.Get(ctx, "/metrics")
	if err != nil {
		return err
	}

	var metrics MetricsResponse
	if err := json.Unmarshal(data, &metrics); err != nil {
		return fmt.Errorf("parsing metrics response: %w", err)
	}

	cli.printMetrics(&metrics)
	return nil
}

func (cli *CLI) handleLogs(args []string) error {
	lines := DefaultLogLines
	if len(args) > 0 {
		if l, err := strconv.Atoi(args[0]); err == nil && l > 0 {
			lines = l
		}
	}

	ctx, cancel := context.WithTimeout(context.Background(), cli.config.Timeout)
	defer cancel()

	cmd := exec.CommandContext(ctx, "journalctl", "-u", ServiceName, "-n", strconv.Itoa(lines), "--no-pager")
	output, err := cmd.Output()
	if err != nil {
		return fmt.Errorf("getting logs: %w", err)
	}

	fmt.Print(string(output))
	return nil
}

func (cli *CLI) handleReload(args []string) error {
	ctx, cancel := context.WithTimeout(context.Background(), cli.config.Timeout)
	defer cancel()

	_, err := cli.client.Post(ctx, "/reload", nil)
	if err != nil {
		return err
	}

	fmt.Println("Configuration reloaded successfully")
	return nil
}

func (cli *CLI) handleEnable(args []string) error {
	ctx, cancel := context.WithTimeout(context.Background(), cli.config.Timeout)
	defer cancel()

	cmd := exec.CommandContext(ctx, "systemctl", "enable", "--now", ServiceName)
	if err := cmd.Run(); err != nil {
		return fmt.Errorf("enabling service: %w", err)
	}

	fmt.Println("QFF service enabled and started")
	return nil
}

func (cli *CLI) handleDisable(args []string) error {
	ctx, cancel := context.WithTimeout(context.Background(), cli.config.Timeout)
	defer cancel()

	cmd := exec.CommandContext(ctx, "systemctl", "disable", "--now", ServiceName)
	if err := cmd.Run(); err != nil {
		return fmt.Errorf("disabling service: %w", err)
	}

	fmt.Println("QFF service disabled and stopped")
	return nil
}

func (cli *CLI) handleVersion(args []string) error {
	fmt.Printf("qff-cli v%s\n", Version)
	return nil
}

func (cli *CLI) handleWhitelist(args []string) error {
	return cli.handleIPList("whitelist", args)
}

func (cli *CLI) handleBlacklist(args []string) error {
	return cli.handleIPList("blacklist", args)
}

func (cli *CLI) handleIPList(listType string, args []string) error {
	if len(args) < 2 {
		return fmt.Errorf("usage: qff-cli %s <add|remove|list> <ip>", listType)
	}

	action := args[0]

	switch action {
	case "list":
		return cli.listIPs(listType)
	case "add":
		if len(args) < 2 {
			return fmt.Errorf("usage: qff-cli %s add <ip>", listType)
		}
		return cli.addIPToList(listType, args[1])
	case "remove":
		if len(args) < 2 {
			return fmt.Errorf("usage: qff-cli %s remove <ip>", listType)
		}
		return cli.removeIPFromList(listType, args[1])
	default:
		return fmt.Errorf("invalid action: %s", action)
	}
}

func (cli *CLI) addIPToList(listType, ip string) error {
	if err := validateIP(ip); err != nil {
		return err
	}

	ctx, cancel := context.WithTimeout(context.Background(), cli.config.Timeout)
	defer cancel()

	endpoint := fmt.Sprintf("/%s?ip=%s", listType, url.QueryEscape(ip))
	_, err := cli.client.Post(ctx, endpoint, nil)
	if err != nil {
		return err
	}

	fmt.Printf("Successfully added %s to %s\n", ip, listType)
	return nil
}

func (cli *CLI) removeIPFromList(listType, ip string) error {
	if err := validateIP(ip); err != nil {
		return err
	}

	ctx, cancel := context.WithTimeout(context.Background(), cli.config.Timeout)
	defer cancel()

	endpoint := fmt.Sprintf("/%s?ip=%s", listType, url.QueryEscape(ip))
	_, err := cli.client.Delete(ctx, endpoint)
	if err != nil {
		return err
	}

	fmt.Printf("Successfully removed %s from %s\n", ip, listType)
	return nil
}

func (cli *CLI) listIPs(listType string) error {
	ctx, cancel := context.WithTimeout(context.Background(), cli.config.Timeout)
	defer cancel()

	endpoint := fmt.Sprintf("/api/%s", listType)
	data, err := cli.client.Get(ctx, endpoint)
	if err != nil {
		return err
	}

	var result map[string]interface{}
	if err := json.Unmarshal(data, &result); err != nil {
		return fmt.Errorf("parsing response: %w", err)
	}

	cli.printIPList(listType, result)
	return nil
}

// IPS command handlers
func (cli *CLI) handleIPS(args []string) error {
	if len(args) == 0 {
		return cli.showIPSUsage()
	}

	ipsCommands := map[string]func([]string) error{
		"status":           cli.handleIPSStatus,
		"blocked":          cli.handleIPSBlocked,
		"whitelist":        cli.handleIPSWhitelist,
		"unblock":          cli.handleIPSUnblock,
		"whitelist-add":    cli.handleIPSWhitelistAdd,
		"whitelist-remove": cli.handleIPSWhitelistRemove,
		"geoip-check":      cli.handleGeoIPCheck,
		"vpn-check":        cli.handleVPNCheck,
		"service-rules":    cli.handleServiceRules,
	}

	subcommand := args[0]
	handler, exists := ipsCommands[subcommand]
	if !exists {
		return fmt.Errorf("unknown IPS command: %s", subcommand)
	}

	return handler(args[1:])
}

func (cli *CLI) showIPSUsage() error {
	fmt.Println("IPS Commands:")
	fmt.Println("  ips status                          Show IPS status and statistics")
	fmt.Println("  ips blocked                         List all blocked IPs")
	fmt.Println("  ips whitelist                       List all whitelisted IPs")
	fmt.Println("  ips unblock <ip>                    Unblock an IP address")
	fmt.Println("  ips whitelist-add <ip> [reason]     Add IP to whitelist permanently")
	fmt.Println("  ips whitelist-remove <ip>           Remove IP from whitelist")
	fmt.Println("  ips geoip-check <ip> [service]      Check GeoIP status for IP and service")
	fmt.Println("  ips vpn-check <ip>                  Check if IP is VPN/Proxy")
	fmt.Println("  ips service-rules                   Show configured service rules")
	return nil
}

func (cli *CLI) handleIPSStatus(args []string) error {
	ctx, cancel := context.WithTimeout(context.Background(), cli.config.Timeout)
	defer cancel()

	data, err := cli.client.Get(ctx, "/api/ips/stats")
	if err != nil {
		return err
	}

	var stats map[string]interface{}
	if err := json.Unmarshal(data, &stats); err != nil {
		return fmt.Errorf("parsing stats response: %w", err)
	}

	fmt.Println("IPS Status:")
	cli.printKeyValue(stats, "  ")
	return nil
}

func (cli *CLI) handleIPSBlocked(args []string) error {
	ctx, cancel := context.WithTimeout(context.Background(), cli.config.Timeout)
	defer cancel()

	data, err := cli.client.Get(ctx, "/api/ips/blocked")
	if err != nil {
		return err
	}

	var result BlockedIPsResponse
	if err := json.Unmarshal(data, &result); err != nil {
		return fmt.Errorf("parsing blocked IPs response: %w", err)
	}

	cli.printBlockedIPs(&result)
	return nil
}

func (cli *CLI) handleIPSWhitelist(args []string) error {
	ctx, cancel := context.WithTimeout(context.Background(), cli.config.Timeout)
	defer cancel()

	data, err := cli.client.Get(ctx, "/api/ips/whitelist")
	if err != nil {
		return err
	}

	var result WhitelistResponse
	if err := json.Unmarshal(data, &result); err != nil {
		return fmt.Errorf("parsing whitelist response: %w", err)
	}

	cli.printWhitelist(&result)
	return nil
}

func (cli *CLI) handleIPSUnblock(args []string) error {
	if len(args) == 0 {
		return fmt.Errorf("usage: qff-cli ips unblock <ip>")
	}

	ip := args[0]
	if err := validateIP(ip); err != nil {
		return err
	}

	ctx, cancel := context.WithTimeout(context.Background(), cli.config.Timeout)
	defer cancel()

	endpoint := fmt.Sprintf("/api/ips/unblock?ip=%s", url.QueryEscape(ip))
	_, err := cli.client.Post(ctx, endpoint, nil)
	if err != nil {
		return err
	}

	fmt.Printf("Successfully unblocked IP: %s\n", ip)
	return nil
}

func (cli *CLI) handleIPSWhitelistAdd(args []string) error {
	if len(args) == 0 {
		return fmt.Errorf("usage: qff-cli ips whitelist-add <ip> [reason]")
	}

	ip := args[0]
	if err := validateIP(ip); err != nil {
		return err
	}

	reason := "Manual CLI whitelist"
	if len(args) > 1 {
		reason = strings.Join(args[1:], " ")
	}

	ctx, cancel := context.WithTimeout(context.Background(), cli.config.Timeout)
	defer cancel()

	endpoint := fmt.Sprintf("/api/ips/whitelist/add?ip=%s&permanent=true&reason=%s",
		url.QueryEscape(ip), url.QueryEscape(reason))

	_, err := cli.client.Post(ctx, endpoint, nil)
	if err != nil {
		return err
	}

	fmt.Printf("Successfully whitelisted IP: %s\n", ip)
	return nil
}

func (cli *CLI) handleIPSWhitelistRemove(args []string) error {
	if len(args) == 0 {
		return fmt.Errorf("usage: qff-cli ips whitelist-remove <ip>")
	}

	ip := args[0]
	if err := validateIP(ip); err != nil {
		return err
	}

	ctx, cancel := context.WithTimeout(context.Background(), cli.config.Timeout)
	defer cancel()

	endpoint := fmt.Sprintf("/api/ips/whitelist/remove?ip=%s", url.QueryEscape(ip))
	_, err := cli.client.Delete(ctx, endpoint)
	if err != nil {
		return err
	}

	fmt.Printf("Successfully removed IP from whitelist: %s\n", ip)
	return nil
}

func (cli *CLI) handleGeoIPCheck(args []string) error {
	if len(args) == 0 {
		return fmt.Errorf("usage: qff-cli ips geoip-check <ip> [service]")
	}

	ip := args[0]
	if err := validateIP(ip); err != nil {
		return err
	}

	service := "web"
	if len(args) > 1 {
		service = args[1]
	}

	ctx, cancel := context.WithTimeout(context.Background(), cli.config.Timeout)
	defer cancel()

	endpoint := fmt.Sprintf("/api/geoip/check?ip=%s&service=%s",
		url.QueryEscape(ip), url.QueryEscape(service))

	data, err := cli.client.Get(ctx, endpoint)
	if err != nil {
		return err
	}

	var result map[string]interface{}
	if err := json.Unmarshal(data, &result); err != nil {
		return fmt.Errorf("parsing GeoIP response: %w", err)
	}

	fmt.Printf("GeoIP Check for %s (service: %s):\n", ip, service)
	cli.printKeyValue(result, "  ")
	return nil
}

func (cli *CLI) handleVPNCheck(args []string) error {
	if len(args) == 0 {
		return fmt.Errorf("usage: qff-cli ips vpn-check <ip>")
	}

	ip := args[0]
	if err := validateIP(ip); err != nil {
		return err
	}

	ctx, cancel := context.WithTimeout(context.Background(), cli.config.Timeout)
	defer cancel()

	endpoint := fmt.Sprintf("/api/geoip/vpn-check?ip=%s", url.QueryEscape(ip))
	data, err := cli.client.Get(ctx, endpoint)
	if err != nil {
		return err
	}

	var result map[string]interface{}
	if err := json.Unmarshal(data, &result); err != nil {
		return fmt.Errorf("parsing VPN check response: %w", err)
	}

	fmt.Printf("VPN/Proxy Check for %s:\n", ip)
	cli.printKeyValue(result, "  ")
	return nil
}

func (cli *CLI) handleServiceRules(args []string) error {
	ctx, cancel := context.WithTimeout(context.Background(), cli.config.Timeout)
	defer cancel()

	data, err := cli.client.Get(ctx, "/api/geoip/service-rules")
	if err != nil {
		return err
	}

	var result map[string]interface{}
	if err := json.Unmarshal(data, &result); err != nil {
		return fmt.Errorf("parsing service rules response: %w", err)
	}

	fmt.Println("Service Rules:")
	cli.printKeyValue(result, "  ")
	return nil
}

// Ports command handlers
func (cli *CLI) handlePorts(args []string) error {
	if len(args) == 0 {
		return cli.showPortsUsage()
	}

	portsCommands := map[string]func([]string) error{
		"list":   cli.handlePortsList,
		"add":    cli.handlePortsAdd,
		"remove": cli.handlePortsRemove,
	}

	subcommand := args[0]
	handler, exists := portsCommands[subcommand]
	if !exists {
		return fmt.Errorf("unknown ports command: %s", subcommand)
	}

	return handler(args[1:])
}

func (cli *CLI) showPortsUsage() error {
	fmt.Println("Port Management Commands:")
	fmt.Println("  ports list                                    List all configured port rules")
	fmt.Println("  ports add <port> <tcp|udp> <in|out> [action]  Add port rule")
	fmt.Println("  ports remove <port> <tcp|udp> <in|out>        Remove port rule")
	fmt.Println("\nExamples:")
	fmt.Println("  qff-cli ports add 8080 tcp in allow")
	fmt.Println("  qff-cli ports add 53 udp out allow")
	fmt.Println("  qff-cli ports add 23 tcp in deny")
	fmt.Println("  qff-cli ports remove 8080 tcp in")
	return nil
}

func (cli *CLI) handlePortsList(args []string) error {
	ctx, cancel := context.WithTimeout(context.Background(), cli.config.Timeout)
	defer cancel()

	data, err := cli.client.Get(ctx, "/api/ports/list")
	if err != nil {
		return err
	}

	var result PortRulesResponse
	if err := json.Unmarshal(data, &result); err != nil {
		return fmt.Errorf("parsing port rules response: %w", err)
	}

	cli.printPortRules(&result)
	return nil
}

func (cli *CLI) handlePortsAdd(args []string) error {
	if len(args) < 3 {
		return fmt.Errorf("usage: qff-cli ports add <port> <tcp|udp> <in|out> [action]")
	}

	port := args[0]
	protocol := args[1]
	direction := args[2]
	action := "allow"

	if len(args) > 3 {
		action = args[3]
	}

	if err := validatePortRule(port, protocol, direction, action); err != nil {
		return err
	}

	ctx, cancel := context.WithTimeout(context.Background(), cli.config.Timeout)
	defer cancel()

	endpoint := fmt.Sprintf("/api/ports/add?port=%s&protocol=%s&direction=%s&action=%s",
		url.QueryEscape(port), protocol, direction, action)

	_, err := cli.client.Post(ctx, endpoint, nil)
	if err != nil {
		return err
	}

	fmt.Printf("Successfully added port rule: %s/%s %s %s\n", port, protocol, direction, action)
	return nil
}

func (cli *CLI) handlePortsRemove(args []string) error {
	if len(args) < 3 {
		return fmt.Errorf("usage: qff-cli ports remove <port> <tcp|udp> <in|out>")
	}

	port := args[0]
	protocol := args[1]
	direction := args[2]

	if err := validatePortRule(port, protocol, direction, ""); err != nil {
		return err
	}

	ctx, cancel := context.WithTimeout(context.Background(), cli.config.Timeout)
	defer cancel()

	endpoint := fmt.Sprintf("/api/ports/remove?port=%s&protocol=%s&direction=%s",
		url.QueryEscape(port), protocol, direction)

	_, err := cli.client.Delete(ctx, endpoint)
	if err != nil {
		return err
	}

	fmt.Printf("Successfully removed port rule: %s/%s %s\n", port, protocol, direction)
	return nil
}

// Utility functions and types
func validateIP(ip string) error {
	if ip == "" {
		return fmt.Errorf("IP address cannot be empty")
	}
	// Add more sophisticated IP validation here if needed
	return nil
}

func validatePortRule(port, protocol, direction, action string) error {
	if port == "" {
		return fmt.Errorf("port cannot be empty")
	}

	if portNum, err := strconv.Atoi(port); err != nil || portNum < 1 || portNum > 65535 {
		return fmt.Errorf("invalid port number: %s", port)
	}

	if protocol != "tcp" && protocol != "udp" {
		return fmt.Errorf("protocol must be 'tcp' or 'udp'")
	}

	if direction != "in" && direction != "out" {
		return fmt.Errorf("direction must be 'in' or 'out'")
	}

	if action != "" && action != "allow" && action != "deny" {
		return fmt.Errorf("action must be 'allow' or 'deny'")
	}

	return nil
}

func getEnvOrDefault(key, defaultValue string) string {
	if value := os.Getenv(key); value != "" {
		return value
	}
	return defaultValue
}

// Response types
type StatusResponse struct {
	Status           string `json:"status"`
	Version          string `json:"version"`
	Uptime           string `json:"uptime"`
	GeoIPAvailable   bool   `json:"geoip_available"`
	TemporaryEntries int    `json:"temporary_entries"`
}

type MetricsResponse struct {
	SystemMetrics   map[string]float64     `json:"system_metrics"`
	FirewallMetrics map[string]interface{} `json:"firewall_metrics"`
}

type BlockedIPsResponse struct {
	BlockedIPs map[string]BlockedIPDetail `json:"blocked_ips"`
}

type BlockedIPDetail struct {
	Reason    string `json:"reason"`
	Service   string `json:"service"`
	BlockTime string `json:"block_time"`
}

type WhitelistResponse struct {
	WhitelistedIPs map[string]WhitelistDetail `json:"whitelisted_ips"`
}

type WhitelistDetail struct {
	Reason    string `json:"reason"`
	Permanent bool   `json:"permanent"`
	AddedTime string `json:"added_time"`
}

type PortRulesResponse struct {
	PortRules map[string]interface{} `json:"port_rules"`
}

// Print functions
func (cli *CLI) printStatus(status *StatusResponse) {
	fmt.Printf("Status: %s\n", status.Status)
	fmt.Printf("Version: %s\n", status.Version)
	fmt.Printf("Uptime: %s\n", status.Uptime)
	fmt.Printf("GeoIP Available: %t\n", status.GeoIPAvailable)
	fmt.Printf("Temporary Entries: %d\n", status.TemporaryEntries)
}

func (cli *CLI) printMetrics(metrics *MetricsResponse) {
	fmt.Println("System Metrics:")
	for key, value := range metrics.SystemMetrics {
		fmt.Printf("  %s: %.2f\n", key, value)
	}

	fmt.Println("Firewall Metrics:")
	cli.printKeyValue(metrics.FirewallMetrics, "  ")
}

func (cli *CLI) printBlockedIPs(response *BlockedIPsResponse) {
	fmt.Printf("Blocked IPs (%d):\n", len(response.BlockedIPs))
	for ip, details := range response.BlockedIPs {
		fmt.Printf("  %s: %s (%s) - %s\n", ip, details.Reason, details.Service, details.BlockTime)
	}
}

func (cli *CLI) printWhitelist(response *WhitelistResponse) {
	fmt.Printf("Whitelisted IPs (%d):\n", len(response.WhitelistedIPs))
	for ip, details := range response.WhitelistedIPs {
		permanent := "temporary"
		if details.Permanent {
			permanent = "permanent"
		}
		fmt.Printf("  %s: %s (%s) - %s\n", ip, details.Reason, permanent, details.AddedTime)
	}
}

func (cli *CLI) printPortRules(response *PortRulesResponse) {
	fmt.Println("Current Port Rules:")
	cli.printKeyValue(response.PortRules, "  ")
}

func (cli *CLI) printIPList(listType string, result map[string]interface{}) {
	fmt.Printf("%s entries:\n", strings.Title(listType))
	cli.printKeyValue(result, "  ")
}

func (cli *CLI) printKeyValue(data map[string]interface{}, indent string) {
	for key, value := range data {
		switch v := value.(type) {
		case map[string]interface{}:
			fmt.Printf("%s%s:\n", indent, key)
			cli.printKeyValue(v, indent+"  ")
		case []interface{}:
			fmt.Printf("%s%s: [%d items]\n", indent, key, len(v))
			for i, item := range v {
				fmt.Printf("%s  [%d]: %v\n", indent, i, item)
			}
		case float64:
			fmt.Printf("%s%s: %.2f\n", indent, key, v)
		default:
			fmt.Printf("%s%s: %v\n", indent, key, v)
		}
	}
}
// cmd/qff/main.go
package main

import (
	"context"
	"flag"
	"fmt"
	"net"
	"os"
	"os/signal"
	"runtime"
	"sync"
	"syscall"
	"time"

	"qff/internal/api"
	"qff/internal/config"
	"qff/internal/firewall"
	"qff/internal/geoip"
	"qff/internal/ips"
	"qff/internal/logger"
	"qff/internal/monitor"
	"qff/internal/notify"
)

const (
	Version                 = "1.0.0"
	DefaultConfigPath       = "/etc/qff/qff.conf"
	DefaultAPIPort          = ":8080"
	ShutdownTimeout         = 30 * time.Second
	ConnectivityTestTimeout = 3 * time.Second
)

// App encapsulates the entire application state
type App struct {
	cfg    *config.Config
	ctx    context.Context
	cancel context.CancelFunc

	// Core components
	notifier      *notify.Notifier
	geoipMgr      *geoip.GeoIPManager
	enhancedGeoIP *geoip.EnhancedGeoIPManager
	firewallMgr   *firewall.NFTManager
	ipsManager    *ips.IPSManager
	systemMonitor *monitor.SystemMonitor
	apiServer     *api.APIServer

	// Synchronization
	wg           sync.WaitGroup
	shutdownOnce sync.Once
}

func main() {
	// Parse command line flags
	flags := parseFlags()

	if flags.version {
		fmt.Printf("QFF - qFibre Firewall Manager v%s\n", Version)
		os.Exit(0)
	}

	// Create application context
	ctx, cancel := context.WithCancel(context.Background())
	defer cancel()

	app := &App{
		ctx:    ctx,
		cancel: cancel,
	}

	// Initialize and run application
	if err := app.initialize(flags); err != nil {
		logger.Error("main", "Failed to initialize application", "error", err.Error())
		os.Exit(1)
	}

	// Handle test mode if enabled
	if flags.testMode || app.cfg.TestMode.EnableTestMode {
		if err := app.runTestMode(); err != nil {
			logger.Error("main", "Test mode failed", "error", err.Error())
			os.Exit(1)
		}
	}

	// Start all services concurrently
	if err := app.start(); err != nil {
		logger.Error("main", "Failed to start services", "error", err.Error())
		os.Exit(1)
	}

	logger.Info("main", "QFF started successfully", "version", Version, "pid", os.Getpid())

	// Wait for shutdown signal
	app.waitForShutdown()

	// Graceful shutdown
	app.shutdown()
	logger.Info("main", "QFF shutdown completed")
}

type flags struct {
	configPath string
	version    bool
	testMode   bool
}

func parseFlags() *flags {
	var f flags
	flag.StringVar(&f.configPath, "config", DefaultConfigPath, "Configuration file path")
	flag.BoolVar(&f.version, "version", false, "Show version information")
	flag.BoolVar(&f.testMode, "test", false, "Run in test mode")
	flag.Parse()
	return &f
}

func (app *App) initialize(flags *flags) error {
	// Pre-flight checks
	if err := preFlightChecks(); err != nil {
		return fmt.Errorf("pre-flight checks failed: %w", err)
	}

	// Load and validate configuration
	cfg, err := config.LoadConfig(flags.configPath)
	if err != nil {
		return fmt.Errorf("failed to load config from %s: %w", flags.configPath, err)
	}

	if err := config.ValidateConfig(cfg); err != nil {
		return fmt.Errorf("configuration validation failed: %w", err)
	}

	app.cfg = cfg
	logger.Info("main", "Configuration loaded and validated", "config_path", flags.configPath)

	// Initialize components in dependency order
	if err := app.initializeComponents(); err != nil {
		return fmt.Errorf("component initialization failed: %w", err)
	}

	return nil
}

func preFlightChecks() error {
	// Check system requirements
	if runtime.GOOS != "linux" {
		return fmt.Errorf("QFF requires Linux operating system")
	}

	// Check nftables availability
	if err := firewall.CheckNFTablesAvailable(); err != nil {
		return fmt.Errorf("nftables check failed: %w", err)
	}

	// Check required permissions
	if os.Geteuid() != 0 {
		return fmt.Errorf("QFF requires root privileges")
	}

	return nil
}

func (app *App) initializeComponents() error {
	// Initialize notifier (no dependencies)
	app.notifier = notify.NewNotifier(&app.cfg.Notification)

	// Initialize GeoIP manager
	app.geoipMgr = geoip.NewGeoIPManager(&app.cfg.GeoIP)
	if err := app.geoipMgr.Initialize(); err != nil {
		logger.Warn("main", "GeoIP initialization failed", "error", err.Error())
		// Continue without GeoIP - not critical for basic firewall functionality
	} else {
		// Enable auto-download if API key is provided
		if app.cfg.GeoIP.MaxMindAPIKey != "" {
			app.geoipMgr.EnableAutoDownload(app.cfg.GeoIP.MaxMindAPIKey)
		}

		// Initialize enhanced GeoIP
		app.enhancedGeoIP = geoip.NewEnhancedGeoIPManager(app.geoipMgr, &app.cfg.GeoIP)
		if err := app.enhancedGeoIP.Initialize(); err != nil {
			logger.Warn("main", "Enhanced GeoIP initialization failed", "error", err.Error())
		}
	}

	// Initialize firewall manager (critical component)
	app.firewallMgr = firewall.NewNFTManager(app.cfg)
	if err := app.firewallMgr.Initialize(); err != nil {
		return fmt.Errorf("firewall initialization failed: %w", err)
	}

	// Auto-whitelist current user to prevent lockout
	if err := app.firewallMgr.WhitelistCurrentUser(); err != nil {
		logger.Warn("main", "Failed to auto-whitelist current user", "error", err.Error())
		// Continue - this is a safety feature, not critical
	}

	// Initialize IPS manager
	app.ipsManager = ips.NewIPSManager(&app.cfg.IPS, app.firewallMgr, app.notifier, app.enhancedGeoIP)

	// Initialize system monitor
	systemMonitor, err := monitor.NewSystemMonitor(&app.cfg.Monitor, app.notifier)
	if err != nil {
		logger.Error("main", "Failed to initialize system monitor", "error", err)
		return fmt.Errorf("system monitor initialization failed: %w", err)
	}
	app.systemMonitor = systemMonitor

	// Initialize API server
	app.apiServer = api.NewAPIServer(app.cfg, app.firewallMgr, app.systemMonitor, app.ipsManager)

	logger.Info("main", "All components initialized successfully")
	return nil
}

func (app *App) start() error {
	// Start IPS manager
	if app.ipsManager != nil {
		if err := app.ipsManager.Start(); err != nil {
			logger.Error("main", "Failed to start IPS manager", "error", err.Error())
			// Continue without IPS - firewall can still function
		}
	}

	// Start system monitor
	if app.systemMonitor != nil {
		app.systemMonitor.Start()
	}

	// Start API server in a separate goroutine
	app.wg.Add(1)
	go func() {
		defer app.wg.Done()

		// Listen for context cancellation
		go func() {
			<-app.ctx.Done()
			logger.Info("api", "Context cancelled, API server should shutdown")
		}()

		// Start the server - this will block until shutdown
		if err := app.apiServer.Start(DefaultAPIPort); err != nil {
			logger.Error("main", "API server failed", "error", err.Error())
			app.cancel() // Trigger shutdown if API server fails
		}
	}()

	return nil
}

func (app *App) waitForShutdown() {
	// Create signal channel
	sigCh := make(chan os.Signal, 1)
	signal.Notify(sigCh, syscall.SIGINT, syscall.SIGTERM, syscall.SIGHUP)

	select {
	case sig := <-sigCh:
		logger.Info("main", "Received shutdown signal", "signal", sig.String())
	case <-app.ctx.Done():
		logger.Info("main", "Context cancelled, initiating shutdown")
	}
}

func (app *App) shutdown() {
	app.shutdownOnce.Do(func() {
		logger.Info("main", "Starting graceful shutdown")

		// Cancel context to stop all operations
		app.cancel()

		// Create shutdown timeout
		shutdownCtx, cancel := context.WithTimeout(context.Background(), ShutdownTimeout)
		defer cancel()

		// Shutdown components in reverse dependency order
		done := make(chan struct{})
		go func() {
			defer close(done)
			app.shutdownComponents()
			app.wg.Wait()
		}()

		select {
		case <-done:
			logger.Info("main", "Graceful shutdown completed")
		case <-shutdownCtx.Done():
			logger.Warn("main", "Shutdown timeout exceeded, forcing exit")
		}
	})
}

func (app *App) shutdownComponents() {
	// Stop API server first to prevent new requests
	if app.apiServer != nil {
		// If APIServer doesn't have a Stop method, we'll use context cancellation
		// The server should be listening for app.ctx.Done()
		logger.Info("shutdown", "Stopping API server")
	}

	// Stop monitoring and detection services
	if app.systemMonitor != nil {
		app.systemMonitor.Stop()
	}

	if app.ipsManager != nil {
		app.ipsManager.Stop()
	}

	// Close GeoIP resources
	if app.enhancedGeoIP != nil {
		app.enhancedGeoIP.Stop()
	}

	if app.geoipMgr != nil {
		app.geoipMgr.Close()
	}

	// Firewall manager cleanup happens automatically via defer in main
}

func (app *App) runTestMode() error {
	if !app.cfg.TestMode.EnableTestMode {
		return nil
	}

	logger.Info("testmode", "Starting test mode", "duration", app.cfg.TestMode.TestDuration)

	// Backup current firewall state
	originalState, err := app.firewallMgr.BackupCurrentState()
	if err != nil {
		return fmt.Errorf("failed to backup firewall state: %w", err)
	}

	// Run connectivity tests
	testResults := app.runConnectivityTests(app.cfg.TestMode.TestConnections)

	// Log test results
	for host, success := range testResults {
		logger.Info("testmode", "Initial connectivity test", "host", host, "success", success)
	}

	// Setup auto-revert if enabled
	if app.cfg.TestMode.RevertOnFailure {
		time.AfterFunc(app.cfg.TestMode.TestDuration, func() {
			logger.Info("testmode", "Test mode timeout, checking connectivity")

			// Re-run connectivity tests
			allTests := true
			for _, host := range app.cfg.TestMode.TestConnections {
				if !testConnectivity(host, ConnectivityTestTimeout) {
					allTests = false
					break
				}
			}

			if !allTests {
				logger.Warn("testmode", "Connectivity tests failed, reverting configuration")
				// originalState is already of type *firewall.FirewallState, no type assertion needed
				if err := app.firewallMgr.RestoreState(originalState); err != nil {
					logger.Error("testmode", "Failed to restore state", "error", err.Error())
				} else {
					logger.Info("testmode", "Configuration reverted successfully")
				}
			} else {
				logger.Info("testmode", "All connectivity tests passed, keeping configuration")
			}
		})
	}

	return nil
}

func (app *App) runConnectivityTests(hosts []string) map[string]bool {
	if len(hosts) == 0 {
		return make(map[string]bool)
	}

	results := make(map[string]bool, len(hosts))
	var wg sync.WaitGroup
	var mu sync.Mutex

	// Test connectivity concurrently for better performance
	for _, host := range hosts {
		wg.Add(1)
		go func(h string) {
			defer wg.Done()
			success := testConnectivity(h, ConnectivityTestTimeout)
			mu.Lock()
			results[h] = success
			mu.Unlock()
		}(host)
	}

	wg.Wait()
	return results
}

func testConnectivity(host string, timeout time.Duration) bool {
	// Add default port if not specified
	if _, _, err := net.SplitHostPort(host); err != nil {
		// Try HTTPS first, then HTTP
		if testSingleConnection(host+":443", timeout) {
			return true
		}
		host += ":80"
	}

	return testSingleConnection(host, timeout)
}

func testSingleConnection(address string, timeout time.Duration) bool {
	conn, err := net.DialTimeout("tcp", address, timeout)
	if err != nil {
		return false
	}
	conn.Close()
	return true
}
// internal/api/api.go
package api

import (
	"encoding/json"
	"net"
	"net/http"
	"strconv"
	"strings"
	"time"

	"qff/internal/config"
	"qff/internal/firewall"
	"qff/internal/ips"
	"qff/internal/logger"
	"qff/internal/monitor"

	"github.com/gorilla/mux"
	"github.com/prometheus/client_golang/prometheus/promhttp"
)

type APIServer struct {
	config     *config.Config
	firewall   *firewall.NFTManager
	monitor    *monitor.SystemMonitor
	ipsManager *ips.IPSManager
	router     *mux.Router
	startTime  time.Time
}

type StatusResponse struct {
	Status           string                 `json:"status"`
	Version          string                 `json:"version"`
	Uptime           string                 `json:"uptime"`
	GeoIPAvailable   bool                   `json:"geoip_available"`
	TemporaryEntries int                    `json:"temporary_entries"`
	Config           map[string]interface{} `json:"config,omitempty"`
}

type MetricsResponse struct {
	SystemMetrics   map[string]interface{} `json:"system_metrics"`
	FirewallMetrics map[string]interface{} `json:"firewall_metrics"`
}

func (a *APIServer) handleIPSBlocked(w http.ResponseWriter, r *http.Request) {
	if a.ipsManager == nil {
		a.writeErrorResponse(w, "IPS not enabled", http.StatusServiceUnavailable)
		return
	}

	blocked := a.ipsManager.GetBlockedIPs()
	a.writeJSONResponse(w, map[string]interface{}{
		"blocked_ips": blocked,
		"count":       len(blocked),
	})
}

func (a *APIServer) handleIPSWhitelist(w http.ResponseWriter, r *http.Request) {
	if a.ipsManager == nil {
		a.writeErrorResponse(w, "IPS not enabled", http.StatusServiceUnavailable)
		return
	}

	whitelist := a.ipsManager.GetWhitelistedIPs()
	a.writeJSONResponse(w, map[string]interface{}{
		"whitelisted_ips": whitelist,
		"count":           len(whitelist),
	})
}

func (a *APIServer) handleIPSUnblock(w http.ResponseWriter, r *http.Request) {
	if a.ipsManager == nil {
		a.writeErrorResponse(w, "IPS not enabled", http.StatusServiceUnavailable)
		return
	}

	ip := a.parseIPFromQuery(w, r)
	if ip == nil {
		return
	}

	if err := a.ipsManager.UnblockIP(ip); err != nil {
		a.writeErrorResponse(w, "Failed to unblock IP", http.StatusInternalServerError)
		return
	}

	a.writeJSONResponse(w, map[string]string{
		"status": "unblocked",
		"ip":     ip.String(),
	})
}

func (a *APIServer) handleIPSWhitelistAdd(w http.ResponseWriter, r *http.Request) {
	if a.ipsManager == nil {
		a.writeErrorResponse(w, "IPS not enabled", http.StatusServiceUnavailable)
		return
	}

	ip := a.parseIPFromQuery(w, r)
	if ip == nil {
		return
	}

	permanent := r.URL.Query().Get("permanent") == "true"
	reason := r.URL.Query().Get("reason")
	if reason == "" {
		reason = "Manual whitelist via API"
	}

	if err := a.ipsManager.AddWhitelist(ip, permanent, reason); err != nil {
		a.writeErrorResponse(w, "Failed to whitelist IP", http.StatusInternalServerError)
		return
	}

	a.writeJSONResponse(w, map[string]interface{}{
		"status":    "whitelisted",
		"ip":        ip.String(),
		"permanent": permanent,
		"reason":    reason,
	})
}

func (a *APIServer) handleIPSWhitelistRemove(w http.ResponseWriter, r *http.Request) {
	if a.ipsManager == nil {
		a.writeErrorResponse(w, "IPS not enabled", http.StatusServiceUnavailable)
		return
	}

	ip := a.parseIPFromQuery(w, r)
	if ip == nil {
		return
	}

	if err := a.ipsManager.RemoveWhitelist(ip); err != nil {
		a.writeErrorResponse(w, "Failed to remove whitelist", http.StatusInternalServerError)
		return
	}

	a.writeJSONResponse(w, map[string]string{
		"status": "removed",
		"ip":     ip.String(),
	})
}

func (a *APIServer) handleIPSStats(w http.ResponseWriter, r *http.Request) {
	if a.ipsManager == nil {
		a.writeErrorResponse(w, "IPS not enabled", http.StatusServiceUnavailable)
		return
	}

	stats := a.ipsManager.GetStats()
	a.writeJSONResponse(w, stats)
}

func NewAPIServer(cfg *config.Config, fw *firewall.NFTManager, mon *monitor.SystemMonitor, ipsManager *ips.IPSManager) *APIServer {
	api := &APIServer{
		config:     cfg,
		firewall:   fw,
		monitor:    mon,
		ipsManager: ipsManager,
		router:     mux.NewRouter(),
		startTime:  time.Now(),
	}

	api.setupRoutes()
	return api
}

func (a *APIServer) setupRoutes() {
	a.router.HandleFunc("/status", a.handleStatus).Methods("GET")
	a.router.HandleFunc("/metrics", a.handleMetrics).Methods("GET")
	a.router.HandleFunc("/reload", a.handleReload).Methods("POST")

	// IP management
	a.router.HandleFunc("/whitelist", a.handleWhitelistAdd).Methods("POST")
	a.router.HandleFunc("/whitelist", a.handleWhitelistRemove).Methods("DELETE")
	a.router.HandleFunc("/blacklist", a.handleBlacklistAdd).Methods("POST")
	a.router.HandleFunc("/blacklist", a.handleBlacklistRemove).Methods("DELETE")

	// DNS management
	a.router.HandleFunc("/dns/hosts", a.handleDNSHosts).Methods("GET")
	a.router.HandleFunc("/dns/add", a.handleDNSAdd).Methods("POST")

	// Prometheus metrics
	a.router.Handle("/prometheus", promhttp.Handler())

	// IPS management endpoints
	a.router.HandleFunc("/api/ips/blocked", a.handleIPSBlocked).Methods("GET")
	a.router.HandleFunc("/api/ips/whitelist", a.handleIPSWhitelist).Methods("GET")
	a.router.HandleFunc("/api/ips/unblock", a.handleIPSUnblock).Methods("POST")
	a.router.HandleFunc("/api/ips/whitelist/add", a.handleIPSWhitelistAdd).Methods("POST")
	a.router.HandleFunc("/api/ips/whitelist/remove", a.handleIPSWhitelistRemove).Methods("DELETE")
	a.router.HandleFunc("/api/ips/stats", a.handleIPSStats).Methods("GET")

	// Enhanced GeoIP endpoints
	a.router.HandleFunc("/api/geoip/check", a.handleGeoIPCheck).Methods("GET")
	a.router.HandleFunc("/api/geoip/service-rules", a.handleServiceRules).Methods("GET")
	a.router.HandleFunc("/api/geoip/vpn-check", a.handleVPNCheck).Methods("GET")
	a.router.HandleFunc("/api/geoip/stats", a.handleGeoIPStats).Methods("GET")

	a.router.HandleFunc("/api/ports/list", a.handlePortsList).Methods("GET")
	a.router.HandleFunc("/api/ports/add", a.handlePortAdd).Methods("POST")
	a.router.HandleFunc("/api/ports/remove", a.handlePortRemove).Methods("DELETE")

	// Middleware
	a.router.Use(a.loggingMiddleware)
	a.router.Use(a.corsMiddleware)
}

func (a *APIServer) handleGeoIPCheck(w http.ResponseWriter, r *http.Request) {
	ip := a.parseIPFromQuery(w, r)
	if ip == nil {
		return
	}

	service := r.URL.Query().Get("service")
	if service == "" {
		service = "web" // Default service
	}

	// This would require access to enhanced GeoIP manager
	// You'll need to pass it to the API server or access it through IPS manager

	a.writeJSONResponse(w, map[string]interface{}{
		"ip":      ip.String(),
		"service": service,
		"message": "Enhanced GeoIP check endpoint - implementation needed",
	})
}

func (a *APIServer) handleServiceRules(w http.ResponseWriter, r *http.Request) {
	// Return configured service rules
	a.writeJSONResponse(w, map[string]interface{}{
		"service_rules": "Service rules endpoint - implementation needed",
	})
}

func (a *APIServer) handleVPNCheck(w http.ResponseWriter, r *http.Request) {
	ip := a.parseIPFromQuery(w, r)
	if ip == nil {
		return
	}

	a.writeJSONResponse(w, map[string]interface{}{
		"ip":      ip.String(),
		"message": "VPN check endpoint - implementation needed",
	})
}

func (a *APIServer) handleGeoIPStats(w http.ResponseWriter, r *http.Request) {
	a.writeJSONResponse(w, map[string]interface{}{
		"message": "Enhanced GeoIP stats endpoint - implementation needed",
	})
}

func (a *APIServer) Start(addr string) error {
	logger.Info("api", "Starting API server", "address", addr)
	return http.ListenAndServe(addr, a.router)
}

func (a *APIServer) handleStatus(w http.ResponseWriter, r *http.Request) {
	uptime := time.Since(a.startTime)

	response := StatusResponse{
		Status:           "running",
		Version:          "1.0.0",
		Uptime:           uptime.String(),
		GeoIPAvailable:   a.config.GeoIP.MMDBPath != "",
		TemporaryEntries: 0,
	}

	a.writeJSONResponse(w, response)
}

func (a *APIServer) handleMetrics(w http.ResponseWriter, r *http.Request) {
	systemMetrics, err := a.monitor.GetMetrics()
	if err != nil {
		logger.Error("api", "Failed to get system metrics", "error", err)
	}

	// Convert map[string]float64 to map[string]interface{}
	systemMetricsInterface := make(map[string]interface{})
	for k, v := range systemMetrics {
		systemMetricsInterface[k] = v
	}

	firewallMetrics, _ := a.firewall.GetStats()

	response := MetricsResponse{
		SystemMetrics:   systemMetricsInterface,
		FirewallMetrics: firewallMetrics,
	}

	a.writeJSONResponse(w, response)
}

func (a *APIServer) handleReload(w http.ResponseWriter, r *http.Request) {
	logger.Info("api", "Reloading configuration via API")

	if err := a.firewall.Reload(); err != nil {
		logger.Error("api", "Failed to reload firewall", "error", err.Error())
		a.writeErrorResponse(w, "Failed to reload", http.StatusInternalServerError)
		return
	}

	a.writeJSONResponse(w, map[string]string{"status": "reloaded"})
}

func (a *APIServer) handleWhitelistAdd(w http.ResponseWriter, r *http.Request) {
	ip := a.parseIPFromQuery(w, r)
	if ip == nil {
		return
	}

	if err := a.firewall.AddWhitelistIP(ip); err != nil {
		logger.Error("api", "Failed to add IP to whitelist", "ip", ip.String(), "error", err.Error())
		a.writeErrorResponse(w, "Failed to add IP", http.StatusInternalServerError)
		return
	}

	a.writeJSONResponse(w, map[string]string{"status": "added", "ip": ip.String()})
}

func (a *APIServer) handleWhitelistRemove(w http.ResponseWriter, r *http.Request) {
	ip := a.parseIPFromQuery(w, r)
	if ip == nil {
		return
	}

	if err := a.firewall.RemoveWhitelistIP(ip); err != nil {
		logger.Error("api", "Failed to remove IP from whitelist", "ip", ip.String(), "error", err.Error())
		a.writeErrorResponse(w, "Failed to remove IP", http.StatusInternalServerError)
		return
	}

	a.writeJSONResponse(w, map[string]string{"status": "removed", "ip": ip.String()})
}

func (a *APIServer) handleBlacklistAdd(w http.ResponseWriter, r *http.Request) {
	ip := a.parseIPFromQuery(w, r)
	if ip == nil {
		return
	}

	if err := a.firewall.AddBlacklistIP(ip); err != nil {
		logger.Error("api", "Failed to add IP to blacklist", "ip", ip.String(), "error", err.Error())
		a.writeErrorResponse(w, "Failed to add IP", http.StatusInternalServerError)
		return
	}

	a.writeJSONResponse(w, map[string]string{"status": "added", "ip": ip.String()})
}

func (a *APIServer) handleBlacklistRemove(w http.ResponseWriter, r *http.Request) {
	ip := a.parseIPFromQuery(w, r)
	if ip == nil {
		return
	}

	if err := a.firewall.RemoveBlacklistIP(ip); err != nil {
		logger.Error("api", "Failed to remove IP from blacklist", "ip", ip.String(), "error", err.Error())
		a.writeErrorResponse(w, "Failed to remove IP", http.StatusInternalServerError)
		return
	}

	a.writeJSONResponse(w, map[string]string{"status": "removed", "ip": ip.String()})
}

func (a *APIServer) handleDNSHosts(w http.ResponseWriter, r *http.Request) {
	hosts := a.firewall.GetDynamicHosts()
	a.writeJSONResponse(w, map[string]interface{}{
		"dynamic_hosts": hosts,
	})
}

func (a *APIServer) handleDNSAdd(w http.ResponseWriter, r *http.Request) {
	hostname := r.URL.Query().Get("hostname")
	if hostname == "" {
		a.writeErrorResponse(w, "hostname parameter required", http.StatusBadRequest)
		return
	}

	if err := a.firewall.AddDynamicHost(hostname); err != nil {
		a.writeErrorResponse(w, "Failed to add hostname", http.StatusInternalServerError)
		return
	}

	a.writeJSONResponse(w, map[string]string{
		"status":   "added",
		"hostname": hostname,
	})
}

func (a *APIServer) parseIPFromQuery(w http.ResponseWriter, r *http.Request) net.IP {
	ipStr := r.URL.Query().Get("ip")
	if ipStr == "" {
		a.writeErrorResponse(w, "IP parameter required", http.StatusBadRequest)
		return nil
	}

	ip := net.ParseIP(ipStr)
	if ip == nil {
		a.writeErrorResponse(w, "Invalid IP address", http.StatusBadRequest)
		return nil
	}

	return ip
}

func (a *APIServer) writeJSONResponse(w http.ResponseWriter, data interface{}) {
	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(data)
}

func (a *APIServer) writeErrorResponse(w http.ResponseWriter, message string, statusCode int) {
	w.Header().Set("Content-Type", "application/json")
	w.WriteHeader(statusCode)
	json.NewEncoder(w).Encode(map[string]string{"error": message})
}

func (a *APIServer) loggingMiddleware(next http.Handler) http.Handler {
	return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		start := time.Now()
		next.ServeHTTP(w, r)
		duration := time.Since(start)

		logger.Info("api", "HTTP request",
			"method", r.Method,
			"path", r.URL.Path,
			"duration", duration.String(),
			"remote_addr", r.RemoteAddr,
		)
	})
}

func (a *APIServer) corsMiddleware(next http.Handler) http.Handler {
	return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		w.Header().Set("Access-Control-Allow-Origin", "*")
		w.Header().Set("Access-Control-Allow-Methods", "GET, POST, DELETE, OPTIONS")
		w.Header().Set("Access-Control-Allow-Headers", "Content-Type")

		if r.Method == "OPTIONS" {
			w.WriteHeader(http.StatusOK)
			return
		}

		next.ServeHTTP(w, r)
	})
}

func (a *APIServer) autoWhitelistClient(r *http.Request) {
	clientIP := GetClientIP(r)
	if clientIP != nil && !clientIP.IsLoopback() {
		if err := a.firewall.AddWhitelistIP(clientIP); err != nil {
			logger.Error("api", "Failed to auto-whitelist client", "ip", clientIP.String(), "error", err.Error())
		} else {
			logger.Info("api", "Auto-whitelisted API client", "ip", clientIP.String())
		}
	}
}

func GetClientIP(r *http.Request) net.IP {
	// Check X-Forwarded-For header first
	xff := r.Header.Get("X-Forwarded-For")
	if xff != "" {
		ips := strings.Split(xff, ",")
		if len(ips) > 0 {
			ip := net.ParseIP(strings.TrimSpace(ips[0]))
			if ip != nil {
				return ip
			}
		}
	}

	// Check X-Real-IP header
	xri := r.Header.Get("X-Real-IP")
	if xri != "" {
		ip := net.ParseIP(strings.TrimSpace(xri))
		if ip != nil {
			return ip
		}
	}

	// Fall back to RemoteAddr
	host, _, err := net.SplitHostPort(r.RemoteAddr)
	if err != nil {
		return nil
	}

	return net.ParseIP(host)
}

func (a *APIServer) handlePortsList(w http.ResponseWriter, r *http.Request) {
	ports := a.firewall.ListPortRules()
	a.writeJSONResponse(w, map[string]interface{}{
		"port_rules": ports,
	})
}

func (a *APIServer) handlePortAdd(w http.ResponseWriter, r *http.Request) {
	port := r.URL.Query().Get("port")
	protocol := r.URL.Query().Get("protocol")
	direction := r.URL.Query().Get("direction")
	action := r.URL.Query().Get("action")

	if port == "" || protocol == "" || direction == "" {
		a.writeErrorResponse(w, "Missing required parameters: port, protocol, direction", http.StatusBadRequest)
		return
	}

	if action == "" {
		action = "allow"
	}

	portNum, err := strconv.Atoi(port)
	if err != nil {
		a.writeErrorResponse(w, "Invalid port number", http.StatusBadRequest)
		return
	}

	if err := a.firewall.AddPortRule(portNum, protocol, direction, action); err != nil {
		a.writeErrorResponse(w, "Failed to add port rule", http.StatusInternalServerError)
		return
	}

	a.writeJSONResponse(w, map[string]interface{}{
		"status":    "added",
		"port":      portNum,
		"protocol":  protocol,
		"direction": direction,
		"action":    action,
	})
}

func (a *APIServer) handlePortRemove(w http.ResponseWriter, r *http.Request) {
	port := r.URL.Query().Get("port")
	protocol := r.URL.Query().Get("protocol")
	direction := r.URL.Query().Get("direction")

	if port == "" || protocol == "" || direction == "" {
		a.writeErrorResponse(w, "Missing required parameters: port, protocol, direction", http.StatusBadRequest)
		return
	}

	portNum, err := strconv.Atoi(port)
	if err != nil {
		a.writeErrorResponse(w, "Invalid port number", http.StatusBadRequest)
		return
	}

	if err := a.firewall.RemovePortRule(portNum, protocol, direction); err != nil {
		a.writeErrorResponse(w, "Failed to remove port rule", http.StatusInternalServerError)
		return
	}

	a.writeJSONResponse(w, map[string]interface{}{
		"status":    "removed",
		"port":      portNum,
		"protocol":  protocol,
		"direction": direction,
	})
}
// internal/config/config.go
package config

import (
	"fmt"
	"os"
	"strconv"
	"strings"
	"time"
)

type IPSConfig struct {
	EnableIPS            bool          `yaml:"enable_ips"`
	LogCheckInterval     time.Duration `yaml:"log_check_interval"`
	TempBlockDuration    time.Duration `yaml:"temp_block_duration"`
	PermBlockThreshold   int           `yaml:"perm_block_threshold"`
	AutoWhitelistSSH     bool          `yaml:"auto_whitelist_ssh_sessions"`
	SSHWhitelistDuration time.Duration `yaml:"ssh_whitelist_duration"`

	// Detection rules
	CPanelFailedLogins      int           `yaml:"cpanel_failed_logins"`
	CPanelTimeWindow        time.Duration `yaml:"cpanel_time_window"`
	DirectAdminFailedLogins int           `yaml:"directadmin_failed_logins"`
	DirectAdminTimeWindow   time.Duration `yaml:"directadmin_time_window"`
	WordPressFailedLogins   int           `yaml:"wordpress_failed_logins"`
	WordPressTimeWindow     time.Duration `yaml:"wordpress_time_window"`

	// Notifications
	EnableBlockNotifications bool          `yaml:"enable_block_notifications"`
	NotifyCPanelBlocks       bool          `yaml:"notify_cpanel_blocks"`
	NotifyWebBlocks          bool          `yaml:"notify_web_blocks"`
	NotificationCooldown     time.Duration `yaml:"notification_cooldown"`

	// Log file paths
	CPanelLogFiles          []string      `yaml:"cpanel_log_files"`
	DirectAdminLogFiles     []string      `yaml:"directadmin_log_files"`
	ApacheLogFiles          []string      `yaml:"apache_log_files"`
	NginxLogFiles           []string      `yaml:"nginx_log_files"`
	MailLogFiles            []string      `yaml:"mail_log_files"`
	FTPLogFiles             []string      `yaml:"ftp_log_files"`
	AuthLogFiles            []string      `yaml:"auth_log_files"`
	EnablePortScanDetection bool          `yaml:"enable_port_scan_detection"`
	PortScanThreshold       int           `yaml:"port_scan_threshold"`
	PortScanTimeWindow      time.Duration `yaml:"port_scan_time_window"`

	EnableFileSystemMonitor bool          `yaml:"enable_filesystem_monitor"`
	CriticalFiles           []string      `yaml:"critical_files"`
	CriticalDirectories     []string      `yaml:"critical_directories"`
	FileCheckInterval       time.Duration `yaml:"file_check_interval"`

	EnableProcessMonitor bool          `yaml:"enable_process_monitor"`
	SuspiciousProcesses  []string      `yaml:"suspicious_process_patterns"`
	MaxProcessMemory     string        `yaml:"max_process_memory"`
	ProcessCheckInterval time.Duration `yaml:"process_check_interval"`

	EnableExternalBlocklists bool          `yaml:"enable_external_blocklists"`
	SpamhausEnabled          bool          `yaml:"spamhaus_enabled"`
	DShieldEnabled           bool          `yaml:"dshield_enabled"`
	BlocklistUpdateInterval  time.Duration `yaml:"blocklist_update_interval"`
}

type Config struct {
	Firewall     FirewallConfig     `yaml:"firewall"`
	Ports        PortsConfig        `yaml:"ports"`
	Security     SecurityConfig     `yaml:"security"`
	GeoIP        GeoIPConfig        `yaml:"geoip"`
	DNS          DNSConfig          `yaml:"dns"`
	RateLimit    RateLimitConfig    `yaml:"ratelimit"`
	SynFlood     SynFloodConfig     `yaml:"synflood"`
	Notification NotificationConfig `yaml:"notification"`
	Monitor      MonitorConfig      `yaml:"monitor"`
	TestMode     TestModeConfig     `yaml:"testmode"`
	IPS          IPSConfig          `yaml:"ips"`
}

type FirewallConfig struct {
	DefaultPolicy string `yaml:"default_policy"`
	EnableIPv6    bool   `yaml:"enable_ipv6"`
}

type PortsConfig struct {
	TCPIn   []int `yaml:"tcp_in"`
	TCPOut  []int `yaml:"tcp_out"`
	UDPIn   []int `yaml:"udp_in"`
	UDPOut  []int `yaml:"udp_out"`
	TCPDeny []int `yaml:"tcp_deny"`
	UDPDeny []int `yaml:"udp_deny"`
}

type SecurityConfig struct {
	EnableBogonFilter   bool          `yaml:"enable_bogon_filter"`
	EnableMartianFilter bool          `yaml:"enable_martian_filter"`
	BogonUpdateInterval time.Duration `yaml:"bogon_update_interval"`
	BogonIPv4URL        string        `yaml:"bogon_ipv4_url"`
	BogonIPv6URL        string        `yaml:"bogon_ipv6_url"`
}

type GeoIPConfig struct {
	// Existing fields...
	MMDBPath         string `yaml:"mmdb_path"`
	CountryBlockFile string `yaml:"country_block_file"`
	CountryAllowFile string `yaml:"country_allow_file"`
	MaxMindAPIKey    string `yaml:"maxmind_api_key"`
	AutoDownload     bool   `yaml:"auto_download"`

	// Enhanced GeoIP features
	EnablePerServiceRules bool                    `yaml:"enable_per_service_rules"`
	ServiceRules          map[string]*ServiceRule `yaml:"service_rules"`
	EnableVPNDetection    bool                    `yaml:"enable_vpn_detection"`
	VPNDetectionAPI       string                  `yaml:"vpn_detection_api"`
	VPNAPIKey             string                  `yaml:"vpn_api_key"`
	VPNBlocklists         []string                `yaml:"vpn_blocklists"`
	CacheVPNResults       bool                    `yaml:"cache_vpn_results"`
	CacheExpiration       time.Duration           `yaml:"cache_expiration"`
}

type ServiceRule struct {
	Service          string   `yaml:"service"`
	AllowedCountries []string `yaml:"allowed_countries"`
	BlockedCountries []string `yaml:"blocked_countries"`
	BlockVPNs        bool     `yaml:"block_vpns"`
	BlockProxies     bool     `yaml:"block_proxies"`
	Enabled          bool     `yaml:"enabled"`
}

type DNSConfig struct {
	EnableDynamicDNS bool          `yaml:"enable_dynamic_dns"`
	Hostnames        []string      `yaml:"hostnames"`
	UpdateInterval   time.Duration `yaml:"update_interval"`
}

type RateLimitConfig struct {
	EnableRateLimit    bool              `yaml:"enable_rate_limit"`
	GlobalConnLimit    int               `yaml:"global_conn_limit"`
	GlobalConnWindow   time.Duration     `yaml:"global_conn_window"`
	PortSpecificLimits map[string]string `yaml:"port_specific_limits"`
}

type SynFloodConfig struct {
	EnableProtection bool `yaml:"enable_protection"`
	SynRateLimit     int  `yaml:"syn_rate_limit"`
	SynBurst         int  `yaml:"syn_burst"`
	ConntrackMax     int  `yaml:"conntrack_max"`
}

type NotificationConfig struct {
	EnableEmail    bool     `yaml:"enable_email"`
	EmailServer    string   `yaml:"email_server"`
	EmailPort      int      `yaml:"email_port"`
	EmailUser      string   `yaml:"email_user"`
	EmailPassword  string   `yaml:"email_password"`
	EmailTo        string   `yaml:"email_to"`
	EnableWebhooks bool     `yaml:"enable_webhooks"`
	WebhookURLs    []string `yaml:"webhook_urls"`
	WebhookTimeout int      `yaml:"webhook_timeout"`
}

type MonitorConfig struct {
	EnableResourceMonitoring bool          `yaml:"enable_resource_monitoring"`
	CPUAlert                 bool          `yaml:"cpu_alert"`
	CPUThreshold             float64       `yaml:"cpu_threshold"`
	CPUDuration              time.Duration `yaml:"cpu_duration"`
	MemoryAlert              bool          `yaml:"memory_alert"`
	MemoryThreshold          float64       `yaml:"memory_threshold"`
	DiskAlert                bool          `yaml:"disk_alert"`
	DiskThreshold            float64       `yaml:"disk_threshold"`
}

type TestModeConfig struct {
	EnableTestMode  bool          `yaml:"enable_test_mode"`
	TestDuration    time.Duration `yaml:"test_duration"`
	RevertOnFailure bool          `yaml:"revert_on_failure"`
	TestConnections []string      `yaml:"test_connections"`
}

func LoadConfig(path string) (*Config, error) {
	data, err := os.ReadFile(path)
	if err != nil {
		return nil, fmt.Errorf("failed to read config file: %w", err)
	}

	cfg := &Config{}
	if err := parseINI(data, cfg); err != nil {
		return nil, fmt.Errorf("failed to parse config: %w", err)
	}

	return cfg, nil
}

func ValidateConfig(cfg *Config) error {
	if cfg.Firewall.DefaultPolicy != "accept" && cfg.Firewall.DefaultPolicy != "drop" {
		return fmt.Errorf("invalid default_policy: must be 'accept' or 'drop'")
	}

	if cfg.Monitor.CPUThreshold < 0 || cfg.Monitor.CPUThreshold > 100 {
		return fmt.Errorf("invalid cpu_threshold: must be between 0 and 100")
	}

	if cfg.Monitor.MemoryThreshold < 0 || cfg.Monitor.MemoryThreshold > 100 {
		return fmt.Errorf("invalid memory_threshold: must be between 0 and 100")
	}

	if cfg.Notification.EnableEmail {
		if cfg.Notification.EmailServer == "" || cfg.Notification.EmailTo == "" {
			return fmt.Errorf("email_server and email_to required when email notifications enabled")
		}
	}

	return nil
}

func parseINI(data []byte, cfg *Config) error {
	lines := strings.Split(string(data), "\n")
	var currentSection string

	for _, line := range lines {
		line = strings.TrimSpace(line)
		if line == "" || strings.HasPrefix(line, "#") {
			continue
		}

		if strings.HasPrefix(line, "[") && strings.HasSuffix(line, "]") {
			currentSection = line[1 : len(line)-1]
			continue
		}

		parts := strings.SplitN(line, "=", 2)
		if len(parts) != 2 {
			continue
		}

		key := strings.TrimSpace(parts[0])
		value := strings.TrimSpace(parts[1])

		if err := setConfigValue(cfg, currentSection, key, value); err != nil {
			return fmt.Errorf("error setting %s.%s: %w", currentSection, key, err)
		}
	}

	return nil
}

func setConfigValue(cfg *Config, section, key, value string) error {
	switch section {
	case "firewall":
		return setFirewallConfig(&cfg.Firewall, key, value)
	case "ports":
		return setPortsConfig(&cfg.Ports, key, value)
	case "security":
		return setSecurityConfig(&cfg.Security, key, value)
	case "geoip":
		return setGeoIPConfig(&cfg.GeoIP, key, value)
	case "dns":
		return setDNSConfig(&cfg.DNS, key, value)
	case "ratelimit":
		return setRateLimitConfig(&cfg.RateLimit, key, value)
	case "synflood":
		return setSynFloodConfig(&cfg.SynFlood, key, value)
	case "notification":
		return setNotificationConfig(&cfg.Notification, key, value)
	case "monitor":
		return setMonitorConfig(&cfg.Monitor, key, value)
	case "testmode":
		return setTestModeConfig(&cfg.TestMode, key, value)
	case "ips":
		return setIPSConfig(&cfg.IPS, key, value)
	}
	return nil
}

func setFirewallConfig(cfg *FirewallConfig, key, value string) error {
	switch key {
	case "default_policy":
		cfg.DefaultPolicy = value
	case "enable_ipv6":
		cfg.EnableIPv6 = value == "true"
	}
	return nil
}

func setPortsConfig(cfg *PortsConfig, key, value string) error {
	ports := parsePorts(value)
	switch key {
	case "tcp_in":
		cfg.TCPIn = ports
	case "tcp_out":
		cfg.TCPOut = ports
	case "udp_in":
		cfg.UDPIn = ports
	case "udp_out":
		cfg.UDPOut = ports
	case "tcp_deny":
		cfg.TCPDeny = ports
	case "udp_deny":
		cfg.UDPDeny = ports
	}
	return nil
}

func parsePorts(value string) []int {
	var ports []int
	for _, p := range strings.Split(value, ",") {
		if port, err := strconv.Atoi(strings.TrimSpace(p)); err == nil {
			ports = append(ports, port)
		}
	}
	return ports
}

func setSecurityConfig(cfg *SecurityConfig, key, value string) error {
	switch key {
	case "enable_bogon_filter":
		cfg.EnableBogonFilter = value == "true"
	case "enable_martian_filter":
		cfg.EnableMartianFilter = value == "true"
	case "bogon_update_interval":
		if d, err := time.ParseDuration(value); err == nil {
			cfg.BogonUpdateInterval = d
		}
	case "bogon_ipv4_url":
		cfg.BogonIPv4URL = value
	case "bogon_ipv6_url":
		cfg.BogonIPv6URL = value
	}
	return nil
}

func setGeoIPConfig(cfg *GeoIPConfig, key, value string) error {
	switch key {
	case "mmdb_path":
		cfg.MMDBPath = value
	case "country_block_file":
		cfg.CountryBlockFile = value
	case "country_allow_file":
		cfg.CountryAllowFile = value
	case "maxmind_api_key":
		cfg.MaxMindAPIKey = value
	case "auto_download":
		cfg.AutoDownload = value == "true"
	case "enable_per_service_rules":
		cfg.EnablePerServiceRules = value == "true"
	case "enable_vpn_detection":
		cfg.EnableVPNDetection = value == "true"
	case "vpn_detection_api":
		cfg.VPNDetectionAPI = value
	case "vpn_api_key":
		cfg.VPNAPIKey = value
	case "vpn_blocklists":
		cfg.VPNBlocklists = parseLogFiles(value)
	case "cache_vpn_results":
		cfg.CacheVPNResults = value == "true"
	case "cache_expiration":
		if d, err := time.ParseDuration(value); err == nil {
			cfg.CacheExpiration = d
		}
	}
	return nil
}

func setDNSConfig(cfg *DNSConfig, key, value string) error {
	switch key {
	case "enable_dynamic_dns":
		cfg.EnableDynamicDNS = value == "true"
	case "hostnames":
		cfg.Hostnames = strings.Split(value, ",")
		for i := range cfg.Hostnames {
			cfg.Hostnames[i] = strings.TrimSpace(cfg.Hostnames[i])
		}
	case "update_interval":
		if d, err := time.ParseDuration(value); err == nil {
			cfg.UpdateInterval = d
		} // Remove the extra } here
	}
	return nil
}

func setRateLimitConfig(cfg *RateLimitConfig, key, value string) error {
	switch key {
	case "enable_rate_limit":
		cfg.EnableRateLimit = value == "true"
	case "global_conn_limit":
		if i, err := strconv.Atoi(value); err == nil {
			cfg.GlobalConnLimit = i
		}
	case "global_conn_window":
		if d, err := time.ParseDuration(value); err == nil {
			cfg.GlobalConnWindow = d
		}
	}
	return nil
}

func setSynFloodConfig(cfg *SynFloodConfig, key, value string) error {
	switch key {
	case "enable_protection":
		cfg.EnableProtection = value == "true"
	case "syn_rate_limit":
		if i, err := strconv.Atoi(value); err == nil {
			cfg.SynRateLimit = i
		}
	case "syn_burst":
		if i, err := strconv.Atoi(value); err == nil {
			cfg.SynBurst = i
		}
	case "conntrack_max":
		if i, err := strconv.Atoi(value); err == nil {
			cfg.ConntrackMax = i
		}
	}
	return nil
}

func setNotificationConfig(cfg *NotificationConfig, key, value string) error {
	switch key {
	case "enable_email":
		cfg.EnableEmail = value == "true"
	case "email_server":
		cfg.EmailServer = value
	case "email_port":
		if i, err := strconv.Atoi(value); err == nil {
			cfg.EmailPort = i
		}
	case "email_user":
		cfg.EmailUser = value
	case "email_password":
		cfg.EmailPassword = value
	case "email_to":
		cfg.EmailTo = value
	case "enable_webhooks":
		cfg.EnableWebhooks = value == "true"
	case "webhook_urls":
		cfg.WebhookURLs = strings.Split(value, ",")
		for i := range cfg.WebhookURLs {
			cfg.WebhookURLs[i] = strings.TrimSpace(cfg.WebhookURLs[i])
		}
	case "webhook_timeout":
		if i, err := strconv.Atoi(value); err == nil {
			cfg.WebhookTimeout = i
		}
	}
	return nil
}

func setMonitorConfig(cfg *MonitorConfig, key, value string) error {
	switch key {
	case "enable_resource_monitoring":
		cfg.EnableResourceMonitoring = value == "true"
	case "cpu_alert":
		cfg.CPUAlert = value == "true"
	case "cpu_threshold":
		if f, err := strconv.ParseFloat(value, 64); err == nil {
			cfg.CPUThreshold = f
		}
	case "cpu_duration":
		if d, err := time.ParseDuration(value); err == nil {
			cfg.CPUDuration = d
		}
	case "memory_alert":
		cfg.MemoryAlert = value == "true"
	case "memory_threshold":
		if f, err := strconv.ParseFloat(value, 64); err == nil {
			cfg.MemoryThreshold = f
		}
	case "disk_alert":
		cfg.DiskAlert = value == "true"
	case "disk_threshold":
		if f, err := strconv.ParseFloat(value, 64); err == nil {
			cfg.DiskThreshold = f
		}
	}
	return nil
}

func setTestModeConfig(cfg *TestModeConfig, key, value string) error {
	switch key {
	case "enable_test_mode":
		cfg.EnableTestMode = value == "true"
	case "test_duration":
		if d, err := time.ParseDuration(value); err == nil {
			cfg.TestDuration = d
		}
	case "revert_on_failure":
		cfg.RevertOnFailure = value == "true"
	case "test_connections":
		cfg.TestConnections = strings.Split(value, ",")
		for i := range cfg.TestConnections {
			cfg.TestConnections[i] = strings.TrimSpace(cfg.TestConnections[i])
		}
	}
	return nil
}

func setIPSConfig(cfg *IPSConfig, key, value string) error {
	switch key {
	case "enable_ips":
		cfg.EnableIPS = value == "true"
	case "log_check_interval":
		if d, err := time.ParseDuration(value); err == nil {
			cfg.LogCheckInterval = d
		}
	case "temp_block_duration":
		if d, err := time.ParseDuration(value); err == nil {
			cfg.TempBlockDuration = d
		}
	case "auto_whitelist_ssh_sessions":
		cfg.AutoWhitelistSSH = value == "true"
	case "ssh_whitelist_duration":
		if d, err := time.ParseDuration(value); err == nil {
			cfg.SSHWhitelistDuration = d
		}
	case "cpanel_failed_logins":
		if i, err := strconv.Atoi(value); err == nil {
			cfg.CPanelFailedLogins = i
		}
	case "cpanel_time_window":
		if d, err := time.ParseDuration(value); err == nil {
			cfg.CPanelTimeWindow = d
		}
	case "enable_block_notifications":
		cfg.EnableBlockNotifications = value == "true"
	case "notify_cpanel_blocks":
		cfg.NotifyCPanelBlocks = value == "true"
	case "cpanel_log_files":
		cfg.CPanelLogFiles = parseLogFiles(value)
	case "directadmin_log_files":
		cfg.DirectAdminLogFiles = parseLogFiles(value)
	case "apache_log_files":
		cfg.ApacheLogFiles = parseLogFiles(value)
	case "nginx_log_files":
		cfg.NginxLogFiles = parseLogFiles(value)
	case "mail_log_files":
		cfg.MailLogFiles = parseLogFiles(value)
	case "ftp_log_files":
		cfg.FTPLogFiles = parseLogFiles(value)
	case "auth_log_files":
		cfg.AuthLogFiles = parseLogFiles(value)
	case "enable_port_scan_detection":
		cfg.EnablePortScanDetection = value == "true"
	case "port_scan_threshold":
		if i, err := strconv.Atoi(value); err == nil {
			cfg.PortScanThreshold = i
		}
	case "port_scan_time_window":
		if d, err := time.ParseDuration(value); err == nil {
			cfg.PortScanTimeWindow = d
		}
	case "enable_filesystem_monitor":
		cfg.EnableFileSystemMonitor = value == "true"
	case "critical_files":
		cfg.CriticalFiles = parseLogFiles(value)
	case "critical_directories":
		cfg.CriticalDirectories = parseLogFiles(value)
	case "file_check_interval":
		if d, err := time.ParseDuration(value); err == nil {
			cfg.FileCheckInterval = d
		}
	case "enable_process_monitor":
		cfg.EnableProcessMonitor = value == "true"
	case "suspicious_process_patterns":
		cfg.SuspiciousProcesses = parseLogFiles(value)
	case "max_process_memory":
		cfg.MaxProcessMemory = value
	case "process_check_interval":
		if d, err := time.ParseDuration(value); err == nil {
			cfg.ProcessCheckInterval = d
		}
	case "enable_external_blocklists":
		cfg.EnableExternalBlocklists = value == "true"
	case "spamhaus_enabled":
		cfg.SpamhausEnabled = value == "true"
	case "dshield_enabled":
		cfg.DShieldEnabled = value == "true"
	case "blocklist_update_interval":
		if d, err := time.ParseDuration(value); err == nil {
			cfg.BlocklistUpdateInterval = d
		}
	}
	return nil
}

func parseLogFiles(value string) []string {
	var files []string
	for _, f := range strings.Split(value, ",") {
		file := strings.TrimSpace(f)
		if file != "" {
			files = append(files, file)
		}
	}
	return files
}
// internal/firewall/dns/dns.go
package dns

import (
	"context"
	"fmt"
	"net"
	"sort"
	"strings"
	"sync"
	"time"

	"qff/internal/logger"

	"github.com/google/nftables"
)

const (
	DefaultUpdateInterval = 5 * time.Minute
	DefaultResolveTimeout = 10 * time.Second
	MaxConcurrentResolves = 10
	SetNamePrefix         = "dns_"
	MaxRetries            = 3
	RetryBackoff          = time.Second
)

// DNSManager handles dynamic DNS resolution for nftables sets
type DNSManager struct {
	// Core components
	conn  *nftables.Conn
	table *nftables.Table

	// State management
	hostnames map[string]*HostEntry
	mu        sync.RWMutex

	// Lifecycle management
	ctx    context.Context
	cancel context.CancelFunc
	wg     sync.WaitGroup

	// Configuration
	config *Config
}

// Config holds configuration for the DNS manager
type Config struct {
	UpdateInterval time.Duration
	ResolveTimeout time.Duration
	MaxRetries     int
	RetryBackoff   time.Duration
}

// HostEntry represents a hostname and its resolved IPs
type HostEntry struct {
	Hostname    string    `json:"hostname"`
	IPs         []net.IP  `json:"ips"`
	SetName     string    `json:"set_name"`
	LastCheck   time.Time `json:"last_check"`
	LastSuccess time.Time `json:"last_success"`
	ErrorCount  int       `json:"error_count"`
	LastError   string    `json:"last_error,omitempty"`
}

// DNSStats provides statistics about DNS resolution
type DNSStats struct {
	TotalHostnames     int           `json:"total_hostnames"`
	SuccessfulChecks   int64         `json:"successful_checks"`
	FailedChecks       int64         `json:"failed_checks"`
	LastUpdateTime     time.Time     `json:"last_update_time"`
	AverageResolveTime time.Duration `json:"average_resolve_time"`
}

func NewDNSManager(conn *nftables.Conn, table *nftables.Table, config *Config) *DNSManager {
	if config == nil {
		config = &Config{
			UpdateInterval: DefaultUpdateInterval,
			ResolveTimeout: DefaultResolveTimeout,
			MaxRetries:     MaxRetries,
			RetryBackoff:   RetryBackoff,
		}
	}

	ctx, cancel := context.WithCancel(context.Background())

	return &DNSManager{
		conn:      conn,
		table:     table,
		hostnames: make(map[string]*HostEntry),
		ctx:       ctx,
		cancel:    cancel,
		config:    config,
	}
}

func (d *DNSManager) Initialize() error {
	logger.Info("dns", "Initializing Dynamic DNS manager",
		"update_interval", d.config.UpdateInterval,
		"resolve_timeout", d.config.ResolveTimeout)

	// Start the DNS updater goroutine
	d.wg.Add(1)
	go d.runDNSUpdater()

	return nil
}

func (d *DNSManager) AddHostname(hostname, setType string) error {
	if hostname == "" {
		return fmt.Errorf("hostname cannot be empty")
	}

	// Validate hostname format
	if err := d.validateHostname(hostname); err != nil {
		return fmt.Errorf("invalid hostname %q: %w", hostname, err)
	}

	d.mu.Lock()
	defer d.mu.Unlock()

	// Check if hostname already exists
	if _, exists := d.hostnames[hostname]; exists {
		logger.Info("dns", "Hostname already managed", "hostname", hostname)
		return nil
	}

	setName := d.generateSetName(hostname)

	// Create nftables set
	set := &nftables.Set{
		Name:    setName,
		Table:   d.table,
		KeyType: nftables.TypeIPAddr,
	}

	if err := d.conn.AddSet(set, []nftables.SetElement{}); err != nil {
		return fmt.Errorf("failed to create nftables set %q: %w", setName, err)
	}

	entry := &HostEntry{
		Hostname:    hostname,
		SetName:     setName,
		IPs:         make([]net.IP, 0),
		LastCheck:   time.Time{},
		LastSuccess: time.Time{},
	}

	d.hostnames[hostname] = entry

	// Perform initial resolution
	go func() {
		if err := d.resolveHostnameWithRetry(entry); err != nil {
			logger.Error("dns", "Initial hostname resolution failed",
				"hostname", hostname, "error", err.Error())
		}
	}()

	logger.Info("dns", "Added dynamic hostname", "hostname", hostname, "set", setName)
	return nil
}

func (d *DNSManager) RemoveHostname(hostname string) error {
	d.mu.Lock()
	defer d.mu.Unlock()

	entry, exists := d.hostnames[hostname]
	if !exists {
		return fmt.Errorf("hostname %q not found", hostname)
	}

	// Remove the nftables set
	set := &nftables.Set{Name: entry.SetName, Table: d.table}
	d.conn.DelSet(set)

	delete(d.hostnames, hostname)

	logger.Info("dns", "Removed dynamic hostname", "hostname", hostname)
	return nil
}

func (d *DNSManager) runDNSUpdater() {
	defer d.wg.Done()

	ticker := time.NewTicker(d.config.UpdateInterval)
	defer ticker.Stop()

	// Perform initial update
	d.updateAllHostnames()

	for {
		select {
		case <-ticker.C:
			d.updateAllHostnames()
		case <-d.ctx.Done():
			logger.Info("dns", "DNS updater stopping")
			return
		}
	}
}

func (d *DNSManager) updateAllHostnames() {
	startTime := time.Now()

	// Get snapshot of hostnames to avoid holding lock during resolution
	d.mu.RLock()
	entries := make([]*HostEntry, 0, len(d.hostnames))
	for _, entry := range d.hostnames {
		entries = append(entries, entry)
	}
	d.mu.RUnlock()

	if len(entries) == 0 {
		return
	}

	logger.Info("dns", "Starting DNS update cycle", "hostnames", len(entries))

	// Use worker pool for concurrent resolution
	d.resolveHostnamesConcurrently(entries)

	// Flush all changes at once for better performance
	if err := d.conn.Flush(); err != nil {
		logger.Error("dns", "Failed to flush nftables changes", "error", err.Error())
	}

	duration := time.Since(startTime)
	logger.Info("dns", "DNS update cycle completed",
		"duration", duration, "hostnames", len(entries))
}

func (d *DNSManager) resolveHostnamesConcurrently(entries []*HostEntry) {
	// Use buffered channel to limit concurrent resolutions
	semaphore := make(chan struct{}, MaxConcurrentResolves)
	var wg sync.WaitGroup

	for _, entry := range entries {
		wg.Add(1)
		go func(e *HostEntry) {
			defer wg.Done()
			semaphore <- struct{}{}        // Acquire
			defer func() { <-semaphore }() // Release

			if err := d.resolveHostnameWithRetry(e); err != nil {
				logger.Error("dns", "Failed to resolve hostname",
					"hostname", e.Hostname, "error", err.Error())
			}
		}(entry)
	}

	wg.Wait()
}

func (d *DNSManager) resolveHostnameWithRetry(entry *HostEntry) error {
	var lastErr error

	for attempt := 0; attempt < d.config.MaxRetries; attempt++ {
		if attempt > 0 {
			// Exponential backoff with jitter
			backoff := d.config.RetryBackoff * time.Duration(1<<uint(attempt-1))
			if backoff > time.Minute {
				backoff = time.Minute
			}

			select {
			case <-time.After(backoff):
			case <-d.ctx.Done():
				return d.ctx.Err()
			}
		}

		if err := d.resolveHostname(entry); err != nil {
			lastErr = err
			logger.Warn("dns", "DNS resolution attempt failed",
				"hostname", entry.Hostname, "attempt", attempt+1, "error", err.Error())
			continue
		}

		// Success
		d.mu.Lock()
		entry.ErrorCount = 0
		entry.LastError = ""
		entry.LastSuccess = time.Now()
		d.mu.Unlock()

		return nil
	}

	// All retries failed
	d.mu.Lock()
	entry.ErrorCount++
	entry.LastError = lastErr.Error()
	d.mu.Unlock()

	return fmt.Errorf("failed after %d attempts: %w", d.config.MaxRetries, lastErr)
}

func (d *DNSManager) resolveHostname(entry *HostEntry) error {
	ctx, cancel := context.WithTimeout(d.ctx, d.config.ResolveTimeout)
	defer cancel()

	// Use custom resolver with timeout
	resolver := &net.Resolver{
		PreferGo: true,
		Dial: func(ctx context.Context, network, address string) (net.Conn, error) {
			d := net.Dialer{
				Timeout: d.config.ResolveTimeout,
			}
			return d.DialContext(ctx, network, address)
		},
	}

	ips, err := resolver.LookupIPAddr(ctx, entry.Hostname)
	if err != nil {
		return fmt.Errorf("DNS lookup failed: %w", err)
	}

	// Extract IPv4 addresses and sort for consistent comparison
	var ipv4s []net.IP
	for _, ip := range ips {
		if ipv4 := ip.IP.To4(); ipv4 != nil {
			ipv4s = append(ipv4s, ipv4)
		}
	}

	// Sort IPs for consistent comparison
	sort.Slice(ipv4s, func(i, j int) bool {
		return ipv4s[i].String() < ipv4s[j].String()
	})

	d.mu.Lock()
	entry.LastCheck = time.Now()

	// Check if IPs have changed
	if d.ipsEqual(entry.IPs, ipv4s) {
		d.mu.Unlock()
		return nil // No change needed
	}

	oldCount := len(entry.IPs)
	entry.IPs = ipv4s
	d.mu.Unlock()

	logger.Info("dns", "Hostname IPs changed",
		"hostname", entry.Hostname,
		"old_count", oldCount,
		"new_count", len(ipv4s),
		"ips", d.formatIPs(ipv4s))

	// Update nftables set
	return d.updateNFTablesSet(entry, ipv4s)
}

func (d *DNSManager) updateNFTablesSet(entry *HostEntry, ips []net.IP) error {
	set := &nftables.Set{Name: entry.SetName, Table: d.table}

	// Clear existing elements
	d.conn.FlushSet(set)

	// Add new elements
	if len(ips) > 0 {
		elements := make([]nftables.SetElement, len(ips))
		for i, ip := range ips {
			elements[i] = nftables.SetElement{Key: ip}
		}

		d.conn.SetAddElements(set, elements)
	}

	return nil
}

func (d *DNSManager) ipsEqual(a, b []net.IP) bool {
	if len(a) != len(b) {
		return false
	}

	// Both slices should be sorted for accurate comparison
	for i := range a {
		if !a[i].Equal(b[i]) {
			return false
		}
	}

	return true
}

func (d *DNSManager) formatIPs(ips []net.IP) []string {
	result := make([]string, len(ips))
	for i, ip := range ips {
		result[i] = ip.String()
	}
	return result
}

func (d *DNSManager) validateHostname(hostname string) error {
	if len(hostname) == 0 || len(hostname) > 253 {
		return fmt.Errorf("hostname length must be 1-253 characters")
	}

	// Basic hostname validation
	if strings.HasPrefix(hostname, ".") || strings.HasSuffix(hostname, ".") {
		return fmt.Errorf("hostname cannot start or end with a dot")
	}

	// Check for invalid characters
	for _, char := range hostname {
		if !((char >= 'a' && char <= 'z') ||
			(char >= 'A' && char <= 'Z') ||
			(char >= '0' && char <= '9') ||
			char == '-' || char == '.') {
			return fmt.Errorf("hostname contains invalid character: %c", char)
		}
	}

	return nil
}

func (d *DNSManager) generateSetName(hostname string) string {
	// Replace dots and other special characters with underscores
	setName := strings.ReplaceAll(hostname, ".", "_")
	setName = strings.ReplaceAll(setName, "-", "_")

	// Ensure it starts with the prefix
	return SetNamePrefix + setName
}

// GetHostnames returns a copy of all managed hostnames
func (d *DNSManager) GetHostnames() map[string]*HostEntry {
	d.mu.RLock()
	defer d.mu.RUnlock()

	result := make(map[string]*HostEntry, len(d.hostnames))
	for k, v := range d.hostnames {
		// Create a copy to avoid race conditions
		entryCopy := &HostEntry{
			Hostname:    v.Hostname,
			IPs:         make([]net.IP, len(v.IPs)),
			SetName:     v.SetName,
			LastCheck:   v.LastCheck,
			LastSuccess: v.LastSuccess,
			ErrorCount:  v.ErrorCount,
			LastError:   v.LastError,
		}
		copy(entryCopy.IPs, v.IPs)
		result[k] = entryCopy
	}

	return result
}

// GetHostnameByName returns a specific hostname entry
func (d *DNSManager) GetHostnameByName(hostname string) (*HostEntry, bool) {
	d.mu.RLock()
	defer d.mu.RUnlock()

	entry, exists := d.hostnames[hostname]
	if !exists {
		return nil, false
	}

	// Return a copy
	entryCopy := &HostEntry{
		Hostname:    entry.Hostname,
		IPs:         make([]net.IP, len(entry.IPs)),
		SetName:     entry.SetName,
		LastCheck:   entry.LastCheck,
		LastSuccess: entry.LastSuccess,
		ErrorCount:  entry.ErrorCount,
		LastError:   entry.LastError,
	}
	copy(entryCopy.IPs, entry.IPs)

	return entryCopy, true
}

// GetStats returns statistics about DNS resolution
func (d *DNSManager) GetStats() *DNSStats {
	d.mu.RLock()
	defer d.mu.RUnlock()

	stats := &DNSStats{
		TotalHostnames: len(d.hostnames),
	}

	var totalResolveTime time.Duration
	var resolveCount int

	for _, entry := range d.hostnames {
		if !entry.LastSuccess.IsZero() {
			stats.SuccessfulChecks++
		}
		if entry.ErrorCount > 0 {
			stats.FailedChecks += int64(entry.ErrorCount)
		}
		if !entry.LastCheck.IsZero() {
			if stats.LastUpdateTime.Before(entry.LastCheck) {
				stats.LastUpdateTime = entry.LastCheck
			}
			resolveCount++
		}
	}

	if resolveCount > 0 {
		stats.AverageResolveTime = totalResolveTime / time.Duration(resolveCount)
	}

	return stats
}

// ForceUpdate immediately updates all hostnames
func (d *DNSManager) ForceUpdate() error {
	logger.Info("dns", "Forcing DNS update for all hostnames")
	go d.updateAllHostnames()
	return nil
}

// Stop gracefully shuts down the DNS manager
func (d *DNSManager) Stop() error {
	logger.Info("dns", "Stopping DNS manager")

	d.cancel()  // Cancel context to stop background goroutines
	d.wg.Wait() // Wait for all goroutines to finish

	logger.Info("dns", "DNS manager stopped")
	return nil
}
// internal/firewall/nftables.go
package firewall

import (
	"fmt"
	"net"
	"os"
	"strings"
	"sync"
	"time"

	"qff/internal/config"
	"qff/internal/logger"

	"github.com/google/nftables"
	"github.com/google/nftables/expr"
)

// RuleKey uniquely identifies a port rule
type RuleKey struct {
	Port      int
	Protocol  string
	Direction string
	Action    string
}

// RuleTracker stores references to nftables rules
type RuleTracker struct {
	Rule    *nftables.Rule
	Key     RuleKey
	AddedAt time.Time
}

// Simplified manager types for this implementation
type DNSManager struct {
	conn      *nftables.Conn
	table     *nftables.Table
	hostnames map[string]*HostEntry
	mu        sync.RWMutex
}

type HostEntry struct {
	Hostname  string
	IPs       []net.IP
	SetName   string
	LastCheck time.Time
}

type RateLimitManager struct {
	conn   *nftables.Conn
	table  *nftables.Table
	config *config.RateLimitConfig
}

type BOGONManager struct {
	config *config.SecurityConfig
	conn   *nftables.Conn
	table  *nftables.Table
}

type NFTManager struct {
	conn        *nftables.Conn
	config      *config.Config
	table       *nftables.Table
	dnsManager  *DNSManager
	rateLimiter *RateLimitManager
	bogonMgr    *BOGONManager

	// Rule tracking
	trackedRules map[RuleKey]*RuleTracker
	rulesMutex   sync.RWMutex
}

type FirewallState struct {
	Rules []byte `json:"rules"`
	Sets  []byte `json:"sets"`
}

// Simplified constructors
func NewDNSManager(conn *nftables.Conn, table *nftables.Table) *DNSManager {
	return &DNSManager{
		conn:      conn,
		table:     table,
		hostnames: make(map[string]*HostEntry),
	}
}

func NewRateLimitManager(conn *nftables.Conn, table *nftables.Table, cfg *config.RateLimitConfig) *RateLimitManager {
	return &RateLimitManager{
		conn:   conn,
		table:  table,
		config: cfg,
	}
}

func NewBOGONManager(cfg *config.SecurityConfig, conn *nftables.Conn, table *nftables.Table) *BOGONManager {
	return &BOGONManager{
		config: cfg,
		conn:   conn,
		table:  table,
	}
}

func NewNFTManager(cfg *config.Config) *NFTManager {
	conn := &nftables.Conn{}
	table := &nftables.Table{
		Name:   "qff",
		Family: nftables.TableFamilyINet,
	}

	mgr := &NFTManager{
		conn:         conn,
		config:       cfg,
		table:        table,
		trackedRules: make(map[RuleKey]*RuleTracker),
	}

	mgr.dnsManager = NewDNSManager(conn, table)
	mgr.rateLimiter = NewRateLimitManager(conn, table, &cfg.RateLimit)
	mgr.bogonMgr = NewBOGONManager(&cfg.Security, conn, table)

	return mgr
}

// Simplified methods for the sub-managers
func (d *DNSManager) Initialize() error {
	logger.Info("dns", "Initializing DNS manager")
	return nil
}

func (d *DNSManager) AddHostname(hostname, setType string) error {
	logger.Info("dns", "Adding hostname", "hostname", hostname)
	return nil
}

func (d *DNSManager) GetHostnames() map[string]*HostEntry {
	d.mu.RLock()
	defer d.mu.RUnlock()
	return d.hostnames
}

func (r *RateLimitManager) Initialize() error {
	if !r.config.EnableRateLimit {
		return nil
	}
	logger.Info("ratelimit", "Initializing rate limiting")
	return nil
}

func (r *RateLimitManager) AddRateLimitRules(inputChain *nftables.Chain) error {
	if !r.config.EnableRateLimit {
		return nil
	}
	logger.Info("ratelimit", "Adding rate limit rules")
	return nil
}

func (b *BOGONManager) Initialize() error {
	if !b.config.EnableBogonFilter {
		return nil
	}
	logger.Info("bogon", "Initializing BOGON filtering")
	return nil
}

func (b *BOGONManager) AddBOGONRules(inputChain *nftables.Chain) error {
	if !b.config.EnableBogonFilter {
		return nil
	}
	logger.Info("bogon", "Adding BOGON rules")
	return nil
}

// Utility functions
func CheckNFTablesAvailable() error {
	// Try to create a test connection
	conn := &nftables.Conn{}

	// Try to list existing tables - this will fail if nftables is not available
	_, err := conn.ListTables()
	if err != nil {
		return fmt.Errorf("nftables is not available or not installed. Please install nftables first:\n"+
			"  Ubuntu/Debian: sudo apt install nftables\n"+
			"  RHEL/CentOS:   sudo yum install nftables\n"+
			"  Arch Linux:    sudo pacman -S nftables\n"+
			"Error: %v", err)
	}

	return nil
}

// NFTManager methods
func (n *NFTManager) AddPortRule(port int, protocol string, direction string, action string) error {
	var chain *nftables.Chain
	var protocolNum byte

	// Determine protocol number
	switch strings.ToLower(protocol) {
	case "tcp":
		protocolNum = 6
	case "udp":
		protocolNum = 17
	default:
		return fmt.Errorf("unsupported protocol: %s", protocol)
	}

	// Determine chain
	switch strings.ToLower(direction) {
	case "input", "in":
		chain = &nftables.Chain{Name: "input", Table: n.table}
	case "output", "out":
		chain = &nftables.Chain{Name: "output", Table: n.table}
	default:
		return fmt.Errorf("unsupported direction: %s", direction)
	}

	// Determine verdict
	var verdict expr.VerdictKind
	switch strings.ToLower(action) {
	case "accept", "allow":
		verdict = expr.VerdictAccept
	case "drop", "deny", "block":
		verdict = expr.VerdictDrop
	case "reject":
		verdict = expr.VerdictReturn
	default:
		return fmt.Errorf("unsupported action: %s", action)
	}

	// Create the rule
	rule := &nftables.Rule{
		Table: n.table,
		Chain: chain,
		Exprs: []expr.Any{
			&expr.Payload{DestRegister: 1, Base: expr.PayloadBaseNetworkHeader, Offset: 9, Len: 1},
			&expr.Cmp{Op: expr.CmpOpEq, Register: 1, Data: []byte{protocolNum}},
			&expr.Payload{DestRegister: 1, Base: expr.PayloadBaseTransportHeader, Offset: 2, Len: 2},
			&expr.Cmp{Op: expr.CmpOpEq, Register: 1, Data: []byte{byte(port >> 8), byte(port)}},
			&expr.Verdict{Kind: verdict},
		},
	}

	// Add the rule
	n.conn.AddRule(rule)

	if err := n.conn.Flush(); err != nil {
		return fmt.Errorf("failed to flush nftables: %w", err)
	}

	// Track the rule
	key := RuleKey{
		Port:      port,
		Protocol:  strings.ToLower(protocol),
		Direction: strings.ToLower(direction),
		Action:    strings.ToLower(action),
	}

	n.rulesMutex.Lock()
	n.trackedRules[key] = &RuleTracker{
		Rule:    rule,
		Key:     key,
		AddedAt: time.Now(),
	}
	n.rulesMutex.Unlock()

	logger.Info("firewall", "Added port rule", "port", port, "protocol", protocol, "direction", direction, "action", action)
	return nil
}

func (n *NFTManager) RemovePortRule(port int, protocol string, direction string) error {
	// Normalize inputs
	protocol = strings.ToLower(protocol)
	direction = strings.ToLower(direction)

	n.rulesMutex.Lock()
	defer n.rulesMutex.Unlock()

	// Find all rules matching port, protocol, and direction (regardless of action)
	var rulesToRemove []*RuleTracker
	var keysToRemove []RuleKey

	for key, tracker := range n.trackedRules {
		if key.Port == port && key.Protocol == protocol && key.Direction == direction {
			rulesToRemove = append(rulesToRemove, tracker)
			keysToRemove = append(keysToRemove, key)
		}
	}

	if len(rulesToRemove) == 0 {
		return fmt.Errorf("no matching rule found for port %d/%s %s", port, protocol, direction)
	}

	// Remove rules from nftables
	for _, tracker := range rulesToRemove {
		n.conn.DelRule(tracker.Rule)
	}

	if err := n.conn.Flush(); err != nil {
		return fmt.Errorf("failed to flush nftables: %w", err)
	}

	// Remove from tracking
	for _, key := range keysToRemove {
		delete(n.trackedRules, key)
	}

	logger.Info("firewall", "Removed port rules", "port", port, "protocol", protocol, "direction", direction, "count", len(rulesToRemove))
	return nil
}

func (n *NFTManager) ListPortRules() map[string]interface{} {
	n.rulesMutex.RLock()
	defer n.rulesMutex.RUnlock()

	// Get config-based rules
	configRules := map[string]interface{}{
		"tcp_in":   n.config.Ports.TCPIn,
		"tcp_out":  n.config.Ports.TCPOut,
		"udp_in":   n.config.Ports.UDPIn,
		"udp_out":  n.config.Ports.UDPOut,
		"tcp_deny": n.config.Ports.TCPDeny,
		"udp_deny": n.config.Ports.UDPDeny,
	}

	// Add dynamically tracked rules
	dynamicRules := make(map[string]interface{})
	for key, tracker := range n.trackedRules {
		ruleID := fmt.Sprintf("%s_%d_%s_%s", key.Protocol, key.Port, key.Direction, key.Action)
		dynamicRules[ruleID] = map[string]interface{}{
			"port":      key.Port,
			"protocol":  key.Protocol,
			"direction": key.Direction,
			"action":    key.Action,
			"added_at":  tracker.AddedAt,
		}
	}

	return map[string]interface{}{
		"config_rules":  configRules,
		"dynamic_rules": dynamicRules,
		"total_tracked": len(n.trackedRules),
	}
}

// RemoveAllPortRules removes all tracked port rules
func (n *NFTManager) RemoveAllPortRules() error {
	n.rulesMutex.Lock()
	defer n.rulesMutex.Unlock()

	for _, tracker := range n.trackedRules {
		n.conn.DelRule(tracker.Rule)
	}

	if err := n.conn.Flush(); err != nil {
		return fmt.Errorf("failed to flush nftables: %w", err)
	}

	// Clear tracking
	n.trackedRules = make(map[RuleKey]*RuleTracker)

	logger.Info("firewall", "Removed all tracked port rules")
	return nil
}

// GetRuleStats returns statistics about tracked rules
func (n *NFTManager) GetRuleStats() map[string]interface{} {
	n.rulesMutex.RLock()
	defer n.rulesMutex.RUnlock()

	stats := map[string]interface{}{
		"total_tracked": len(n.trackedRules),
	}

	// Count by protocol
	protocolCount := make(map[string]int)
	directionCount := make(map[string]int)
	actionCount := make(map[string]int)

	for key := range n.trackedRules {
		protocolCount[key.Protocol]++
		directionCount[key.Direction]++
		actionCount[key.Action]++
	}

	stats["by_protocol"] = protocolCount
	stats["by_direction"] = directionCount
	stats["by_action"] = actionCount

	return stats
}

// UpdatePortRuleAction changes the action of an existing rule
func (n *NFTManager) UpdatePortRuleAction(port int, protocol string, direction string, newAction string) error {
	// Remove the old rule
	if err := n.RemovePortRule(port, protocol, direction); err != nil {
		return fmt.Errorf("failed to remove old rule: %w", err)
	}

	// Add the new rule with updated action
	if err := n.AddPortRule(port, protocol, direction, newAction); err != nil {
		return fmt.Errorf("failed to add updated rule: %w", err)
	}

	return nil
}

func (n *NFTManager) Initialize() error {
	logger.Info("firewall", "Initializing nftables")

	n.conn.AddTable(n.table)

	if err := n.setupChains(); err != nil {
		return fmt.Errorf("failed to setup chains: %w", err)
	}

	if err := n.setupSets(); err != nil {
		return fmt.Errorf("failed to setup sets: %w", err)
	}

	if err := n.setupRules(); err != nil {
		return fmt.Errorf("failed to setup rules: %w", err)
	}

	// Initialize sub-managers
	if err := n.dnsManager.Initialize(); err != nil {
		logger.Error("firewall", "DNS manager initialization failed", "error", err.Error())
	}

	if err := n.rateLimiter.Initialize(); err != nil {
		logger.Error("firewall", "Rate limiter initialization failed", "error", err.Error())
	}

	if err := n.bogonMgr.Initialize(); err != nil {
		logger.Error("firewall", "BOGON manager initialization failed", "error", err.Error())
	}

	if err := n.conn.Flush(); err != nil {
		return fmt.Errorf("failed to flush nftables: %w", err)
	}

	logger.Info("firewall", "nftables initialized successfully")
	return nil
}

func (n *NFTManager) setupChains() error {
	chains := []struct {
		name     string
		hook     *nftables.ChainHook
		priority *nftables.ChainPriority
		policy   nftables.ChainPolicy
	}{
		{"input", nftables.ChainHookInput, nftables.ChainPriorityFilter, n.getDefaultPolicy()},
		{"output", nftables.ChainHookOutput, nftables.ChainPriorityFilter, nftables.ChainPolicyAccept},
		{"forward", nftables.ChainHookForward, nftables.ChainPriorityFilter, nftables.ChainPolicyDrop},
	}

	for _, c := range chains {
		n.conn.AddChain(&nftables.Chain{
			Name:     c.name,
			Table:    n.table,
			Type:     nftables.ChainTypeFilter,
			Hooknum:  c.hook,
			Priority: c.priority,
			Policy:   &c.policy,
		})
	}

	return nil
}

func (n *NFTManager) getDefaultPolicy() nftables.ChainPolicy {
	if n.config.Firewall.DefaultPolicy == "accept" {
		return nftables.ChainPolicyAccept
	}
	return nftables.ChainPolicyDrop
}

func (n *NFTManager) setupSets() error {
	sets := []struct {
		name    string
		keyType nftables.SetDatatype
	}{
		{"whitelist_ips", nftables.TypeIPAddr},
		{"blacklist_ips", nftables.TypeIPAddr},
		{"temp_block_ips", nftables.TypeIPAddr},
	}

	for _, s := range sets {
		n.conn.AddSet(&nftables.Set{
			Name:    s.name,
			Table:   n.table,
			KeyType: s.keyType,
		}, []nftables.SetElement{})
	}

	return nil
}

func (n *NFTManager) setupRules() error {
	inputChain := &nftables.Chain{Name: "input", Table: n.table}

	// Allow loopback
	n.conn.AddRule(&nftables.Rule{
		Table: n.table,
		Chain: inputChain,
		Exprs: []expr.Any{
			&expr.Meta{Key: expr.MetaKeyIIFNAME, Register: 1},
			&expr.Cmp{Op: expr.CmpOpEq, Register: 1, Data: []byte("lo\x00")},
			&expr.Verdict{Kind: expr.VerdictAccept},
		},
	})

	// Whitelist rule
	n.conn.AddRule(&nftables.Rule{
		Table: n.table,
		Chain: inputChain,
		Exprs: []expr.Any{
			&expr.Payload{DestRegister: 1, Base: expr.PayloadBaseNetworkHeader, Offset: 12, Len: 4},
			&expr.Lookup{SourceRegister: 1, SetName: "whitelist_ips"},
			&expr.Verdict{Kind: expr.VerdictAccept},
		},
	})

	// Blacklist rule
	n.conn.AddRule(&nftables.Rule{
		Table: n.table,
		Chain: inputChain,
		Exprs: []expr.Any{
			&expr.Payload{DestRegister: 1, Base: expr.PayloadBaseNetworkHeader, Offset: 12, Len: 4},
			&expr.Lookup{SourceRegister: 1, SetName: "blacklist_ips"},
			&expr.Verdict{Kind: expr.VerdictDrop},
		},
	})

	// Setup port rules from config (these won't be tracked for removal)
	if err := n.setupConfigPortRules(); err != nil {
		return err
	}

	// Add rate limiting rules
	if err := n.rateLimiter.AddRateLimitRules(inputChain); err != nil {
		return err
	}

	// Add BOGON filtering rules
	if err := n.bogonMgr.AddBOGONRules(inputChain); err != nil {
		return err
	}

	return nil
}

func (n *NFTManager) setupConfigPortRules() error {
	inputChain := &nftables.Chain{Name: "input", Table: n.table}
	outputChain := &nftables.Chain{Name: "output", Table: n.table}

	// TCP incoming ports (allow) - config rules, not tracked
	for _, port := range n.config.Ports.TCPIn {
		n.conn.AddRule(&nftables.Rule{
			Table: n.table,
			Chain: inputChain,
			Exprs: []expr.Any{
				&expr.Payload{DestRegister: 1, Base: expr.PayloadBaseNetworkHeader, Offset: 9, Len: 1},
				&expr.Cmp{Op: expr.CmpOpEq, Register: 1, Data: []byte{6}}, // TCP protocol
				&expr.Payload{DestRegister: 1, Base: expr.PayloadBaseTransportHeader, Offset: 2, Len: 2},
				&expr.Cmp{Op: expr.CmpOpEq, Register: 1, Data: []byte{byte(port >> 8), byte(port)}},
				&expr.Verdict{Kind: expr.VerdictAccept},
			},
		})
		logger.Info("firewall", "Added TCP input rule from config", "port", port)
	}

	// UDP incoming ports (allow)
	for _, port := range n.config.Ports.UDPIn {
		n.conn.AddRule(&nftables.Rule{
			Table: n.table,
			Chain: inputChain,
			Exprs: []expr.Any{
				&expr.Payload{DestRegister: 1, Base: expr.PayloadBaseNetworkHeader, Offset: 9, Len: 1},
				&expr.Cmp{Op: expr.CmpOpEq, Register: 1, Data: []byte{17}}, // UDP protocol
				&expr.Payload{DestRegister: 1, Base: expr.PayloadBaseTransportHeader, Offset: 2, Len: 2},
				&expr.Cmp{Op: expr.CmpOpEq, Register: 1, Data: []byte{byte(port >> 8), byte(port)}},
				&expr.Verdict{Kind: expr.VerdictAccept},
			},
		})
		logger.Info("firewall", "Added UDP input rule from config", "port", port)
	}

	// TCP outgoing ports (allow)
	for _, port := range n.config.Ports.TCPOut {
		n.conn.AddRule(&nftables.Rule{
			Table: n.table,
			Chain: outputChain,
			Exprs: []expr.Any{
				&expr.Payload{DestRegister: 1, Base: expr.PayloadBaseNetworkHeader, Offset: 9, Len: 1},
				&expr.Cmp{Op: expr.CmpOpEq, Register: 1, Data: []byte{6}}, // TCP protocol
				&expr.Payload{DestRegister: 1, Base: expr.PayloadBaseTransportHeader, Offset: 2, Len: 2},
				&expr.Cmp{Op: expr.CmpOpEq, Register: 1, Data: []byte{byte(port >> 8), byte(port)}},
				&expr.Verdict{Kind: expr.VerdictAccept},
			},
		})
		logger.Info("firewall", "Added TCP output rule from config", "port", port)
	}

	// UDP outgoing ports (allow)
	for _, port := range n.config.Ports.UDPOut {
		n.conn.AddRule(&nftables.Rule{
			Table: n.table,
			Chain: outputChain,
			Exprs: []expr.Any{
				&expr.Payload{DestRegister: 1, Base: expr.PayloadBaseNetworkHeader, Offset: 9, Len: 1},
				&expr.Cmp{Op: expr.CmpOpEq, Register: 1, Data: []byte{17}}, // UDP protocol
				&expr.Payload{DestRegister: 1, Base: expr.PayloadBaseTransportHeader, Offset: 2, Len: 2},
				&expr.Cmp{Op: expr.CmpOpEq, Register: 1, Data: []byte{byte(port >> 8), byte(port)}},
				&expr.Verdict{Kind: expr.VerdictAccept},
			},
		})
		logger.Info("firewall", "Added UDP output rule from config", "port", port)
	}

	// TCP deny ports (explicit block)
	for _, port := range n.config.Ports.TCPDeny {
		n.conn.AddRule(&nftables.Rule{
			Table: n.table,
			Chain: inputChain,
			Exprs: []expr.Any{
				&expr.Payload{DestRegister: 1, Base: expr.PayloadBaseNetworkHeader, Offset: 9, Len: 1},
				&expr.Cmp{Op: expr.CmpOpEq, Register: 1, Data: []byte{6}}, // TCP protocol
				&expr.Payload{DestRegister: 1, Base: expr.PayloadBaseTransportHeader, Offset: 2, Len: 2},
				&expr.Cmp{Op: expr.CmpOpEq, Register: 1, Data: []byte{byte(port >> 8), byte(port)}},
				&expr.Verdict{Kind: expr.VerdictDrop},
			},
		})
		logger.Info("firewall", "Added TCP deny rule from config", "port", port)
	}

	// UDP deny ports (explicit block)
	for _, port := range n.config.Ports.UDPDeny {
		n.conn.AddRule(&nftables.Rule{
			Table: n.table,
			Chain: inputChain,
			Exprs: []expr.Any{
				&expr.Payload{DestRegister: 1, Base: expr.PayloadBaseNetworkHeader, Offset: 9, Len: 1},
				&expr.Cmp{Op: expr.CmpOpEq, Register: 1, Data: []byte{17}}, // UDP protocol
				&expr.Payload{DestRegister: 1, Base: expr.PayloadBaseTransportHeader, Offset: 2, Len: 2},
				&expr.Cmp{Op: expr.CmpOpEq, Register: 1, Data: []byte{byte(port >> 8), byte(port)}},
				&expr.Verdict{Kind: expr.VerdictDrop},
			},
		})
		logger.Info("firewall", "Added UDP deny rule from config", "port", port)
	}

	return nil
}

// Additional helper methods...
func (n *NFTManager) AddWhitelistIP(ip net.IP) error {
	logger.Info("firewall", "Adding IP to whitelist", "ip", ip.String())
	set := &nftables.Set{Name: "whitelist_ips", Table: n.table}
	n.conn.SetAddElements(set, []nftables.SetElement{{Key: ip.To4()}})
	return n.conn.Flush()
}

func (n *NFTManager) RemoveWhitelistIP(ip net.IP) error {
	logger.Info("firewall", "Removing IP from whitelist", "ip", ip.String())
	set := &nftables.Set{Name: "whitelist_ips", Table: n.table}
	n.conn.SetDeleteElements(set, []nftables.SetElement{{Key: ip.To4()}})
	return n.conn.Flush()
}

func (n *NFTManager) AddBlacklistIP(ip net.IP) error {
	logger.Info("firewall", "Adding IP to blacklist", "ip", ip.String())
	set := &nftables.Set{Name: "blacklist_ips", Table: n.table}
	n.conn.SetAddElements(set, []nftables.SetElement{{Key: ip.To4()}})
	return n.conn.Flush()
}

func (n *NFTManager) RemoveBlacklistIP(ip net.IP) error {
	logger.Info("firewall", "Removing IP from blacklist", "ip", ip.String())
	set := &nftables.Set{Name: "blacklist_ips", Table: n.table}
	n.conn.SetDeleteElements(set, []nftables.SetElement{{Key: ip.To4()}})
	return n.conn.Flush()
}

func (n *NFTManager) WhitelistCurrentUser() error {
	// Get the IP of the user who started the application
	sshClient := os.Getenv("SSH_CLIENT")
	if sshClient != "" {
		parts := strings.Fields(sshClient)
		if len(parts) > 0 {
			ip := net.ParseIP(parts[0])
			if ip != nil && !ip.IsLoopback() {
				logger.Info("firewall", "Auto-whitelisting SSH client IP", "ip", ip.String())
				return n.AddWhitelistIP(ip)
			}
		}
	}

	sshConn := os.Getenv("SSH_CONNECTION")
	if sshConn != "" {
		parts := strings.Fields(sshConn)
		if len(parts) >= 4 {
			ip := net.ParseIP(parts[0])
			if ip != nil && !ip.IsLoopback() {
				logger.Info("firewall", "Auto-whitelisting SSH connection IP", "ip", ip.String())
				return n.AddWhitelistIP(ip)
			}
		}
	}

	logger.Info("firewall", "No remote connection detected, skipping auto-whitelist")
	return nil
}

func (n *NFTManager) Reload() error {
	logger.Info("firewall", "Reloading nftables configuration")
	n.conn.FlushTable(n.table)

	// Clear tracked rules on reload
	n.rulesMutex.Lock()
	n.trackedRules = make(map[RuleKey]*RuleTracker)
	n.rulesMutex.Unlock()

	return n.Initialize()
}

func (n *NFTManager) GetStats() (map[string]interface{}, error) {
	stats := make(map[string]interface{})
	stats["table_name"] = n.table.Name
	stats["dns_hosts"] = len(n.dnsManager.GetHostnames())
	stats["rule_stats"] = n.GetRuleStats()
	return stats, nil
}

// Include other methods like DNS, blocklist management etc...
func (n *NFTManager) AddDynamicHost(hostname string) error {
	return n.dnsManager.AddHostname(hostname, "whitelist")
}

func (n *NFTManager) GetDynamicHosts() map[string]interface{} {
	hosts := n.dnsManager.GetHostnames()
	result := make(map[string]interface{})
	for k, v := range hosts {
		result[k] = map[string]interface{}{
			"ips":        v.IPs,
			"set_name":   v.SetName,
			"last_check": v.LastCheck,
		}
	}
	return result
}

func (n *NFTManager) RemoveBlocklistSet(setName string) error {
	logger.Info("firewall", "Removing blocklist set", "set", setName)
	return nil
}

func (n *NFTManager) AddBlocklistSet(setName string, ips []net.IP) error {
	logger.Info("firewall", "Adding blocklist set", "set", setName, "count", len(ips))
	return nil
}

func (n *NFTManager) BackupCurrentState() (*FirewallState, error) {
	state := &FirewallState{
		Rules: []byte("backup_rules"),
		Sets:  []byte("backup_sets"),
	}
	return state, nil
}

func (n *NFTManager) RestoreState(state *FirewallState) error {
	logger.Info("firewall", "Restoring firewall state")
	return n.Initialize()
}
// internal/firewall/ratelimit/ratelimit.go
// internal/firewall/ratelimit/ratelimit.go
package ratelimit

import (
	"context"
	"fmt"
	"net"
	"sync"
	"time"

	"qff/internal/config"
	"qff/internal/logger"

	"github.com/google/nftables"
)

const (
	// Default configurations
	DefaultGlobalConnLimit = 1000
	DefaultPerIPConnLimit  = 100
	DefaultBurstSize       = 50
	DefaultTimeWindow      = time.Second
	DefaultCleanupInterval = 5 * time.Minute
	DefaultSetTimeout      = time.Hour

	// nftables set names
	RateLimitIPsSet       = "rate_limit_ips"
	RateLimitBannedSet    = "rate_limit_banned"
	RateLimitWhitelistSet = "rate_limit_whitelist"

	// Chain priorities
	RateLimitChainPriority = -150
)

// RateLimitManager manages rate limiting
type RateLimitManager struct {
	conn   *nftables.Conn
	table  *nftables.Table
	config *Config

	stats *RateLimitStats
	mu    sync.RWMutex

	ctx    context.Context
	cancel context.CancelFunc
	wg     sync.WaitGroup
}

// Config holds rate limiting configuration
type Config struct {
	EnableRateLimit    bool          `json:"enable_rate_limit"`
	GlobalConnLimit    int           `json:"global_conn_limit"`
	GlobalBurstSize    int           `json:"global_burst_size"`
	PerIPConnLimit     int           `json:"per_ip_conn_limit"`
	PerIPBurstSize     int           `json:"per_ip_burst_size"`
	PerIPTimeWindow    time.Duration `json:"per_ip_time_window"`
	HTTPRequestLimit   int           `json:"http_request_limit"`
	HTTPBurstSize      int           `json:"http_burst_size"`
	SSHConnLimit       int           `json:"ssh_conn_limit"`
	SSHBurstSize       int           `json:"ssh_burst_size"`
	EnableAutoBan      bool          `json:"enable_auto_ban"`
	BanThreshold       int           `json:"ban_threshold"`
	BanDuration        time.Duration `json:"ban_duration"`
	CleanupInterval    time.Duration `json:"cleanup_interval"`
	SetTimeout         time.Duration `json:"set_timeout"`
	WhitelistedIPs     []string      `json:"whitelisted_ips"`
	WhitelistedSubnets []string      `json:"whitelisted_subnets"`
}

// RateLimitStats tracks statistics
type RateLimitStats struct {
	TotalConnections int64     `json:"total_connections"`
	RateLimitedConns int64     `json:"rate_limited_connections"`
	BannedIPs        int       `json:"banned_ips"`
	WhitelistedIPs   int       `json:"whitelisted_ips"`
	HTTPRequests     int64     `json:"http_requests"`
	HTTPRateLimited  int64     `json:"http_rate_limited"`
	SSHConnections   int64     `json:"ssh_connections"`
	SSHRateLimited   int64     `json:"ssh_rate_limited"`
	LastCleanup      time.Time `json:"last_cleanup"`
	LastStatsUpdate  time.Time `json:"last_stats_update"`
}

// RuleType represents rule type
type RuleType int

const (
	RuleTypeGlobal RuleType = iota
	RuleTypePerIP
	RuleTypeHTTP
	RuleTypeSSH
	RuleTypeCustom
)

// RateLimitRule represents a rate limit rule
type RateLimitRule struct {
	Type       RuleType      `json:"type"`
	Name       string        `json:"name"`
	Rate       int           `json:"rate"`
	Burst      int           `json:"burst"`
	TimeWindow time.Duration `json:"time_window"`
	Protocol   string        `json:"protocol,omitempty"`
	Port       int           `json:"port,omitempty"`
	Enabled    bool          `json:"enabled"`
}

// NewRateLimitManager creates a new manager
func NewRateLimitManager(conn *nftables.Conn, table *nftables.Table, cfg *config.RateLimitConfig) *RateLimitManager {
	ctx, cancel := context.WithCancel(context.Background())
	return &RateLimitManager{
		conn:   conn,
		table:  table,
		config: convertConfig(cfg),
		stats:  &RateLimitStats{},
		ctx:    ctx,
		cancel: cancel,
	}
}

func convertConfig(oldCfg *config.RateLimitConfig) *Config {
	if oldCfg == nil {
		return getDefaultConfig()
	}
	return &Config{
		EnableRateLimit:    oldCfg.EnableRateLimit,
		GlobalConnLimit:    getIntOrDefault(oldCfg.GlobalConnLimit, DefaultGlobalConnLimit),
		GlobalBurstSize:    DefaultBurstSize,
		PerIPConnLimit:     DefaultPerIPConnLimit,
		PerIPBurstSize:     DefaultBurstSize,
		PerIPTimeWindow:    DefaultTimeWindow,
		HTTPRequestLimit:   500,
		HTTPBurstSize:      100,
		SSHConnLimit:       10,
		SSHBurstSize:       5,
		EnableAutoBan:      true,
		BanThreshold:       5,
		BanDuration:        24 * time.Hour,
		CleanupInterval:    DefaultCleanupInterval,
		SetTimeout:         DefaultSetTimeout,
		WhitelistedIPs:     []string{},
		WhitelistedSubnets: []string{},
	}
}

func getDefaultConfig() *Config {
	return &Config{
		EnableRateLimit:    false,
		GlobalConnLimit:    DefaultGlobalConnLimit,
		GlobalBurstSize:    DefaultBurstSize,
		PerIPConnLimit:     DefaultPerIPConnLimit,
		PerIPBurstSize:     DefaultBurstSize,
		PerIPTimeWindow:    DefaultTimeWindow,
		HTTPRequestLimit:   500,
		HTTPBurstSize:      100,
		SSHConnLimit:       10,
		SSHBurstSize:       5,
		EnableAutoBan:      true,
		BanThreshold:       5,
		BanDuration:        24 * time.Hour,
		CleanupInterval:    DefaultCleanupInterval,
		SetTimeout:         DefaultSetTimeout,
		WhitelistedIPs:     []string{},
		WhitelistedSubnets: []string{},
	}
}

func getIntOrDefault(value, defaultValue int) int {
	if value <= 0 {
		return defaultValue
	}
	return value
}

// Initialize creates nftables sets and starts background tasks
func (r *RateLimitManager) Initialize() error {
	if !r.config.EnableRateLimit {
		logger.Info("ratelimit", "Rate limiting disabled")
		return nil
	}

	logger.Info("ratelimit", "Initializing rate limiting",
		"global_limit", r.config.GlobalConnLimit,
		"per_ip_limit", r.config.PerIPConnLimit,
		"auto_ban", r.config.EnableAutoBan)

	if err := r.createNFTablesSets(); err != nil {
		return fmt.Errorf("failed to create sets: %w", err)
	}

	if err := r.initializeWhitelistedIPs(); err != nil {
		logger.Warn("ratelimit", "Failed to init whitelisted IPs", "error", err.Error())
	}

	r.startBackgroundTasks()
	return nil
}

func (r *RateLimitManager) createNFTablesSets() error {
	sets := []struct {
		name     string
		keyType  nftables.SetDatatype
		interval bool
		timeout  time.Duration
		dynamic  bool
	}{
		{
			name:     RateLimitIPsSet,
			keyType:  nftables.TypeIPAddr,
			interval: true,
			timeout:  r.config.SetTimeout,
			dynamic:  true,
		},
		{
			name:     RateLimitBannedSet,
			keyType:  nftables.TypeIPAddr,
			interval: true,
			timeout:  r.config.BanDuration,
			dynamic:  true,
		},
		{
			name:     RateLimitWhitelistSet,
			keyType:  nftables.TypeIPAddr,
			interval: true,
			timeout:  0, // permanent
			dynamic:  false,
		},
	}

	for _, cfg := range sets {
		set := &nftables.Set{
			Name:     cfg.name,
			Table:    r.table,
			KeyType:  cfg.keyType,
			Interval: cfg.interval,
			Dynamic:  cfg.dynamic,
		}

		// Assign time.Duration directly
		if cfg.timeout > 0 {
			set.Timeout = cfg.timeout // Directly use time.Duration
		}

		if err := r.conn.AddSet(set, nil); err != nil {
			return fmt.Errorf("failed to create set %s: %w", cfg.name, err)
		}

		logger.Info("ratelimit", "Created nftables set",
			"name", cfg.name,
			"timeout", cfg.timeout,
			"dynamic", cfg.dynamic)
	}
	return nil
}

// initializeWhitelistedIPs adds whitelist IPs and subnets
func (r *RateLimitManager) initializeWhitelistedIPs() error {
	if len(r.config.WhitelistedIPs) == 0 && len(r.config.WhitelistedSubnets) == 0 {
		return nil
	}

	set := &nftables.Set{Name: RateLimitWhitelistSet, Table: r.table}
	var elements []nftables.SetElement

	for _, ipStr := range r.config.WhitelistedIPs {
		ip := net.ParseIP(ipStr)
		if ip == nil {
			logger.Warn("ratelimit", "Invalid whitelisted IP", "ip", ipStr)
			continue
		}
		elements = append(elements, nftables.SetElement{Key: ip.To4()})
	}

	for _, subnetStr := range r.config.WhitelistedSubnets {
		_, subnet, err := net.ParseCIDR(subnetStr)
		if err != nil {
			logger.Warn("ratelimit", "Invalid whitelisted subnet", "subnet", subnetStr, "error", err.Error())
			continue
		}
		elements = append(elements, nftables.SetElement{
			Key:    subnet.IP.To4(),
			KeyEnd: r.getSubnetEnd(subnet),
		})
	}

	if len(elements) > 0 {
		r.conn.SetAddElements(set, elements)
		r.mu.Lock()
		r.stats.WhitelistedIPs = len(elements)
		r.mu.Unlock()

		logger.Info("ratelimit", "Added whitelisted IPs", "count", len(elements))
	}

	return nil
}

func (r *RateLimitManager) getSubnetEnd(subnet *net.IPNet) []byte {
	ip := make(net.IP, len(subnet.IP))
	copy(ip, subnet.IP)
	for i := range ip {
		ip[i] |= ^subnet.Mask[i]
	}
	return ip.To4()
}

// startBackgroundTasks runs cleanup and stats updates
func (r *RateLimitManager) startBackgroundTasks() {
	r.wg.Add(2)
	go r.runCleanupTask()
	go r.runStatsUpdateTask()
}

func (r *RateLimitManager) runCleanupTask() {
	defer r.wg.Done()
	ticker := time.NewTicker(r.config.CleanupInterval)
	defer ticker.Stop()
	for {
		select {
		case <-ticker.C:
			r.performCleanup()
		case <-r.ctx.Done():
			return
		}
	}
}

func (r *RateLimitManager) runStatsUpdateTask() {
	defer r.wg.Done()
	ticker := time.NewTicker(30 * time.Second)
	defer ticker.Stop()
	for {
		select {
		case <-ticker.C:
			r.updateStats()
		case <-r.ctx.Done():
			return
		}
	}
}

func (r *RateLimitManager) performCleanup() {
	logger.Info("ratelimit", "Performing cleanup")
	r.mu.Lock()
	r.stats.LastCleanup = time.Now()
	r.mu.Unlock()
	logger.Info("ratelimit", "Cleanup completed")
}

func (r *RateLimitManager) updateStats() {
	r.mu.Lock()
	defer r.mu.Unlock()
	r.stats.LastStatsUpdate = time.Now()
}

// Stop stops the manager
func (r *RateLimitManager) Stop() {
	r.cancel()
	r.wg.Wait()
	logger.Info("ratelimit", "RateLimitManager stopped")
}

// BanIP bans an IP for a duration
func (r *RateLimitManager) BanIP(ip net.IP, duration time.Duration) error {
	if !r.config.EnableRateLimit || !r.config.EnableAutoBan {
		return fmt.Errorf("auto-ban is disabled")
	}

	// Timeout is a time.Duration, not *time.Duration
	element := nftables.SetElement{
		Key:     ip.To4(),
		Timeout: duration, //  just pass the value
	}

	set := &nftables.Set{
		Name:  RateLimitBannedSet,
		Table: r.table,
	}

	if err := r.conn.SetAddElements(set, []nftables.SetElement{element}); err != nil {
		return fmt.Errorf("failed to add IP to banned set: %w", err)
	}

	if err := r.conn.Flush(); err != nil {
		return fmt.Errorf("failed to flush changes: %w", err)
	}

	r.mu.Lock()
	r.stats.BannedIPs++
	r.mu.Unlock()

	logger.Info("ratelimit", "Banned IP", "ip", ip.String(), "duration", duration)
	return nil
}

// UnbanIP removes an IP from banned set
func (r *RateLimitManager) UnbanIP(ip net.IP) error {
	set := &nftables.Set{
		Name:  RateLimitBannedSet,
		Table: r.table,
	}
	element := nftables.SetElement{Key: ip.To4()}

	if err := r.conn.SetDeleteElements(set, []nftables.SetElement{element}); err != nil {
		return fmt.Errorf("failed to remove IP from banned set: %w", err)
	}
	if err := r.conn.Flush(); err != nil {
		return fmt.Errorf("failed to flush changes: %w", err)
	}

	r.mu.Lock()
	if r.stats.BannedIPs > 0 {
		r.stats.BannedIPs--
	}
	r.mu.Unlock()

	logger.Info("ratelimit", "Unbanned IP", "ip", ip.String())
	return nil
}

// GetStats returns a copy of current stats
func (r *RateLimitManager) GetStats() *RateLimitStats {
	r.mu.RLock()
	defer r.mu.RUnlock()

	copy := *r.stats
	return &copy
}

// UpdateConfig updates configuration
func (r *RateLimitManager) UpdateConfig(cfg *Config) {
	r.mu.Lock()
	defer r.mu.Unlock()
	r.config = cfg
	logger.Info("ratelimit", "Configuration updated")
}

// IsEnabled returns if rate limiting is enabled
func (r *RateLimitManager) IsEnabled() bool {
	return r.config.EnableRateLimit
}
// internal/geoip/enhanced.go
package geoip

import (
	"bufio"
	"encoding/json"
	"fmt"
	"net"
	"net/http"
	"strings"
	"sync"
	"time"

	"qff/internal/config"
	"qff/internal/logger"
)

type EnhancedGeoIPManager struct {
	basicGeoIP   *GeoIPManager
	config       *config.GeoIPConfig
	vpnCache     map[string]*VPNResult
	vpnBlocklist map[string]bool
	mu           sync.RWMutex
	stopCh       chan struct{}
}

type VPNResult struct {
	IP        string
	IsVPN     bool
	IsProxy   bool
	IsTor     bool
	Country   string
	Provider  string
	Timestamp time.Time
	Source    string
}

type ServiceDecision struct {
	Allow       bool
	Reason      string
	Country     string
	IsVPN       bool
	IsProxy     bool
	Service     string
	AppliedRule *config.ServiceRule
}

// IPQualityScore API response structure
type IPQSResponse struct {
	Success     bool   `json:"success"`
	FraudScore  int    `json:"fraud_score"`
	CountryCode string `json:"country_code"`
	ISP         string `json:"ISP"`
	ASN         int    `json:"ASN"`
	VPN         bool   `json:"vpn"`
	Tor         bool   `json:"tor"`
	Proxy       bool   `json:"proxy"`
	Mobile      bool   `json:"mobile"`
	Message     string `json:"message"`
}

func NewEnhancedGeoIPManager(basicGeoIP *GeoIPManager, cfg *config.GeoIPConfig) *EnhancedGeoIPManager {
	egm := &EnhancedGeoIPManager{
		basicGeoIP:   basicGeoIP,
		config:       cfg,
		vpnCache:     make(map[string]*VPNResult),
		vpnBlocklist: make(map[string]bool),
		stopCh:       make(chan struct{}),
	}

	egm.setDefaults()
	return egm
}

func (e *EnhancedGeoIPManager) setDefaults() {
	if e.config.CacheExpiration == 0 {
		e.config.CacheExpiration = 24 * time.Hour
	}

	if e.config.VPNDetectionAPI == "" {
		e.config.VPNDetectionAPI = "ipqualityscore" // Default to IPQS
	}

	// Set default VPN blocklists if none configured
	if len(e.config.VPNBlocklists) == 0 {
		e.config.VPNBlocklists = []string{
			"https://raw.githubusercontent.com/X4BNet/lists_vpn/main/ipv4.txt",
			"https://raw.githubusercontent.com/SecOps-Institute/Tor-IP-Addresses/master/tor-exit-nodes.txt",
		}
	}

	// Initialize default service rules if not configured
	if e.config.ServiceRules == nil {
		e.config.ServiceRules = make(map[string]*config.ServiceRule)
	}

	// Add default SSH rule if none exists
	if _, exists := e.config.ServiceRules["ssh"]; !exists {
		e.config.ServiceRules["ssh"] = &config.ServiceRule{
			Service:      "ssh",
			BlockVPNs:    true,
			BlockProxies: true,
			Enabled:      true,
		}
	}
}

func (e *EnhancedGeoIPManager) Initialize() error {
	if !e.config.EnablePerServiceRules && !e.config.EnableVPNDetection {
		return nil
	}

	logger.Info("geoip", "Initializing enhanced GeoIP manager")

	// Load VPN blocklists
	if e.config.EnableVPNDetection {
		go e.loadVPNBlocklists()
		go e.startCacheCleanup()
	}

	return nil
}

func (e *EnhancedGeoIPManager) loadVPNBlocklists() {
	logger.Info("geoip", "Loading VPN blocklists")

	for _, url := range e.config.VPNBlocklists {
		e.loadVPNBlocklist(url)
	}

	logger.Info("geoip", "VPN blocklists loaded", "count", len(e.vpnBlocklist))
}

func (e *EnhancedGeoIPManager) loadVPNBlocklist(url string) {
	client := &http.Client{Timeout: 30 * time.Second}

	resp, err := client.Get(url)
	if err != nil {
		logger.Error("geoip", "Failed to fetch VPN blocklist", "url", url, "error", err.Error())
		return
	}
	defer resp.Body.Close()

	if resp.StatusCode != 200 {
		logger.Error("geoip", "VPN blocklist returned non-200", "url", url, "status", resp.StatusCode)
		return
	}

	scanner := bufio.NewScanner(resp.Body)
	count := 0

	e.mu.Lock()
	for scanner.Scan() {
		line := strings.TrimSpace(scanner.Text())
		if line != "" && !strings.HasPrefix(line, "#") {
			// Handle both single IPs and CIDR ranges
			if ip := net.ParseIP(line); ip != nil {
				e.vpnBlocklist[line] = true
				count++
			} else if _, _, err := net.ParseCIDR(line); err == nil {
				e.vpnBlocklist[line] = true
				count++
			}
		}
	}
	e.mu.Unlock()

	logger.Info("geoip", "Loaded VPN blocklist", "url", url, "entries", count)
}

func (e *EnhancedGeoIPManager) CheckServiceAccess(ip net.IP, service string) *ServiceDecision {
	decision := &ServiceDecision{
		Allow:   true,
		Service: service,
		Country: e.basicGeoIP.GetCountry(ip),
	}

	// Check if service has specific rules
	rule, hasRule := e.config.ServiceRules[service]
	if !hasRule || !rule.Enabled {
		// No specific rule, fall back to basic GeoIP blocking
		if e.basicGeoIP.IsBlocked(ip) {
			decision.Allow = false
			decision.Reason = "Country blocked by basic GeoIP rules"
		}
		return decision
	}

	decision.AppliedRule = rule

	// Check VPN/Proxy if enabled for this service
	if e.config.EnableVPNDetection && (rule.BlockVPNs || rule.BlockProxies) {
		vpnResult := e.checkVPN(ip)
		decision.IsVPN = vpnResult.IsVPN
		decision.IsProxy = vpnResult.IsProxy

		if rule.BlockVPNs && vpnResult.IsVPN {
			decision.Allow = false
			decision.Reason = fmt.Sprintf("VPN detected (%s)", vpnResult.Provider)
			return decision
		}

		if rule.BlockProxies && vpnResult.IsProxy {
			decision.Allow = false
			decision.Reason = "Proxy detected"
			return decision
		}
	}

	// Check country rules
	country := decision.Country

	// If allowed countries specified, must be in the list
	if len(rule.AllowedCountries) > 0 {
		allowed := false
		for _, allowedCountry := range rule.AllowedCountries {
			if country == allowedCountry {
				allowed = true
				break
			}
		}
		if !allowed {
			decision.Allow = false
			decision.Reason = fmt.Sprintf("Country %s not in allowed list for %s", country, service)
			return decision
		}
	}

	// Check blocked countries
	for _, blockedCountry := range rule.BlockedCountries {
		if country == blockedCountry {
			decision.Allow = false
			decision.Reason = fmt.Sprintf("Country %s blocked for %s", country, service)
			return decision
		}
	}

	return decision
}

func (e *EnhancedGeoIPManager) checkVPN(ip net.IP) *VPNResult {
	ipStr := ip.String()

	// Check cache first
	e.mu.RLock()
	if cached, exists := e.vpnCache[ipStr]; exists {
		if time.Since(cached.Timestamp) < e.config.CacheExpiration {
			e.mu.RUnlock()
			return cached
		}
	}
	e.mu.RUnlock()

	// Check static blocklist first (faster)
	result := e.checkVPNBlocklist(ip)
	if result.IsVPN || result.IsProxy {
		e.cacheVPNResult(ipStr, result)
		return result
	}

	// Check API if configured
	if e.config.VPNAPIKey != "" {
		if apiResult := e.checkVPNAPI(ip); apiResult != nil {
			e.cacheVPNResult(ipStr, apiResult)
			return apiResult
		}
	}

	// Cache negative result
	result.Timestamp = time.Now()
	e.cacheVPNResult(ipStr, result)
	return result
}

func (e *EnhancedGeoIPManager) checkVPNBlocklist(ip net.IP) *VPNResult {
	ipStr := ip.String()

	e.mu.RLock()
	defer e.mu.RUnlock()

	result := &VPNResult{
		IP:        ipStr,
		Timestamp: time.Now(),
		Source:    "blocklist",
	}

	// Check exact IP match
	if e.vpnBlocklist[ipStr] {
		result.IsVPN = true
		result.Provider = "Known VPN/Proxy"
		return result
	}

	// Check CIDR ranges (simplified - you might want to optimize this)
	for cidr := range e.vpnBlocklist {
		if strings.Contains(cidr, "/") {
			if _, network, err := net.ParseCIDR(cidr); err == nil {
				if network.Contains(ip) {
					result.IsVPN = true
					result.Provider = "VPN Range"
					return result
				}
			}
		}
	}

	return result
}

func (e *EnhancedGeoIPManager) checkVPNAPI(ip net.IP) *VPNResult {
	switch e.config.VPNDetectionAPI {
	case "ipqualityscore":
		return e.checkIPQualityScore(ip)
	default:
		logger.Warn("geoip", "Unknown VPN detection API", "api", e.config.VPNDetectionAPI)
		return nil
	}
}

func (e *EnhancedGeoIPManager) checkIPQualityScore(ip net.IP) *VPNResult {
	url := fmt.Sprintf("https://ipqualityscore.com/api/json/ip/%s/%s",
		e.config.VPNAPIKey, ip.String())

	client := &http.Client{Timeout: 5 * time.Second}
	resp, err := client.Get(url)
	if err != nil {
		logger.Error("geoip", "IPQS API request failed", "error", err.Error())
		return nil
	}
	defer resp.Body.Close()

	var ipqsResp IPQSResponse
	if err := json.NewDecoder(resp.Body).Decode(&ipqsResp); err != nil {
		logger.Error("geoip", "Failed to decode IPQS response", "error", err.Error())
		return nil
	}

	if !ipqsResp.Success {
		logger.Error("geoip", "IPQS API returned error", "message", ipqsResp.Message)
		return nil
	}

	return &VPNResult{
		IP:        ip.String(),
		IsVPN:     ipqsResp.VPN,
		IsProxy:   ipqsResp.Proxy,
		IsTor:     ipqsResp.Tor,
		Country:   ipqsResp.CountryCode,
		Provider:  ipqsResp.ISP,
		Timestamp: time.Now(),
		Source:    "ipqualityscore",
	}
}

func (e *EnhancedGeoIPManager) cacheVPNResult(ip string, result *VPNResult) {
	if !e.config.CacheVPNResults {
		return
	}

	e.mu.Lock()
	e.vpnCache[ip] = result
	e.mu.Unlock()
}

func (e *EnhancedGeoIPManager) startCacheCleanup() {
	ticker := time.NewTicker(1 * time.Hour)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			e.cleanupCache()
		case <-e.stopCh:
			return
		}
	}
}

func (e *EnhancedGeoIPManager) cleanupCache() {
	e.mu.Lock()
	defer e.mu.Unlock()

	now := time.Now()
	cleaned := 0

	for ip, result := range e.vpnCache {
		if now.Sub(result.Timestamp) > e.config.CacheExpiration {
			delete(e.vpnCache, ip)
			cleaned++
		}
	}

	if cleaned > 0 {
		logger.Info("geoip", "Cleaned up VPN cache", "entries", cleaned)
	}
}

func (e *EnhancedGeoIPManager) GetStats() map[string]interface{} {
	e.mu.RLock()
	defer e.mu.RUnlock()

	return map[string]interface{}{
		"enhanced_enabled":   e.config.EnablePerServiceRules,
		"vpn_detection":      e.config.EnableVPNDetection,
		"service_rules":      len(e.config.ServiceRules),
		"vpn_cache_size":     len(e.vpnCache),
		"vpn_blocklist_size": len(e.vpnBlocklist),
		"cache_expiration":   e.config.CacheExpiration.String(),
	}
}

func (e *EnhancedGeoIPManager) Stop() {
	close(e.stopCh)
}
// internal/geoip/geoip.go
package geoip

import (
	"bufio"
	"net"
	"os"
	"strings"
	"time"

	"github.com/oschwald/geoip2-golang"
	"qff/internal/config"
	"qff/internal/logger"
)

type GeoIPManager struct {
	db               *geoip2.Reader
	config           *config.GeoIPConfig
	blockedCountries map[string]bool
	allowedCountries map[string]bool
	downloader       *MaxMindDownloader
}

func NewGeoIPManager(cfg *config.GeoIPConfig) *GeoIPManager {
	mgr := &GeoIPManager{
		config:           cfg,
		blockedCountries: make(map[string]bool),
		allowedCountries: make(map[string]bool),
	}

	if cfg.MaxMindAPIKey != "" {
		mgr.downloader = NewMaxMindDownloader(cfg.MaxMindAPIKey, cfg.MMDBPath)
	}

	return mgr
}

func (g *GeoIPManager) Initialize() error {
	if g.config.MMDBPath == "" {
		logger.Warn("geoip", "GeoIP database path not configured")
		return nil
	}

	// Check if database exists, download if needed
	if g.downloader != nil && g.config.AutoDownload {
		if _, err := os.Stat(g.config.MMDBPath); os.IsNotExist(err) {
			logger.Info("geoip", "Database not found, downloading")
			if err := g.downloader.DownloadDatabase(); err != nil {
				logger.Error("geoip", "Failed to download database", "error", err.Error())
			}
		}
	}

	db, err := geoip2.Open(g.config.MMDBPath)
	if err != nil {
		return err
	}
	g.db = db

	if err := g.loadCountryLists(); err != nil {
		return err
	}

	logger.Info("geoip", "GeoIP initialized", "blocked_countries", len(g.blockedCountries), "allowed_countries", len(g.allowedCountries))
	return nil
}

func (g *GeoIPManager) loadCountryLists() error {
	if g.config.CountryBlockFile != "" {
		if err := g.loadCountryFile(g.config.CountryBlockFile, g.blockedCountries); err != nil {
			return err
		}
	}

	if g.config.CountryAllowFile != "" {
		if err := g.loadCountryFile(g.config.CountryAllowFile, g.allowedCountries); err != nil {
			return err
		}
	}

	return nil
}

func (g *GeoIPManager) loadCountryFile(filename string, countryMap map[string]bool) error {
	file, err := os.Open(filename)
	if err != nil {
		return err
	}
	defer file.Close()

	scanner := bufio.NewScanner(file)
	for scanner.Scan() {
		line := strings.TrimSpace(scanner.Text())
		if line != "" && !strings.HasPrefix(line, "#") {
			countryMap[strings.ToUpper(line)] = true
		}
	}

	return scanner.Err()
}

func (g *GeoIPManager) IsBlocked(ip net.IP) bool {
	if g.db == nil {
		return false
	}

	record, err := g.db.Country(ip)
	if err != nil {
		return false
	}

	country := record.Country.IsoCode

	if len(g.allowedCountries) > 0 {
		return !g.allowedCountries[country]
	}

	return g.blockedCountries[country]
}

func (g *GeoIPManager) GetCountry(ip net.IP) string {
	if g.db == nil {
		return ""
	}

	record, err := g.db.Country(ip)
	if err != nil {
		return ""
	}

	return record.Country.IsoCode
}

func (g *GeoIPManager) EnableAutoDownload(apiKey string) {
	if g.downloader == nil {
		g.downloader = NewMaxMindDownloader(apiKey, g.config.MMDBPath)
	}

	go func() {
		ticker := time.NewTicker(24 * time.Hour)
		defer ticker.Stop()

		for range ticker.C {
			if g.downloader.ShouldUpdate() {
				if err := g.downloader.DownloadDatabase(); err != nil {
					logger.Error("geoip", "Failed to auto-update database", "error", err.Error())
				}
			}
		}
	}()

	logger.Info("geoip", "Auto-download enabled for MaxMind database")
}

func (g *GeoIPManager) Close() error {
	if g.db != nil {
		return g.db.Close()
	}
	return nil
}
// internal/geoip/maxmind.go
package geoip

import (
	"archive/tar"
	"compress/gzip"
	"context"
	"crypto/sha256"
	"encoding/hex"
	"fmt"
	"io"
	"net/http"
	"os"
	"path/filepath"
	"strings"
	"sync"
	"time"

	"qff/internal/logger"
)

const (
	// MaxMind configuration
	MaxMindBaseURL         = "https://download.maxmind.com/app/geoip_download"
	DefaultUpdateInterval  = 7 * 24 * time.Hour // Weekly updates
	DefaultDownloadTimeout = 10 * time.Minute
	DefaultMaxFileSize     = 100 * 1024 * 1024 // 100MB max
	DefaultRetryAttempts   = 3
	DefaultRetryDelay      = 30 * time.Second

	// Database editions
	GeoLite2Country = "GeoLite2-Country"
	GeoLite2City    = "GeoLite2-City"
	GeoLite2ASN     = "GeoLite2-ASN"

	// File extensions
	TarGzSuffix = "tar.gz"
	MmdbSuffix  = ".mmdb"
)

// MaxMindDownloader handles downloading and updating MaxMind GeoIP databases
type MaxMindDownloader struct {
	// Configuration
	config *DownloaderConfig

	// State management
	mu         sync.RWMutex
	lastUpdate map[string]time.Time
	isUpdating map[string]bool

	// HTTP client
	client *http.Client
}

// DownloaderConfig holds configuration for the MaxMind downloader
type DownloaderConfig struct {
	APIKey          string        `json:"api_key"`
	DatabasePath    string        `json:"database_path"`
	UpdateInterval  time.Duration `json:"update_interval"`
	DownloadTimeout time.Duration `json:"download_timeout"`
	MaxFileSize     int64         `json:"max_file_size"`
	RetryAttempts   int           `json:"retry_attempts"`
	RetryDelay      time.Duration `json:"retry_delay"`
	EnableChecksum  bool          `json:"enable_checksum"`
	BackupOldDB     bool          `json:"backup_old_db"`
	AutoUpdate      bool          `json:"auto_update"`
}

// DatabaseInfo contains metadata about a downloaded database
type DatabaseInfo struct {
	Edition      string    `json:"edition"`
	FilePath     string    `json:"file_path"`
	Size         int64     `json:"size"`
	Checksum     string    `json:"checksum"`
	DownloadTime time.Time `json:"download_time"`
	LastUpdate   time.Time `json:"last_update"`
	Version      string    `json:"version,omitempty"`
}

// DownloadResult represents the result of a download operation
type DownloadResult struct {
	Success         bool          `json:"success"`
	DatabaseInfo    *DatabaseInfo `json:"database_info,omitempty"`
	Error           string        `json:"error,omitempty"`
	Duration        time.Duration `json:"duration"`
	BytesDownloaded int64         `json:"bytes_downloaded"`
}

func NewMaxMindDownloader(apiKeyOrConfig interface{}, dbPath ...string) *MaxMindDownloader {
	var config *DownloaderConfig

	// Handle both old and new calling conventions
	switch v := apiKeyOrConfig.(type) {
	case string:
		// Old interface: NewMaxMindDownloader(apiKey, dbPath)
		var path string
		if len(dbPath) > 0 {
			path = dbPath[0]
		}
		config = &DownloaderConfig{
			APIKey:          v,
			DatabasePath:    path,
			UpdateInterval:  DefaultUpdateInterval,
			DownloadTimeout: DefaultDownloadTimeout,
			MaxFileSize:     DefaultMaxFileSize,
			RetryAttempts:   DefaultRetryAttempts,
			RetryDelay:      DefaultRetryDelay,
			EnableChecksum:  true,
			BackupOldDB:     true,
			AutoUpdate:      true,
		}
	case *DownloaderConfig:
		// New interface: NewMaxMindDownloader(config)
		config = v
	default:
		// Fallback to default config
		config = getDefaultConfig()
	}

	// Apply defaults for missing values
	applyConfigDefaults(config)

	// Create HTTP client with timeout and reasonable defaults
	client := &http.Client{
		Timeout: config.DownloadTimeout,
		Transport: &http.Transport{
			MaxIdleConns:       10,
			IdleConnTimeout:    30 * time.Second,
			DisableCompression: false,
			MaxConnsPerHost:    2,
		},
	}

	return &MaxMindDownloader{
		config:     config,
		lastUpdate: make(map[string]time.Time),
		isUpdating: make(map[string]bool),
		client:     client,
	}
}

func getDefaultConfig() *DownloaderConfig {
	return &DownloaderConfig{
		UpdateInterval:  DefaultUpdateInterval,
		DownloadTimeout: DefaultDownloadTimeout,
		MaxFileSize:     DefaultMaxFileSize,
		RetryAttempts:   DefaultRetryAttempts,
		RetryDelay:      DefaultRetryDelay,
		EnableChecksum:  true,
		BackupOldDB:     true,
		AutoUpdate:      true,
	}
}

func applyConfigDefaults(config *DownloaderConfig) {
	if config.UpdateInterval == 0 {
		config.UpdateInterval = DefaultUpdateInterval
	}
	if config.DownloadTimeout == 0 {
		config.DownloadTimeout = DefaultDownloadTimeout
	}
	if config.MaxFileSize == 0 {
		config.MaxFileSize = DefaultMaxFileSize
	}
	if config.RetryAttempts == 0 {
		config.RetryAttempts = DefaultRetryAttempts
	}
	if config.RetryDelay == 0 {
		config.RetryDelay = DefaultRetryDelay
	}
}

// DownloadDatabase provides the old interface - returns only error
func (m *MaxMindDownloader) DownloadDatabase() error {
	result, err := m.downloadDatabaseInternal(context.Background(), GeoLite2Country)
	if err != nil {
		return err
	}

	if result != nil && !result.Success {
		return fmt.Errorf("download failed: %s", result.Error)
	}

	return nil
}

// ShouldUpdate checks if a database should be updated (old interface)
func (m *MaxMindDownloader) ShouldUpdate() bool {
	return m.ShouldUpdateEdition(GeoLite2Country)
}

// DownloadDatabaseWithResult downloads the specified MaxMind database edition with full result
func (m *MaxMindDownloader) DownloadDatabaseWithResult(ctx context.Context, edition string) (*DownloadResult, error) {
	return m.downloadDatabaseInternal(ctx, edition)
}

// ShouldUpdateEdition checks if a specific database edition should be updated
func (m *MaxMindDownloader) ShouldUpdateEdition(edition string) bool {
	m.mu.RLock()
	lastUpdate, exists := m.lastUpdate[edition]
	m.mu.RUnlock()

	if !exists {
		return true // Never updated
	}

	return time.Since(lastUpdate) > m.config.UpdateInterval
}

// downloadDatabaseInternal is the actual implementation
func (m *MaxMindDownloader) downloadDatabaseInternal(ctx context.Context, edition string) (*DownloadResult, error) {
	if m.config.APIKey == "" {
		return nil, fmt.Errorf("MaxMind API key not configured")
	}

	if err := m.validateEdition(edition); err != nil {
		return nil, fmt.Errorf("invalid edition: %w", err)
	}

	// Check if already updating
	m.mu.Lock()
	if m.isUpdating[edition] {
		m.mu.Unlock()
		return nil, fmt.Errorf("database %s is already being updated", edition)
	}
	m.isUpdating[edition] = true
	m.mu.Unlock()

	defer func() {
		m.mu.Lock()
		m.isUpdating[edition] = false
		m.mu.Unlock()
	}()

	startTime := time.Now()
	logger.Info("geoip", "Starting MaxMind database download",
		"edition", edition, "api_key_length", len(m.config.APIKey))

	result := &DownloadResult{}

	// Download with retries
	var lastErr error
	for attempt := 1; attempt <= m.config.RetryAttempts; attempt++ {
		if attempt > 1 {
			logger.Info("geoip", "Retrying download", "edition", edition, "attempt", attempt)

			select {
			case <-ctx.Done():
				return nil, ctx.Err()
			case <-time.After(m.config.RetryDelay):
			}
		}

		dbInfo, err := m.downloadWithRetry(ctx, edition)
		if err != nil {
			lastErr = err
			logger.Warn("geoip", "Download attempt failed",
				"edition", edition, "attempt", attempt, "error", err.Error())
			continue
		}

		// Success
		result.Success = true
		result.DatabaseInfo = dbInfo
		result.Duration = time.Since(startTime)
		result.BytesDownloaded = dbInfo.Size

		m.mu.Lock()
		m.lastUpdate[edition] = time.Now()
		m.mu.Unlock()

		logger.Info("geoip", "MaxMind database downloaded successfully",
			"edition", edition, "size", dbInfo.Size, "duration", result.Duration)

		return result, nil
	}

	// All attempts failed
	result.Success = false
	result.Error = fmt.Sprintf("failed after %d attempts: %v", m.config.RetryAttempts, lastErr)
	result.Duration = time.Since(startTime)

	return result, lastErr
}

func (m *MaxMindDownloader) downloadWithRetry(ctx context.Context, edition string) (*DatabaseInfo, error) {
	// Create download URL
	url := fmt.Sprintf("%s?edition_id=%s&license_key=%s&suffix=%s",
		MaxMindBaseURL, edition, m.config.APIKey, TarGzSuffix)

	// Create request with context
	req, err := http.NewRequestWithContext(ctx, "GET", url, nil)
	if err != nil {
		return nil, fmt.Errorf("failed to create request: %w", err)
	}

	// Add headers
	req.Header.Set("User-Agent", "QFF-GeoIP-Downloader/1.0")
	req.Header.Set("Accept", "application/octet-stream")

	// Make request
	resp, err := m.client.Do(req)
	if err != nil {
		return nil, fmt.Errorf("failed to download database: %w", err)
	}
	defer resp.Body.Close()

	// Check response status
	if resp.StatusCode != http.StatusOK {
		body, _ := io.ReadAll(io.LimitReader(resp.Body, 1024))
		return nil, fmt.Errorf("MaxMind API returned status %d: %s", resp.StatusCode, string(body))
	}

	// Check content length
	if resp.ContentLength > m.config.MaxFileSize {
		return nil, fmt.Errorf("file too large: %d bytes (max: %d)", resp.ContentLength, m.config.MaxFileSize)
	}

	// Download to temporary file
	return m.downloadAndExtract(ctx, resp, edition)
}

func (m *MaxMindDownloader) downloadAndExtract(ctx context.Context, resp *http.Response, edition string) (*DatabaseInfo, error) {
	// Create temporary file
	tempFile, err := os.CreateTemp("", fmt.Sprintf("maxmind-%s-*.tar.gz", edition))
	if err != nil {
		return nil, fmt.Errorf("failed to create temp file: %w", err)
	}
	tempPath := tempFile.Name()

	defer func() {
		tempFile.Close()
		os.Remove(tempPath)
	}()

	// Download with progress tracking and size limit
	hasher := sha256.New()
	limitedReader := io.LimitReader(resp.Body, m.config.MaxFileSize)

	var downloadedBytes int64
	if m.config.EnableChecksum {
		// Use TeeReader for checksum calculation
		teeReader := io.TeeReader(limitedReader, hasher)
		downloadedBytes, err = io.Copy(tempFile, teeReader)
	} else {
		downloadedBytes, err = io.Copy(tempFile, limitedReader)
	}

	if err != nil {
		return nil, fmt.Errorf("failed to download file: %w", err)
	}

	// Verify download completed
	if resp.ContentLength > 0 && downloadedBytes != resp.ContentLength {
		return nil, fmt.Errorf("incomplete download: got %d bytes, expected %d",
			downloadedBytes, resp.ContentLength)
	}

	tempFile.Close()

	// Calculate checksum
	var checksum string
	if m.config.EnableChecksum {
		checksum = hex.EncodeToString(hasher.Sum(nil))
	}

	// Extract MMDB file
	dbInfo, err := m.extractMMDB(ctx, tempPath, edition, downloadedBytes, checksum)
	if err != nil {
		return nil, fmt.Errorf("failed to extract database: %w", err)
	}

	return dbInfo, nil
}

func (m *MaxMindDownloader) extractMMDB(ctx context.Context, tarPath, edition string, size int64, checksum string) (*DatabaseInfo, error) {
	file, err := os.Open(tarPath)
	if err != nil {
		return nil, fmt.Errorf("failed to open tar file: %w", err)
	}
	defer file.Close()

	// Create gzip reader
	gzr, err := gzip.NewReader(file)
	if err != nil {
		return nil, fmt.Errorf("failed to create gzip reader: %w", err)
	}
	defer gzr.Close()

	// Create tar reader
	tr := tar.NewReader(gzr)

	// Target filename to look for
	targetFile := fmt.Sprintf("%s%s", edition, MmdbSuffix)

	// Extract the MMDB file
	for {
		select {
		case <-ctx.Done():
			return nil, ctx.Err()
		default:
		}

		header, err := tr.Next()
		if err == io.EOF {
			break
		}
		if err != nil {
			return nil, fmt.Errorf("failed to read tar header: %w", err)
		}

		// Check if this is the file we want
		if strings.HasSuffix(header.Name, targetFile) {
			return m.saveMMDBFile(ctx, tr, edition, header, size, checksum)
		}
	}

	return nil, fmt.Errorf("%s not found in archive", targetFile)
}

func (m *MaxMindDownloader) saveMMDBFile(ctx context.Context, tr *tar.Reader, edition string, header *tar.Header, archiveSize int64, checksum string) (*DatabaseInfo, error) {
	// Generate final path
	finalPath := m.generateDBPath(edition)

	// Create directory if needed
	if err := os.MkdirAll(filepath.Dir(finalPath), 0755); err != nil {
		return nil, fmt.Errorf("failed to create directory: %w", err)
	}

	// Backup existing file if requested
	if m.config.BackupOldDB {
		if err := m.backupExistingDB(finalPath); err != nil {
			logger.Warn("geoip", "Failed to backup existing database", "error", err.Error())
		}
	}

	// Create temporary file for atomic replacement
	tempPath := finalPath + ".tmp"
	outFile, err := os.Create(tempPath)
	if err != nil {
		return nil, fmt.Errorf("failed to create output file: %w", err)
	}
	defer func() {
		outFile.Close()
		if err != nil {
			os.Remove(tempPath)
		}
	}()

	// Copy file content with context cancellation check
	written, err := m.copyWithContext(ctx, outFile, tr)
	if err != nil {
		return nil, fmt.Errorf("failed to extract file: %w", err)
	}

	outFile.Close()

	// Atomic move
	if err := os.Rename(tempPath, finalPath); err != nil {
		os.Remove(tempPath)
		return nil, fmt.Errorf("failed to move file to final location: %w", err)
	}

	// Set appropriate permissions
	if err := os.Chmod(finalPath, 0644); err != nil {
		logger.Warn("geoip", "Failed to set file permissions", "path", finalPath, "error", err.Error())
	}

	// Create database info
	dbInfo := &DatabaseInfo{
		Edition:      edition,
		FilePath:     finalPath,
		Size:         written,
		Checksum:     checksum,
		DownloadTime: time.Now(),
		LastUpdate:   time.Now(),
	}

	// Try to get version from header
	if header.ModTime != (time.Time{}) {
		dbInfo.Version = header.ModTime.Format("20060102")
	}

	return dbInfo, nil
}

func (m *MaxMindDownloader) copyWithContext(ctx context.Context, dst io.Writer, src io.Reader) (int64, error) {
	buf := make([]byte, 32*1024) // 32KB buffer
	var written int64

	for {
		select {
		case <-ctx.Done():
			return written, ctx.Err()
		default:
		}

		nr, er := src.Read(buf)
		if nr > 0 {
			nw, ew := dst.Write(buf[0:nr])
			if nw < 0 || nr < nw {
				nw = 0
				if ew == nil {
					ew = fmt.Errorf("invalid write result")
				}
			}
			written += int64(nw)
			if ew != nil {
				return written, ew
			}
			if nr != nw {
				return written, io.ErrShortWrite
			}
		}
		if er != nil {
			if er != io.EOF {
				return written, er
			}
			break
		}
	}
	return written, nil
}

func (m *MaxMindDownloader) backupExistingDB(filePath string) error {
	if _, err := os.Stat(filePath); os.IsNotExist(err) {
		return nil // No existing file to backup
	}

	backupPath := filePath + ".backup." + time.Now().Format("20060102-150405")

	return m.copyFile(filePath, backupPath)
}

func (m *MaxMindDownloader) copyFile(src, dst string) error {
	sourceFile, err := os.Open(src)
	if err != nil {
		return err
	}
	defer sourceFile.Close()

	destFile, err := os.Create(dst)
	if err != nil {
		return err
	}
	defer destFile.Close()

	_, err = io.Copy(destFile, sourceFile)
	return err
}

func (m *MaxMindDownloader) generateDBPath(edition string) string {
	if m.config.DatabasePath != "" {
		// If specific path provided, use it
		if strings.HasSuffix(m.config.DatabasePath, MmdbSuffix) {
			return m.config.DatabasePath
		}
		// Treat as directory
		return filepath.Join(m.config.DatabasePath, edition+MmdbSuffix)
	}

	// Use default path
	return filepath.Join("/var/lib/qff/geoip", edition+MmdbSuffix)
}

func (m *MaxMindDownloader) validateEdition(edition string) error {
	validEditions := []string{GeoLite2Country, GeoLite2City, GeoLite2ASN}

	for _, valid := range validEditions {
		if edition == valid {
			return nil
		}
	}

	return fmt.Errorf("unsupported edition %q, valid editions: %v", edition, validEditions)
}

// GetLastUpdate returns the last update time for a specific edition
func (m *MaxMindDownloader) GetLastUpdate(edition string) (time.Time, bool) {
	m.mu.RLock()
	defer m.mu.RUnlock()

	lastUpdate, exists := m.lastUpdate[edition]
	return lastUpdate, exists
}

// IsUpdating checks if a specific edition is currently being updated
func (m *MaxMindDownloader) IsUpdating(edition string) bool {
	m.mu.RLock()
	defer m.mu.RUnlock()

	return m.isUpdating[edition]
}

// GetConfig returns a copy of the current configuration
func (m *MaxMindDownloader) GetConfig() *DownloaderConfig {
	configCopy := *m.config
	return &configCopy
}

// UpdateConfig updates the downloader configuration
func (m *MaxMindDownloader) UpdateConfig(newConfig *DownloaderConfig) error {
	if newConfig == nil {
		return fmt.Errorf("config cannot be nil")
	}

	// Validate configuration
	if err := m.validateConfig(newConfig); err != nil {
		return fmt.Errorf("invalid configuration: %w", err)
	}

	m.mu.Lock()
	defer m.mu.Unlock()

	applyConfigDefaults(newConfig)
	m.config = newConfig

	// Update HTTP client timeout
	m.client.Timeout = newConfig.DownloadTimeout

	logger.Info("geoip", "MaxMind downloader configuration updated")
	return nil
}

func (m *MaxMindDownloader) validateConfig(config *DownloaderConfig) error {
	if config.APIKey == "" {
		return fmt.Errorf("API key is required")
	}

	if config.UpdateInterval < time.Hour {
		return fmt.Errorf("update interval must be at least 1 hour")
	}

	if config.DownloadTimeout < 30*time.Second {
		return fmt.Errorf("download timeout must be at least 30 seconds")
	}

	if config.MaxFileSize < 1024*1024 {
		return fmt.Errorf("max file size must be at least 1MB")
	}

	if config.RetryAttempts < 1 || config.RetryAttempts > 10 {
		return fmt.Errorf("retry attempts must be between 1 and 10")
	}

	return nil
}

// GetDatabaseInfo returns information about a downloaded database
func (m *MaxMindDownloader) GetDatabaseInfo(edition string) (*DatabaseInfo, error) {
	dbPath := m.generateDBPath(edition)

	stat, err := os.Stat(dbPath)
	if err != nil {
		if os.IsNotExist(err) {
			return nil, fmt.Errorf("database %s not found", edition)
		}
		return nil, fmt.Errorf("failed to stat database file: %w", err)
	}

	m.mu.RLock()
	lastUpdate, hasUpdate := m.lastUpdate[edition]
	m.mu.RUnlock()

	dbInfo := &DatabaseInfo{
		Edition:    edition,
		FilePath:   dbPath,
		Size:       stat.Size(),
		LastUpdate: stat.ModTime(),
	}

	if hasUpdate {
		dbInfo.DownloadTime = lastUpdate
	}

	// Calculate checksum if enabled
	if m.config.EnableChecksum {
		checksum, err := m.calculateFileChecksum(dbPath)
		if err != nil {
			logger.Warn("geoip", "Failed to calculate checksum", "path", dbPath, "error", err.Error())
		} else {
			dbInfo.Checksum = checksum
		}
	}

	return dbInfo, nil
}

func (m *MaxMindDownloader) calculateFileChecksum(filePath string) (string, error) {
	file, err := os.Open(filePath)
	if err != nil {
		return "", err
	}
	defer file.Close()

	hasher := sha256.New()
	if _, err := io.Copy(hasher, file); err != nil {
		return "", err
	}

	return hex.EncodeToString(hasher.Sum(nil)), nil
}

// ListAvailableEditions returns a list of supported MaxMind database editions
func (m *MaxMindDownloader) ListAvailableEditions() []string {
	return []string{GeoLite2Country, GeoLite2City, GeoLite2ASN}
}

// ForceUpdate forces an immediate update of the specified database edition
func (m *MaxMindDownloader) ForceUpdate(ctx context.Context, edition string) (*DownloadResult, error) {
	logger.Info("geoip", "Forcing database update", "edition", edition)
	return m.downloadDatabaseInternal(ctx, edition)
}
// internal/ips/blocklist.go
package ips

import (
	"bufio"
	"context"
	"fmt"
	"io"
	"net"
	"net/http"
	"strings"
	"sync"
	"time"

	"qff/internal/config"
	"qff/internal/logger"
)

const (
	defaultUpdateInterval = 24 * time.Hour
	defaultHTTPTimeout    = 30 * time.Second
	defaultBatchSize      = 1000
	defaultBatchDelay     = 100 * time.Millisecond
)

type ExternalBlocklistManager struct {
	config     *config.IPSConfig
	ipsManager *IPSManager
	blocklists map[string]*Blocklist
	client     *http.Client
	mu         sync.RWMutex
	stopCh     chan struct{}
	wg         sync.WaitGroup
}

type Blocklist struct {
	Name       string
	URL        string
	LastUpdate time.Time
	IPCount    int
	Enabled    bool
	ErrorCount int // Track consecutive failures
}

func NewExternalBlocklistManager(cfg *config.IPSConfig, ipsManager *IPSManager) *ExternalBlocklistManager {
	bm := &ExternalBlocklistManager{
		config:     cfg,
		ipsManager: ipsManager,
		blocklists: make(map[string]*Blocklist),
		client: &http.Client{
			Timeout: defaultHTTPTimeout,
			Transport: &http.Transport{
				MaxIdleConns:        10,
				IdleConnTimeout:     30 * time.Second,
				DisableCompression:  false,
				MaxConnsPerHost:     5,
				MaxIdleConnsPerHost: 5,
			},
		},
		stopCh: make(chan struct{}),
	}

	bm.initializeBlocklists()
	return bm
}

func (b *ExternalBlocklistManager) initializeBlocklists() {
	if b.config.BlocklistUpdateInterval == 0 {
		b.config.BlocklistUpdateInterval = defaultUpdateInterval
	}

	// Initialize predefined blocklists
	predefinedLists := []struct {
		key     string
		name    string
		url     string
		enabled bool
	}{
		{"spamhaus_drop", "Spamhaus DROP", "https://www.spamhaus.org/drop/drop.txt", b.config.SpamhausEnabled},
		{"spamhaus_edrop", "Spamhaus EDROP", "https://www.spamhaus.org/drop/edrop.txt", b.config.SpamhausEnabled},
		{"dshield_top", "DShield Top Attackers", "https://www.dshield.org/feeds/suspiciousdomains_High.txt", b.config.DShieldEnabled},
		{"abuse_ch", "Abuse.ch IP Blacklist", "https://feodotracker.abuse.ch/downloads/ipblocklist.txt", true},
		{"greensnow", "GreenSnow Blacklist", "https://blocklist.greensnow.co/greensnow.txt", true},
	}

	for _, list := range predefinedLists {
		if list.enabled {
			b.blocklists[list.key] = &Blocklist{
				Name:    list.name,
				URL:     list.url,
				Enabled: true,
			}
		}
	}
}

func (b *ExternalBlocklistManager) Start() error {
	if !b.config.EnableExternalBlocklists {
		logger.Debug("blocklist", "External blocklists disabled in config")
		return nil
	}

	logger.Info("blocklist", "Starting external blocklist manager")

	// Initial update
	b.wg.Add(1)
	go func() {
		defer b.wg.Done()
		b.updateAllBlocklists()
	}()

	// Start periodic updates
	b.wg.Add(1)
	go func() {
		defer b.wg.Done()
		b.startPeriodicUpdates()
	}()

	return nil
}

func (b *ExternalBlocklistManager) startPeriodicUpdates() {
	ticker := time.NewTicker(b.config.BlocklistUpdateInterval)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			b.updateAllBlocklists()
		case <-b.stopCh:
			return
		}
	}
}

func (b *ExternalBlocklistManager) updateAllBlocklists() {
	logger.Info("blocklist", "Starting blocklist update")

	var wg sync.WaitGroup
	semaphore := make(chan struct{}, 3) // Limit concurrent downloads

	for name, blocklist := range b.blocklists {
		if !blocklist.Enabled {
			continue
		}

		wg.Add(1)
		semaphore <- struct{}{}

		go func(name string, blocklist *Blocklist) {
			defer wg.Done()
			defer func() { <-semaphore }()

			ctx, cancel := context.WithTimeout(context.Background(), 2*time.Minute)
			defer cancel()

			b.updateBlocklist(ctx, name, blocklist)
		}(name, blocklist)
	}

	wg.Wait()
	logger.Info("blocklist", "Blocklist update completed")
}

func (b *ExternalBlocklistManager) updateBlocklist(ctx context.Context, name string, blocklist *Blocklist) {
	startTime := time.Now()
	logger.Info("blocklist", "Updating blocklist", "name", name, "url", blocklist.URL)

	req, err := http.NewRequestWithContext(ctx, "GET", blocklist.URL, nil)
	if err != nil {
		logger.Error("blocklist", "Failed to create request", "name", name, "error", err)
		return
	}

	req.Header.Set("User-Agent", "QFF-IPS/1.0")
	req.Header.Set("Accept", "text/plain")

	resp, err := b.client.Do(req)
	if err != nil {
		b.handleBlocklistError(name, blocklist, err)
		return
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		b.handleBlocklistError(name, blocklist, fmt.Errorf("unexpected status code: %d", resp.StatusCode))
		return
	}

	ips, err := b.parseBlocklist(resp.Body, name)
	if err != nil {
		b.handleBlocklistError(name, blocklist, err)
		return
	}

	if len(ips) == 0 {
		logger.Warn("blocklist", "Empty blocklist received", "name", name)
		return
	}

	// Update firewall rules
	b.applyBlocklist(name, ips)

	// Update metadata
	b.mu.Lock()
	blocklist.LastUpdate = time.Now()
	blocklist.IPCount = len(ips)
	blocklist.ErrorCount = 0 // Reset error count on success
	b.mu.Unlock()

	logger.Info("blocklist", "Blocklist updated",
		"name", name,
		"ips", len(ips),
		"duration", time.Since(startTime).String())
}

func (b *ExternalBlocklistManager) handleBlocklistError(name string, blocklist *Blocklist, err error) {
	b.mu.Lock()
	blocklist.ErrorCount++
	if blocklist.ErrorCount > 3 {
		blocklist.Enabled = false
		logger.Warn("blocklist", "Disabling blocklist after consecutive failures",
			"name", name,
			"errors", blocklist.ErrorCount)
	}
	b.mu.Unlock()

	logger.Error("blocklist", "Failed to update blocklist",
		"name", name,
		"error", err.Error(),
		"consecutive_errors", blocklist.ErrorCount)
}

func (b *ExternalBlocklistManager) parseBlocklist(body io.Reader, listName string) ([]net.IP, error) {
	var ips []net.IP
	scanner := bufio.NewScanner(body)
	uniqueIPs := make(map[string]struct{})

	for scanner.Scan() {
		line := strings.TrimSpace(scanner.Text())

		// Skip comments and empty lines
		if line == "" || line[0] == '#' || line[0] == ';' {
			continue
		}

		// Extract IP/CIDR from line
		ipStr := line
		if parts := strings.SplitN(line, ";", 2); len(parts) > 0 {
			ipStr = strings.TrimSpace(parts[0])
		}

		// Parse IP or CIDR
		var ip net.IP
		if strings.Contains(ipStr, "/") {
			_, cidr, err := net.ParseCIDR(ipStr)
			if err != nil {
				continue
			}
			ip = cidr.IP
		} else {
			ip = net.ParseIP(ipStr)
			if ip == nil {
				continue
			}
		}

		// Deduplicate
		ipStr = ip.String()
		if _, exists := uniqueIPs[ipStr]; !exists {
			uniqueIPs[ipStr] = struct{}{}
			ips = append(ips, ip)
		}
	}

	if err := scanner.Err(); err != nil {
		return nil, fmt.Errorf("scan error: %w", err)
	}

	return ips, nil
}

func (b *ExternalBlocklistManager) applyBlocklist(name string, ips []net.IP) {
	setName := fmt.Sprintf("blocklist_%s", strings.ReplaceAll(name, " ", "_"))

	// Remove old entries
	if err := b.ipsManager.firewall.RemoveBlocklistSet(setName); err != nil {
		logger.Error("blocklist", "Failed to remove old blocklist",
			"name", name,
			"error", err.Error())
		return
	}

	// Add new entries in batches
	for i := 0; i < len(ips); i += defaultBatchSize {
		end := i + defaultBatchSize
		if end > len(ips) {
			end = len(ips)
		}

		batch := ips[i:end]
		if err := b.ipsManager.firewall.AddBlocklistSet(setName, batch); err != nil {
			logger.Error("blocklist", "Failed to add blocklist batch",
				"name", name,
				"batch", fmt.Sprintf("%d-%d", i, end-1),
				"error", err.Error())
			// Continue with next batch despite error
		}

		time.Sleep(defaultBatchDelay)
	}
}

func (b *ExternalBlocklistManager) IsIPBlocked(ip net.IP) (bool, string) {
	// This should be implemented by querying your firewall's state
	// For example, if using nftables, you would check if IP exists in any blocklist set
	return false, ""
}

func (b *ExternalBlocklistManager) Stop() {
	close(b.stopCh)
	b.wg.Wait()
	logger.Info("blocklist", "External blocklist manager stopped")
}

func (b *ExternalBlocklistManager) GetStats() map[string]interface{} {
	b.mu.RLock()
	defer b.mu.RUnlock()

	stats := map[string]interface{}{
		"enabled":    b.config.EnableExternalBlocklists,
		"blocklists": len(b.blocklists),
		"active":     0,
		"total_ips":  0,
	}

	blocklistStats := make(map[string]interface{})
	activeCount := 0
	totalIPs := 0

	for name, blocklist := range b.blocklists {
		blocklistStats[name] = map[string]interface{}{
			"enabled":     blocklist.Enabled,
			"last_update": blocklist.LastUpdate,
			"ip_count":    blocklist.IPCount,
			"error_count": blocklist.ErrorCount,
			"source":      blocklist.URL,
		}
		if blocklist.Enabled {
			activeCount++
			totalIPs += blocklist.IPCount
		}
	}

	stats["blocklist_details"] = blocklistStats
	stats["active"] = activeCount
	stats["total_ips"] = totalIPs

	return stats
}

func (b *ExternalBlocklistManager) GetBlocklists() map[string]*Blocklist {
	b.mu.RLock()
	defer b.mu.RUnlock()

	result := make(map[string]*Blocklist, len(b.blocklists))
	for k, v := range b.blocklists {
		// Return a copy to avoid concurrent modification
		bl := *v
		result[k] = &bl
	}
	return result
}
// internal/ips/filesystem.go
package ips

import (
	"crypto/md5"
	"fmt"
	"io"
	"os"
	"path/filepath"
	"sync"
	"time"

	"qff/internal/config"
	"qff/internal/logger"
)

type FileSystemMonitor struct {
	config     *config.IPSConfig
	ipsManager *IPSManager
	fileHashes map[string]string
	mu         sync.RWMutex
	stopCh     chan struct{}
}

type FileChange struct {
	Path      string
	OldHash   string
	NewHash   string
	Timestamp time.Time
	Action    string // "modified", "deleted", "created"
}

func NewFileSystemMonitor(cfg *config.IPSConfig, ipsManager *IPSManager) *FileSystemMonitor {
	return &FileSystemMonitor{
		config:     cfg,
		ipsManager: ipsManager,
		fileHashes: make(map[string]string),
		stopCh:     make(chan struct{}),
	}
}

func (f *FileSystemMonitor) Start() error {
	if !f.config.EnableFileSystemMonitor {
		return nil
	}

	logger.Info("filesystem", "Starting file system monitor")

	// Set default critical files if not configured
	f.setDefaultCriticalFiles()

	// Initial scan
	f.scanFiles()

	// Start periodic monitoring
	go f.startMonitoring()

	return nil
}

func (f *FileSystemMonitor) setDefaultCriticalFiles() {
	if len(f.config.CriticalFiles) == 0 {
		f.config.CriticalFiles = []string{
			"/etc/passwd",
			"/etc/shadow",
			"/etc/sudoers",
			"/etc/hosts",
			"/etc/ssh/sshd_config",
			"/etc/crontab",
			"/root/.ssh/authorized_keys",
		}
	}

	if len(f.config.CriticalDirectories) == 0 {
		f.config.CriticalDirectories = []string{
			"/bin",
			"/sbin",
			"/usr/bin",
			"/usr/sbin",
		}
	}

	if f.config.FileCheckInterval == 0 {
		f.config.FileCheckInterval = 5 * time.Minute
	}
}

func (f *FileSystemMonitor) startMonitoring() {
	ticker := time.NewTicker(f.config.FileCheckInterval)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			f.checkChanges()
		case <-f.stopCh:
			return
		}
	}
}

func (f *FileSystemMonitor) scanFiles() {
	f.mu.Lock()
	defer f.mu.Unlock()

	// Scan critical files
	for _, filePath := range f.config.CriticalFiles {
		if hash := f.calculateFileHash(filePath); hash != "" {
			f.fileHashes[filePath] = hash
		}
	}

	// Scan critical directories
	for _, dirPath := range f.config.CriticalDirectories {
		filepath.Walk(dirPath, func(path string, info os.FileInfo, err error) error {
			if err != nil {
				return nil
			}

			if !info.IsDir() {
				if hash := f.calculateFileHash(path); hash != "" {
					f.fileHashes[path] = hash
				}
			}
			return nil
		})
	}

	logger.Info("filesystem", "Initial file scan completed", "files", len(f.fileHashes))
}

func (f *FileSystemMonitor) checkChanges() {
	f.mu.Lock()
	defer f.mu.Unlock()

	changes := []FileChange{}

	// Check existing files
	for filePath, oldHash := range f.fileHashes {
		newHash := f.calculateFileHash(filePath)

		if newHash == "" {
			// File deleted
			changes = append(changes, FileChange{
				Path:      filePath,
				OldHash:   oldHash,
				NewHash:   "",
				Timestamp: time.Now(),
				Action:    "deleted",
			})
			delete(f.fileHashes, filePath)
		} else if newHash != oldHash {
			// File modified
			changes = append(changes, FileChange{
				Path:      filePath,
				OldHash:   oldHash,
				NewHash:   newHash,
				Timestamp: time.Now(),
				Action:    "modified",
			})
			f.fileHashes[filePath] = newHash
		}
	}

	// Check for new files in critical directories
	for _, dirPath := range f.config.CriticalDirectories {
		filepath.Walk(dirPath, func(path string, info os.FileInfo, err error) error {
			if err != nil {
				return nil
			}

			if !info.IsDir() {
				if _, exists := f.fileHashes[path]; !exists {
					if hash := f.calculateFileHash(path); hash != "" {
						changes = append(changes, FileChange{
							Path:      path,
							OldHash:   "",
							NewHash:   hash,
							Timestamp: time.Now(),
							Action:    "created",
						})
						f.fileHashes[path] = hash
					}
				}
			}
			return nil
		})
	}

	// Process changes
	for _, change := range changes {
		f.handleFileChange(change)
	}
}

func (f *FileSystemMonitor) calculateFileHash(filePath string) string {
	file, err := os.Open(filePath)
	if err != nil {
		return ""
	}
	defer file.Close()

	hash := md5.New()
	if _, err := io.Copy(hash, file); err != nil {
		return ""
	}

	return fmt.Sprintf("%x", hash.Sum(nil))
}

func (f *FileSystemMonitor) handleFileChange(change FileChange) {
	logger.Warn("filesystem", "Critical file change detected",
		"path", change.Path,
		"action", change.Action,
		"timestamp", change.Timestamp)

	// Send alert
	data := map[string]interface{}{
		"path":      change.Path,
		"action":    change.Action,
		"timestamp": change.Timestamp,
		"old_hash":  change.OldHash,
		"new_hash":  change.NewHash,
	}

	message := fmt.Sprintf("SECURITY: Critical file %s: %s", change.Action, change.Path)
	f.ipsManager.notifier.SendAlert(message, data)
}

func (f *FileSystemMonitor) Stop() {
	close(f.stopCh)
}

func (f *FileSystemMonitor) GetStats() map[string]interface{} {
	f.mu.RLock()
	defer f.mu.RUnlock()

	return map[string]interface{}{
		"monitored_files": len(f.fileHashes),
		"enabled":         f.config.EnableFileSystemMonitor,
		"critical_files":  len(f.config.CriticalFiles),
		"critical_dirs":   len(f.config.CriticalDirectories),
	}
}
// internal/ips/ips.go
package ips

import (
	"bufio"
	"fmt"
	"net"
	"os"
	"regexp"
	"strings"
	"sync"
	"time"

	"qff/internal/config"
	"qff/internal/firewall"
	"qff/internal/geoip"
	"qff/internal/logger"
	"qff/internal/notify"
)

type IPSManager struct {
	config            *config.IPSConfig
	firewall          *firewall.NFTManager
	notifier          *notify.Notifier
	geoipManager      *geoip.EnhancedGeoIPManager
	blockedIPs        map[string]*BlockEntry
	tempWhitelist     map[string]*WhitelistEntry
	attackCounters    map[string]*AttackCounter
	mu                sync.RWMutex
	stopCh            chan struct{}
	logPatterns       map[string]*DetectionRule
	portScanDetector  *PortScanDetector
	fileSystemMonitor *FileSystemMonitor
	processMonitor    *ProcessMonitor
	blocklistManager  *ExternalBlocklistManager
}

type BlockEntry struct {
	IP         net.IP
	Reason     string
	Service    string
	BlockTime  time.Time
	ExpiryTime *time.Time
	Permanent  bool
	HitCount   int
	LastSeen   time.Time
}

type WhitelistEntry struct {
	IP         net.IP
	ExpiryTime *time.Time
	Permanent  bool
	Reason     string
	AddedTime  time.Time
}

type AttackCounter struct {
	IP         net.IP
	Service    string
	Count      int
	FirstSeen  time.Time
	LastSeen   time.Time
	LogEntries []string
}

type DetectionRule struct {
	Name       string
	Service    string
	Pattern    *regexp.Regexp
	Threshold  int
	TimeWindow time.Duration
	LogFiles   []string
}

func NewIPSManager(cfg *config.IPSConfig, fw *firewall.NFTManager, notifier *notify.Notifier, geoipMgr *geoip.EnhancedGeoIPManager) *IPSManager {
	ips := &IPSManager{
		config:         cfg,
		firewall:       fw,
		notifier:       notifier,
		geoipManager:   geoipMgr,
		blockedIPs:     make(map[string]*BlockEntry),
		tempWhitelist:  make(map[string]*WhitelistEntry),
		attackCounters: make(map[string]*AttackCounter),
		stopCh:         make(chan struct{}),
		logPatterns:    make(map[string]*DetectionRule),
	}

	ips.portScanDetector = NewPortScanDetector(cfg, ips)
	ips.fileSystemMonitor = NewFileSystemMonitor(cfg, ips)
	ips.processMonitor = NewProcessMonitor(cfg, ips)
	ips.blocklistManager = NewExternalBlocklistManager(cfg, ips)

	ips.initializePatterns()
	return ips
}

func (i *IPSManager) initializePatterns() {
	// Set default log files if not configured
	i.setDefaultLogFiles()

	// cPanel login failures
	i.logPatterns["cpanel_failed"] = &DetectionRule{
		Name:       "cPanel Failed Login",
		Service:    "cpanel",
		Pattern:    regexp.MustCompile(`\[info\] .* FAILED LOGIN .* from (\d+\.\d+\.\d+\.\d+)`),
		Threshold:  i.config.CPanelFailedLogins,
		TimeWindow: i.config.CPanelTimeWindow,
		LogFiles:   i.config.CPanelLogFiles,
	}

	// DirectAdmin login failures
	i.logPatterns["directadmin_failed"] = &DetectionRule{
		Name:       "DirectAdmin Failed Login",
		Service:    "directadmin",
		Pattern:    regexp.MustCompile(`SECURITY_VIOLATION\|([0-9.]+)\|.*\|LOGIN_FAILED`),
		Threshold:  i.config.DirectAdminFailedLogins,
		TimeWindow: i.config.DirectAdminTimeWindow,
		LogFiles:   i.config.DirectAdminLogFiles,
	}

	// WordPress login failures
	i.logPatterns["wordpress_failed"] = &DetectionRule{
		Name:       "WordPress Failed Login",
		Service:    "wordpress",
		Pattern:    regexp.MustCompile(`authentication failure.*rhost=(\d+\.\d+\.\d+\.\d+)`),
		Threshold:  i.config.WordPressFailedLogins,
		TimeWindow: i.config.WordPressTimeWindow,
		LogFiles:   i.config.AuthLogFiles,
	}

	// Apache scanning
	i.logPatterns["apache_scan"] = &DetectionRule{
		Name:       "Apache 404 Scanning",
		Service:    "web",
		Pattern:    regexp.MustCompile(`(\d+\.\d+\.\d+\.\d+) .* "GET .* HTTP/1\.[01]" 404`),
		Threshold:  10,
		TimeWindow: 2 * time.Minute,
		LogFiles:   i.config.ApacheLogFiles,
	}

	// Nginx scanning
	i.logPatterns["nginx_scan"] = &DetectionRule{
		Name:       "Nginx 404 Scanning",
		Service:    "web",
		Pattern:    regexp.MustCompile(`(\d+\.\d+\.\d+\.\d+) .* "GET .* HTTP/1\.[01]" 404`),
		Threshold:  10,
		TimeWindow: 2 * time.Minute,
		LogFiles:   i.config.NginxLogFiles,
	}

	// FTP brute force
	i.logPatterns["ftp_failed"] = &DetectionRule{
		Name:       "FTP Failed Login",
		Service:    "ftp",
		Pattern:    regexp.MustCompile(`FAIL LOGIN.*Client "(\d+\.\d+\.\d+\.\d+)"`),
		Threshold:  3,
		TimeWindow: 5 * time.Minute,
		LogFiles:   i.config.FTPLogFiles,
	}

	// SMTP Authentication failures
	i.logPatterns["smtp_auth_failed"] = &DetectionRule{
		Name:       "SMTP Auth Failed",
		Service:    "smtp",
		Pattern:    regexp.MustCompile(`warning: [^[]*\[(\d+\.\d+\.\d+\.\d+)\]: SASL.*authentication failed`),
		Threshold:  5,
		TimeWindow: 15 * time.Minute,
		LogFiles:   i.config.MailLogFiles,
	}

	// SQL Injection (Apache)
	i.logPatterns["apache_sql_injection"] = &DetectionRule{
		Name:       "SQL Injection Attempt",
		Service:    "web",
		Pattern:    regexp.MustCompile(`(\d+\.\d+\.\d+\.\d+).*"[^"]*(?:union|select|insert|delete|update|drop|create|alter).*(?:from|where|join).*"`),
		Threshold:  1,
		TimeWindow: 1 * time.Minute,
		LogFiles:   i.config.ApacheLogFiles,
	}

	// SQL Injection (Nginx)
	i.logPatterns["nginx_sql_injection"] = &DetectionRule{
		Name:       "SQL Injection Attempt",
		Service:    "web",
		Pattern:    regexp.MustCompile(`(\d+\.\d+\.\d+\.\d+).*"[^"]*(?:union|select|insert|delete|update|drop|create|alter).*(?:from|where|join).*"`),
		Threshold:  1,
		TimeWindow: 1 * time.Minute,
		LogFiles:   i.config.NginxLogFiles,
	}

	// Shell Upload (Apache)
	i.logPatterns["apache_shell_upload"] = &DetectionRule{
		Name:       "Shell Upload Attempt",
		Service:    "web",
		Pattern:    regexp.MustCompile(`(\d+\.\d+\.\d+\.\d+).*"POST.*\.(?:php|asp|jsp|sh).*"`),
		Threshold:  1,
		TimeWindow: 1 * time.Minute,
		LogFiles:   i.config.ApacheLogFiles,
	}

	// Shell Upload (Nginx)
	i.logPatterns["nginx_shell_upload"] = &DetectionRule{
		Name:       "Shell Upload Attempt",
		Service:    "web",
		Pattern:    regexp.MustCompile(`(\d+\.\d+\.\d+\.\d+).*"POST.*\.(?:php|asp|jsp|sh).*"`),
		Threshold:  1,
		TimeWindow: 1 * time.Minute,
		LogFiles:   i.config.NginxLogFiles,
	}
}

func (i *IPSManager) Start() error {
	if !i.config.EnableIPS {
		return nil
	}

	logger.Info("ips", "Starting IPS manager")

	// Auto-whitelist current SSH session
	if i.config.AutoWhitelistSSH {
		i.autoWhitelistSSHSessions()
	}

	// Start Phase 1 components
	go i.startLogMonitoring()
	go i.startCleanupRoutine()

	// Start Phase 2 components
	if err := i.portScanDetector.Start(); err != nil {
		logger.Error("ips", "Failed to start port scan detector", "error", err.Error())
	}

	if err := i.fileSystemMonitor.Start(); err != nil {
		logger.Error("ips", "Failed to start filesystem monitor", "error", err.Error())
	}

	if err := i.processMonitor.Start(); err != nil {
		logger.Error("ips", "Failed to start process monitor", "error", err.Error())
	}

	if err := i.blocklistManager.Start(); err != nil {
		logger.Error("ips", "Failed to start blocklist manager", "error", err.Error())
	}

	return nil
}

func (i *IPSManager) setDefaultLogFiles() {
	if len(i.config.CPanelLogFiles) == 0 {
		i.config.CPanelLogFiles = []string{"/usr/local/cpanel/logs/login_log", "/usr/local/cpanel/logs/access_log"}
	}

	if len(i.config.DirectAdminLogFiles) == 0 {
		i.config.DirectAdminLogFiles = []string{"/var/log/directadmin/security.log", "/var/log/directadmin/login.log"}
	}

	if len(i.config.ApacheLogFiles) == 0 {
		i.config.ApacheLogFiles = []string{"/var/log/apache2/access.log", "/var/log/httpd/access_log"}
	}

	if len(i.config.NginxLogFiles) == 0 {
		i.config.NginxLogFiles = []string{"/var/log/nginx/access.log"}
	}

	if len(i.config.MailLogFiles) == 0 {
		i.config.MailLogFiles = []string{"/var/log/mail.log", "/var/log/maillog"}
	}

	if len(i.config.FTPLogFiles) == 0 {
		i.config.FTPLogFiles = []string{"/var/log/vsftpd.log", "/var/log/proftpd/proftpd.log"}
	}

	if len(i.config.AuthLogFiles) == 0 {
		i.config.AuthLogFiles = []string{"/var/log/auth.log", "/var/log/secure"}
	}
}

func (i *IPSManager) autoWhitelistSSHSessions() {
	sshClient := os.Getenv("SSH_CLIENT")
	if sshClient != "" {
		parts := strings.Fields(sshClient)
		if len(parts) > 0 {
			ip := net.ParseIP(parts[0])
			if ip != nil && !ip.IsLoopback() {
				expiryTime := time.Now().Add(i.config.SSHWhitelistDuration)
				i.addTempWhitelist(ip, &expiryTime, "Auto SSH session")
				logger.Info("ips", "Auto-whitelisted SSH session", "ip", ip.String(), "expires", expiryTime)
			}
		}
	}
}

func (i *IPSManager) addTempWhitelist(ip net.IP, expiryTime *time.Time, reason string) {
	i.mu.Lock()
	defer i.mu.Unlock()

	key := ip.String()
	i.tempWhitelist[key] = &WhitelistEntry{
		IP:         ip,
		ExpiryTime: expiryTime,
		Permanent:  expiryTime == nil,
		Reason:     reason,
		AddedTime:  time.Now(),
	}

	// Add to firewall whitelist
	i.firewall.AddWhitelistIP(ip)
}

func (i *IPSManager) startLogMonitoring() {
	ticker := time.NewTicker(i.config.LogCheckInterval)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			i.processLogs()
		case <-i.stopCh:
			return
		}
	}
}

func (i *IPSManager) processLogs() {
	for _, rule := range i.logPatterns {
		for _, logFile := range rule.LogFiles {
			i.processLogFile(rule, logFile)
		}
	}
}

func (i *IPSManager) processLogFile(rule *DetectionRule, logFile string) {
	file, err := os.Open(logFile)
	if err != nil {
		// Log file doesn't exist, skip silently
		return
	}
	defer file.Close()

	// Read last N lines (simple implementation - can be optimized)
	scanner := bufio.NewScanner(file)
	var lines []string
	for scanner.Scan() {
		lines = append(lines, scanner.Text())
	}

	// Process recent entries (last 100 lines)
	start := len(lines) - 100
	if start < 0 {
		start = 0
	}

	for _, line := range lines[start:] {
		i.processLogLine(line, rule)
	}
}

func (i *IPSManager) processLogLine(line string, rule *DetectionRule) {
	matches := rule.Pattern.FindStringSubmatch(line)
	if len(matches) < 2 {
		return
	}

	ipStr := matches[1]
	ip := net.ParseIP(ipStr)
	if ip == nil {
		return
	}

	// Check if IP is whitelisted
	if i.isWhitelisted(ip) {
		return
	}

	// Enhanced GeoIP check per service
	if i.geoipManager != nil {
		decision := i.geoipManager.CheckServiceAccess(ip, rule.Service)
		if !decision.Allow {
			logger.Info("ips", "IP blocked by enhanced GeoIP",
				"ip", ip.String(),
				"service", rule.Service,
				"reason", decision.Reason,
				"country", decision.Country,
				"vpn", decision.IsVPN,
				"proxy", decision.IsProxy)

			// Block immediately for GeoIP/VPN violations
			i.blockIP(ip, decision.Reason, rule.Service, false)
			return
		}
	}

	// Track attack
	i.trackAttack(ip, rule.Service, line)

	// Check if threshold exceeded
	if i.shouldBlock(ip, rule) {
		i.blockIP(ip, rule.Name, rule.Service, false)
	}
}

func (i *IPSManager) isWhitelisted(ip net.IP) bool {
	i.mu.RLock()
	defer i.mu.RUnlock()

	key := ip.String()
	entry, exists := i.tempWhitelist[key]
	if !exists {
		return false
	}

	// Check if temporary whitelist expired
	if entry.ExpiryTime != nil && time.Now().After(*entry.ExpiryTime) {
		delete(i.tempWhitelist, key)
		i.firewall.RemoveWhitelistIP(ip)
		return false
	}

	return true
}

func (i *IPSManager) trackAttack(ip net.IP, service, logEntry string) {
	i.mu.Lock()
	defer i.mu.Unlock()

	key := fmt.Sprintf("%s:%s", ip.String(), service)
	counter, exists := i.attackCounters[key]

	if !exists {
		counter = &AttackCounter{
			IP:         ip,
			Service:    service,
			Count:      0,
			FirstSeen:  time.Now(),
			LogEntries: []string{},
		}
		i.attackCounters[key] = counter
	}

	counter.Count++
	counter.LastSeen = time.Now()
	counter.LogEntries = append(counter.LogEntries, logEntry)

	// Keep only last 10 log entries
	if len(counter.LogEntries) > 10 {
		counter.LogEntries = counter.LogEntries[1:]
	}
}

func (i *IPSManager) shouldBlock(ip net.IP, rule *DetectionRule) bool {
	i.mu.RLock()
	defer i.mu.RUnlock()

	key := fmt.Sprintf("%s:%s", ip.String(), rule.Service)
	counter, exists := i.attackCounters[key]
	if !exists {
		return false
	}

	// Check if within time window and exceeded threshold
	if time.Since(counter.FirstSeen) <= rule.TimeWindow && counter.Count >= rule.Threshold {
		return true
	}

	return false
}

func (i *IPSManager) blockIP(ip net.IP, reason, service string, permanent bool) {
	i.mu.Lock()
	defer i.mu.Unlock()

	key := ip.String()

	// Check if already blocked
	if _, exists := i.blockedIPs[key]; exists {
		return
	}

	var expiryTime *time.Time
	if !permanent {
		expiry := time.Now().Add(i.config.TempBlockDuration)
		expiryTime = &expiry
	}

	entry := &BlockEntry{
		IP:         ip,
		Reason:     reason,
		Service:    service,
		BlockTime:  time.Now(),
		ExpiryTime: expiryTime,
		Permanent:  permanent,
		HitCount:   1,
		LastSeen:   time.Now(),
	}

	i.blockedIPs[key] = entry

	// Add to firewall
	i.firewall.AddBlacklistIP(ip)

	// Send notification
	if i.config.EnableBlockNotifications {
		i.sendBlockNotification(entry)
	}

	logger.Info("ips", "Blocked IP", "ip", ip.String(), "reason", reason, "service", service, "permanent", permanent)
}

func (i *IPSManager) sendBlockNotification(entry *BlockEntry) {
	// Get attack details
	key := fmt.Sprintf("%s:%s", entry.IP.String(), entry.Service)
	counter := i.attackCounters[key]

	data := map[string]interface{}{
		"ip":         entry.IP.String(),
		"reason":     entry.Reason,
		"service":    entry.Service,
		"permanent":  entry.Permanent,
		"block_time": entry.BlockTime,
	}

	if counter != nil {
		data["attack_count"] = counter.Count
		data["first_seen"] = counter.FirstSeen
		data["log_sample"] = counter.LogEntries[len(counter.LogEntries)-1]
	}

	message := fmt.Sprintf("IPS: Blocked %s for %s (%s)", entry.IP.String(), entry.Reason, entry.Service)
	i.notifier.SendAlert(message, data)
}

func (i *IPSManager) startCleanupRoutine() {
	ticker := time.NewTicker(5 * time.Minute)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			i.cleanupExpiredEntries()
		case <-i.stopCh:
			return
		}
	}
}

func (i *IPSManager) cleanupExpiredEntries() {
	i.mu.Lock()
	defer i.mu.Unlock()

	now := time.Now()

	// Cleanup expired blocks
	for key, entry := range i.blockedIPs {
		if entry.ExpiryTime != nil && now.After(*entry.ExpiryTime) {
			i.firewall.RemoveBlacklistIP(entry.IP)
			delete(i.blockedIPs, key)
			logger.Info("ips", "Unblocked expired IP", "ip", entry.IP.String())
		}
	}

	// Cleanup expired whitelists
	for key, entry := range i.tempWhitelist {
		if entry.ExpiryTime != nil && now.After(*entry.ExpiryTime) {
			i.firewall.RemoveWhitelistIP(entry.IP)
			delete(i.tempWhitelist, key)
			logger.Info("ips", "Removed expired whitelist", "ip", entry.IP.String())
		}
	}

	// Cleanup old attack counters
	for key, counter := range i.attackCounters {
		if now.Sub(counter.LastSeen) > 1*time.Hour {
			delete(i.attackCounters, key)
		}
	}
}

func (i *IPSManager) GetBlockedIPs() map[string]*BlockEntry {
	i.mu.RLock()
	defer i.mu.RUnlock()

	result := make(map[string]*BlockEntry)
	for k, v := range i.blockedIPs {
		result[k] = v
	}
	return result
}

func (i *IPSManager) Stop() {
	close(i.stopCh)

	// Stop Phase 2 components
	if i.portScanDetector != nil {
		i.portScanDetector.Stop()
	}
	if i.fileSystemMonitor != nil {
		i.fileSystemMonitor.Stop()
	}
	if i.processMonitor != nil {
		i.processMonitor.Stop()
	}
	if i.blocklistManager != nil {
		i.blocklistManager.Stop()
	}
}

func (i *IPSManager) UnblockIP(ip net.IP) error {
	i.mu.Lock()
	defer i.mu.Unlock()

	key := ip.String()
	entry, exists := i.blockedIPs[key]
	if !exists {
		return fmt.Errorf("IP not blocked")
	}

	// Remove from firewall
	if err := i.firewall.RemoveBlacklistIP(ip); err != nil {
		return err
	}

	// Remove from blocked list
	delete(i.blockedIPs, key)

	logger.Info("ips", "Manually unblocked IP", "ip", ip.String(), "reason", entry.Reason)
	return nil
}

func (i *IPSManager) RemoveWhitelist(ip net.IP) error {
	i.mu.Lock()
	defer i.mu.Unlock()

	key := ip.String()
	_, exists := i.tempWhitelist[key]
	if !exists {
		return fmt.Errorf("IP not whitelisted")
	}

	// Remove from whitelist
	delete(i.tempWhitelist, key)

	logger.Info("ips", "Removed whitelist", "ip", ip.String())
	return nil
}

func (i *IPSManager) GetWhitelistedIPs() map[string]*WhitelistEntry {
	i.mu.RLock()
	defer i.mu.RUnlock()

	result := make(map[string]*WhitelistEntry)
	for k, v := range i.tempWhitelist {
		result[k] = v
	}
	return result
}

func (i *IPSManager) AddWhitelist(ip net.IP, permanent bool, reason string) error {
	var expiryTime *time.Time
	if !permanent {
		expiry := time.Now().Add(i.config.SSHWhitelistDuration)
		expiryTime = &expiry
	}

	i.addTempWhitelist(ip, expiryTime, reason)
	logger.Info("ips", "Added whitelist", "ip", ip.String(), "permanent", permanent, "reason", reason)
	return nil
}

func (i *IPSManager) GetStats() map[string]interface{} {
	i.mu.RLock()
	defer i.mu.RUnlock()

	stats := map[string]interface{}{
		"blocked_count":     len(i.blockedIPs),
		"whitelisted_count": len(i.tempWhitelist),
		"attack_counters":   len(i.attackCounters),
		"enabled":           i.config.EnableIPS,
		"patterns_loaded":   len(i.logPatterns),
	}

	// Add Phase 2 stats
	if i.portScanDetector != nil {
		stats["port_scan_detector"] = i.portScanDetector.GetStats()
	}
	if i.fileSystemMonitor != nil {
		stats["filesystem_monitor"] = i.fileSystemMonitor.GetStats()
	}
	if i.processMonitor != nil {
		stats["process_monitor"] = i.processMonitor.GetStats()
	}
	if i.blocklistManager != nil {
		stats["blocklist_manager"] = i.blocklistManager.GetStats()
	}

	// Count by service
	serviceStats := make(map[string]int)
	for _, entry := range i.blockedIPs {
		serviceStats[entry.Service]++
	}
	stats["blocked_by_service"] = serviceStats

	return stats
}
// internal/ips/portscan.go
package ips

import (
	"bufio"
	"fmt"
	"net"
	"os"
	"regexp"
	"strconv"
	"strings"
	"sync"
	"time"

	"qff/internal/config"
	"qff/internal/logger"
)

type PortScanDetector struct {
	config       *config.IPSConfig
	ipsManager   *IPSManager
	scanCounters map[string]*ScanCounter
	mu           sync.RWMutex
	stopCh       chan struct{}
}

type ScanCounter struct {
	IP            net.IP
	PortsScanned  map[int]bool
	FirstSeen     time.Time
	LastSeen      time.Time
	TotalAttempts int
}

func NewPortScanDetector(cfg *config.IPSConfig, ipsManager *IPSManager) *PortScanDetector {
	return &PortScanDetector{
		config:       cfg,
		ipsManager:   ipsManager,
		scanCounters: make(map[string]*ScanCounter),
		stopCh:       make(chan struct{}),
	}
}

func (p *PortScanDetector) Start() error {
	if !p.config.EnablePortScanDetection {
		return nil
	}

	logger.Info("portscan", "Starting port scan detector")

	go p.monitorNetstat()
	go p.monitorKernelLogs()
	go p.cleanupCounters()

	return nil
}

func (p *PortScanDetector) monitorNetstat() {
	ticker := time.NewTicker(30 * time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			p.checkConnections()
		case <-p.stopCh:
			return
		}
	}
}

func (p *PortScanDetector) checkConnections() {
	// Parse /proc/net/tcp for connection attempts
	file, err := os.Open("/proc/net/tcp")
	if err != nil {
		return
	}
	defer file.Close()

	scanner := bufio.NewScanner(file)
	scanner.Scan() // Skip header

	connectionCounts := make(map[string]int)

	for scanner.Scan() {
		line := scanner.Text()
		fields := strings.Fields(line)
		if len(fields) < 4 {
			continue
		}

		// Parse remote address
		remoteAddr := fields[2]
		if ipStr := p.parseIPFromHex(remoteAddr); ipStr != "" {
			connectionCounts[ipStr]++
		}
	}

	// Check for suspicious connection patterns
	for ipStr, count := range connectionCounts {
		if count > 20 { // Threshold for suspicious activity
			ip := net.ParseIP(ipStr)
			if ip != nil {
				p.trackScan(ip, 0, "Multiple connection attempts")
			}
		}
	}
}

func (p *PortScanDetector) parseIPFromHex(hexAddr string) string {
	parts := strings.Split(hexAddr, ":")
	if len(parts) != 2 {
		return ""
	}

	// Convert hex IP to dotted decimal
	hexIP := parts[0]
	if len(hexIP) != 8 {
		return ""
	}

	var ip []byte
	for i := 0; i < 8; i += 2 {
		b, err := strconv.ParseUint(hexIP[i:i+2], 16, 8)
		if err != nil {
			return ""
		}
		ip = append(ip, byte(b))
	}

	// Reverse byte order (little endian)
	return fmt.Sprintf("%d.%d.%d.%d", ip[3], ip[2], ip[1], ip[0])
}

func (p *PortScanDetector) monitorKernelLogs() {
	ticker := time.NewTicker(10 * time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			p.checkKernelLogs()
		case <-p.stopCh:
			return
		}
	}
}

func (p *PortScanDetector) checkKernelLogs() {
	// Monitor dmesg for dropped packets that might indicate scanning
	file, err := os.Open("/var/log/kern.log")
	if err != nil {
		return
	}
	defer file.Close()

	scanner := bufio.NewScanner(file)

	// SYN flood pattern
	synPattern := regexp.MustCompile(`SRC=(\d+\.\d+\.\d+\.\d+).*DPT=(\d+).*SYN`)

	var lines []string
	for scanner.Scan() {
		lines = append(lines, scanner.Text())
	}

	// Process last 50 lines
	start := len(lines) - 50
	if start < 0 {
		start = 0
	}

	for _, line := range lines[start:] {
		if matches := synPattern.FindStringSubmatch(line); len(matches) >= 3 {
			ip := net.ParseIP(matches[1])
			if port, err := strconv.Atoi(matches[2]); err == nil && ip != nil {
				p.trackScan(ip, port, "SYN scan detected")
			}
		}
	}
}

func (p *PortScanDetector) trackScan(ip net.IP, port int, reason string) {
	p.mu.Lock()
	defer p.mu.Unlock()

	key := ip.String()
	counter, exists := p.scanCounters[key]

	if !exists {
		counter = &ScanCounter{
			IP:            ip,
			PortsScanned:  make(map[int]bool),
			FirstSeen:     time.Now(),
			TotalAttempts: 0,
		}
		p.scanCounters[key] = counter
	}

	counter.LastSeen = time.Now()
	counter.TotalAttempts++

	if port > 0 {
		counter.PortsScanned[port] = true
	}

	// Check if threshold exceeded
	if len(counter.PortsScanned) >= p.config.PortScanThreshold ||
		counter.TotalAttempts >= p.config.PortScanThreshold*2 {

		logger.Info("portscan", "Port scan detected", "ip", ip.String(), "ports", len(counter.PortsScanned), "attempts", counter.TotalAttempts)

		// Block the IP
		p.ipsManager.blockIP(ip, "Port scanning", "portscan", false)
	}
}

func (p *PortScanDetector) cleanupCounters() {
	ticker := time.NewTicker(10 * time.Minute)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			p.mu.Lock()
			now := time.Now()
			for key, counter := range p.scanCounters {
				if now.Sub(counter.LastSeen) > p.config.PortScanTimeWindow {
					delete(p.scanCounters, key)
				}
			}
			p.mu.Unlock()
		case <-p.stopCh:
			return
		}
	}
}

func (p *PortScanDetector) Stop() {
	close(p.stopCh)
}

func (p *PortScanDetector) GetStats() map[string]interface{} {
	p.mu.RLock()
	defer p.mu.RUnlock()

	return map[string]interface{}{
		"active_scanners": len(p.scanCounters),
		"enabled":         p.config.EnablePortScanDetection,
		"threshold":       p.config.PortScanThreshold,
	}
}
// internal/ips/process.go
package ips

import (
	"bufio"
	"fmt"
	"os"
	"regexp"
	"strconv"
	"strings"
	"sync"
	"syscall"
	"time"

	"qff/internal/config"
	"qff/internal/logger"
)

type ProcessMonitor struct {
	config          *config.IPSConfig
	ipsManager      *IPSManager
	suspiciousProcs map[int]*SuspiciousProcess
	patterns        []*regexp.Regexp
	mu              sync.RWMutex
	stopCh          chan struct{}
}

type SuspiciousProcess struct {
	PID       int
	Name      string
	Command   string
	User      string
	MemoryMB  int
	StartTime time.Time
	LastSeen  time.Time
	Reason    string
}

func NewProcessMonitor(cfg *config.IPSConfig, ipsManager *IPSManager) *ProcessMonitor {
	pm := &ProcessMonitor{
		config:          cfg,
		ipsManager:      ipsManager,
		suspiciousProcs: make(map[int]*SuspiciousProcess),
		stopCh:          make(chan struct{}),
	}

	pm.initializePatterns()
	return pm
}

func (p *ProcessMonitor) initializePatterns() {
	// Set default suspicious patterns if not configured
	if len(p.config.SuspiciousProcesses) == 0 {
		p.config.SuspiciousProcesses = []string{
			`perl /tmp/.*\.pl`,
			`php.*mailer`,
			`wget http.*\.php`,
			`curl.*\.sh`,
			`python.*backdoor`,
			`nc -l.*`,
			`/tmp/.*\.py`,
			`bash.*reverse`,
			`sh.*shell`,
			`.*\.php.*system`,
		}
	}

	if p.config.MaxProcessMemory == "" {
		p.config.MaxProcessMemory = "1GB"
	}

	if p.config.ProcessCheckInterval == 0 {
		p.config.ProcessCheckInterval = 1 * time.Minute
	}

	// Compile regex patterns
	for _, pattern := range p.config.SuspiciousProcesses {
		if regex, err := regexp.Compile(pattern); err == nil {
			p.patterns = append(p.patterns, regex)
		}
	}
}

func (p *ProcessMonitor) Start() error {
	if !p.config.EnableProcessMonitor {
		return nil
	}

	logger.Info("process", "Starting process monitor")

	go p.startMonitoring()
	go p.cleanupOldProcesses()

	return nil
}

func (p *ProcessMonitor) startMonitoring() {
	ticker := time.NewTicker(p.config.ProcessCheckInterval)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			p.scanProcesses()
		case <-p.stopCh:
			return
		}
	}
}

func (p *ProcessMonitor) scanProcesses() {
	processes, err := p.getProcessList()
	if err != nil {
		logger.Error("process", "Failed to get process list", "error", err.Error())
		return
	}

	for _, proc := range processes {
		p.analyzeProcess(proc)
	}
}

func (p *ProcessMonitor) getProcessList() ([]*ProcessInfo, error) {
	var processes []*ProcessInfo

	// Read /proc/*/stat for process information
	procDir, err := os.Open("/proc")
	if err != nil {
		return nil, err
	}
	defer procDir.Close()

	entries, err := procDir.Readdir(-1)
	if err != nil {
		return nil, err
	}

	for _, entry := range entries {
		if !entry.IsDir() {
			continue
		}

		// Check if directory name is a PID
		if pid, err := strconv.Atoi(entry.Name()); err == nil {
			if proc := p.readProcessInfo(pid); proc != nil {
				processes = append(processes, proc)
			}
		}
	}

	return processes, nil
}

type ProcessInfo struct {
	PID      int
	Name     string
	Command  string
	User     string
	MemoryKB int
}

func (p *ProcessMonitor) readProcessInfo(pid int) *ProcessInfo {
	// Read /proc/PID/stat
	statPath := fmt.Sprintf("/proc/%d/stat", pid)
	statFile, err := os.Open(statPath)
	if err != nil {
		return nil
	}
	defer statFile.Close()

	scanner := bufio.NewScanner(statFile)
	if !scanner.Scan() {
		return nil
	}

	fields := strings.Fields(scanner.Text())
	if len(fields) < 24 {
		return nil
	}

	name := strings.Trim(fields[1], "()")

	// Read command line
	cmdlinePath := fmt.Sprintf("/proc/%d/cmdline", pid)
	cmdline := p.readCmdline(cmdlinePath)

	// Read memory usage from /proc/PID/status
	memoryKB := p.readMemoryUsage(pid)

	// Read user from /proc/PID/status
	user := p.readProcessUser(pid)

	return &ProcessInfo{
		PID:      pid,
		Name:     name,
		Command:  cmdline,
		User:     user,
		MemoryKB: memoryKB,
	}
}

func (p *ProcessMonitor) readCmdline(path string) string {
	data, err := os.ReadFile(path)
	if err != nil {
		return ""
	}

	// Replace null bytes with spaces
	cmdline := strings.ReplaceAll(string(data), "\x00", " ")
	return strings.TrimSpace(cmdline)
}

func (p *ProcessMonitor) readMemoryUsage(pid int) int {
	statusPath := fmt.Sprintf("/proc/%d/status", pid)
	file, err := os.Open(statusPath)
	if err != nil {
		return 0
	}
	defer file.Close()

	scanner := bufio.NewScanner(file)
	for scanner.Scan() {
		line := scanner.Text()
		if strings.HasPrefix(line, "VmRSS:") {
			fields := strings.Fields(line)
			if len(fields) >= 2 {
				if kb, err := strconv.Atoi(fields[1]); err == nil {
					return kb
				}
			}
		}
	}
	return 0
}

func (p *ProcessMonitor) readProcessUser(pid int) string {
	statusPath := fmt.Sprintf("/proc/%d/status", pid)
	file, err := os.Open(statusPath)
	if err != nil {
		return ""
	}
	defer file.Close()

	scanner := bufio.NewScanner(file)
	for scanner.Scan() {
		line := scanner.Text()
		if strings.HasPrefix(line, "Uid:") {
			fields := strings.Fields(line)
			if len(fields) >= 2 {
				return fields[1] // Real UID
			}
		}
	}
	return ""
}

func (p *ProcessMonitor) analyzeProcess(proc *ProcessInfo) {
	reasons := []string{}

	// Check against suspicious patterns
	for _, pattern := range p.patterns {
		if pattern.MatchString(proc.Command) || pattern.MatchString(proc.Name) {
			reasons = append(reasons, fmt.Sprintf("Matches pattern: %s", pattern.String()))
		}
	}

	// Check memory usage
	maxMemoryMB := p.parseMemoryLimit(p.config.MaxProcessMemory)
	if proc.MemoryKB/1024 > maxMemoryMB {
		reasons = append(reasons, fmt.Sprintf("High memory usage: %dMB", proc.MemoryKB/1024))
	}

	// Check for suspicious locations
	if strings.Contains(proc.Command, "/tmp/") || strings.Contains(proc.Command, "/var/tmp/") {
		reasons = append(reasons, "Running from temporary directory")
	}

	// Check for suspicious users (processes running as www-data, nobody that shouldn't)
	if proc.User == "33" || proc.User == "65534" { // www-data, nobody
		if strings.Contains(proc.Command, "wget") || strings.Contains(proc.Command, "curl") {
			reasons = append(reasons, "Web user running download tools")
		}
	}

	if len(reasons) > 0 {
		p.handleSuspiciousProcess(proc, reasons)
	}
}

func (p *ProcessMonitor) parseMemoryLimit(limit string) int {
	limit = strings.ToUpper(limit)

	var multiplier int = 1
	if strings.HasSuffix(limit, "GB") {
		multiplier = 1024
		limit = strings.TrimSuffix(limit, "GB")
	} else if strings.HasSuffix(limit, "MB") {
		multiplier = 1
		limit = strings.TrimSuffix(limit, "MB")
	}

	if value, err := strconv.Atoi(limit); err == nil {
		return value * multiplier
	}

	return 1024 // Default 1GB
}

func (p *ProcessMonitor) handleSuspiciousProcess(proc *ProcessInfo, reasons []string) {
	p.mu.Lock()
	defer p.mu.Unlock()

	suspProc := &SuspiciousProcess{
		PID:       proc.PID,
		Name:      proc.Name,
		Command:   proc.Command,
		User:      proc.User,
		MemoryMB:  proc.MemoryKB / 1024,
		StartTime: time.Now(),
		LastSeen:  time.Now(),
		Reason:    strings.Join(reasons, "; "),
	}

	p.suspiciousProcs[proc.PID] = suspProc

	logger.Warn("process", "Suspicious process detected",
		"pid", proc.PID,
		"name", proc.Name,
		"command", proc.Command,
		"reasons", suspProc.Reason)

	// Send alert
	data := map[string]interface{}{
		"pid":       proc.PID,
		"name":      proc.Name,
		"command":   proc.Command,
		"user":      proc.User,
		"memory_mb": proc.MemoryKB / 1024,
		"reasons":   reasons,
	}

	message := fmt.Sprintf("SECURITY: Suspicious process detected: %s (PID %d)", proc.Name, proc.PID)
	p.ipsManager.notifier.SendAlert(message, data)

	// Optionally kill the process (careful with this!)
	// if you want to auto-kill suspicious processes:
	// p.killProcess(proc.PID)
}

func (p *ProcessMonitor) killProcess(pid int) {
	logger.Warn("process", "Killing suspicious process", "pid", pid)

	// Send SIGTERM first
	if err := syscall.Kill(pid, syscall.SIGTERM); err != nil {
		logger.Error("process", "Failed to terminate process", "pid", pid, "error", err.Error())

		// If SIGTERM fails, try SIGKILL
		if err := syscall.Kill(pid, syscall.SIGKILL); err != nil {
			logger.Error("process", "Failed to kill process", "pid", pid, "error", err.Error())
		}
	}
}

func (p *ProcessMonitor) cleanupOldProcesses() {
	ticker := time.NewTicker(10 * time.Minute)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			p.mu.Lock()
			now := time.Now()
			for pid, proc := range p.suspiciousProcs {
				// Remove entries older than 1 hour or if process no longer exists
				if now.Sub(proc.LastSeen) > 1*time.Hour || !p.processExists(pid) {
					delete(p.suspiciousProcs, pid)
				}
			}
			p.mu.Unlock()
		case <-p.stopCh:
			return
		}
	}
}

func (p *ProcessMonitor) processExists(pid int) bool {
	_, err := os.Stat(fmt.Sprintf("/proc/%d", pid))
	return err == nil
}

func (p *ProcessMonitor) Stop() {
	close(p.stopCh)
}

func (p *ProcessMonitor) GetStats() map[string]interface{} {
	p.mu.RLock()
	defer p.mu.RUnlock()

	return map[string]interface{}{
		"suspicious_processes": len(p.suspiciousProcs),
		"enabled":              p.config.EnableProcessMonitor,
		"patterns_loaded":      len(p.patterns),
	}
}

func (p *ProcessMonitor) GetSuspiciousProcesses() map[int]*SuspiciousProcess {
	p.mu.RLock()
	defer p.mu.RUnlock()

	result := make(map[int]*SuspiciousProcess)
	for k, v := range p.suspiciousProcs {
		result[k] = v
	}
	return result
}
// internal/logger/logger.go
package logger

import (
	"encoding/json"
	"fmt"
	"log/slog"
	"os"
	"time"

	"github.com/prometheus/client_golang/prometheus"
)

type Logger struct {
	slog       *slog.Logger
	prometheus *PrometheusLogger
}

type PrometheusLogger struct {
	logCounter *prometheus.CounterVec
}

type LogEntry struct {
	Timestamp time.Time              `json:"timestamp"`
	Level     string                 `json:"level"`
	Message   string                 `json:"message"`
	Component string                 `json:"component"`
	Fields    map[string]interface{} `json:"fields,omitempty"`
}

var DefaultLogger *Logger

func init() {
	DefaultLogger = New()
}

func New() *Logger {
	promLogger := &PrometheusLogger{
		logCounter: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "qff_log_entries_total",
				Help: "Total number of log entries by level",
			},
			[]string{"level", "component"},
		),
	}

	prometheus.MustRegister(promLogger.logCounter)

	return &Logger{
		slog:       slog.New(slog.NewJSONHandler(os.Stdout, nil)),
		prometheus: promLogger,
	}
}

func (l *Logger) Info(component, msg string, fields ...interface{}) {
	l.log("INFO", component, msg, fields...)
}

func (l *Logger) Error(component, msg string, fields ...interface{}) {
	l.log("ERROR", component, msg, fields...)
}

func (l *Logger) Debug(component, msg string, fields ...interface{}) {
	l.log("DEBUG", component, msg, fields...)
}

func (l *Logger) Warn(component, msg string, fields ...interface{}) {
	l.log("WARN", component, msg, fields...)
}

func (l *Logger) log(level, component, msg string, fields ...interface{}) {
	entry := LogEntry{
		Timestamp: time.Now(),
		Level:     level,
		Message:   msg,
		Component: component,
	}

	if len(fields) > 0 {
		entry.Fields = make(map[string]interface{})
		for i := 0; i < len(fields)-1; i += 2 {
			if key, ok := fields[i].(string); ok {
				entry.Fields[key] = fields[i+1]
			}
		}
	}

	// JSON output for journalctl
	jsonData, _ := json.Marshal(entry)
	fmt.Println(string(jsonData))

	// Prometheus metrics
	l.prometheus.logCounter.WithLabelValues(level, component).Inc()

	// Standard slog
	switch level {
	case "INFO":
		l.slog.Info(msg, "component", component)
	case "ERROR":
		l.slog.Error(msg, "component", component)
	case "DEBUG":
		l.slog.Debug(msg, "component", component)
	case "WARN":
		l.slog.Warn(msg, "component", component)
	}
}

func Info(component, msg string, fields ...interface{}) {
	DefaultLogger.Info(component, msg, fields...)
}

func Error(component, msg string, fields ...interface{}) {
	DefaultLogger.Error(component, msg, fields...)
}

func Debug(component, msg string, fields ...interface{}) {
	DefaultLogger.Debug(component, msg, fields...)
}

func Warn(component, msg string, fields ...interface{}) {
	DefaultLogger.Warn(component, msg, fields...)
}
// internal/monitor/monitor.go
package monitor

import (
	"context"
	"errors"
	"fmt"
	"runtime"
	"sync"
	"syscall"
	"time"

	"qff/internal/config"
	"qff/internal/logger"
	"qff/internal/notify"

	"github.com/prometheus/client_golang/prometheus"
)

const (
	defaultCollectionInterval = 30 * time.Second
	defaultAlertCooldown      = 10 * time.Minute
)

type SystemMonitor struct {
	config        *config.MonitorConfig
	notifier      *notify.Notifier
	metrics       *MonitorMetrics
	ctx           context.Context
	cancel        context.CancelFunc
	wg            sync.WaitGroup
	alertCooldown *sync.Map // thread-safe cooldown tracking
}

type MonitorMetrics struct {
	cpuUsage    prometheus.Gauge
	memoryUsage prometheus.Gauge
	diskUsage   prometheus.Gauge
	connections prometheus.Gauge
}

func NewSystemMonitor(cfg *config.MonitorConfig, notifier *notify.Notifier) (*SystemMonitor, error) {
	if cfg == nil {
		return nil, ErrNilConfig
	}
	if notifier == nil {
		return nil, ErrNilNotifier
	}

	metrics := &MonitorMetrics{
		cpuUsage: prometheus.NewGauge(prometheus.GaugeOpts{
			Name: "qff_cpu_usage_percent",
			Help: "Current CPU usage percentage",
		}),
		memoryUsage: prometheus.NewGauge(prometheus.GaugeOpts{
			Name: "qff_memory_usage_percent",
			Help: "Current memory usage percentage",
		}),
		diskUsage: prometheus.NewGauge(prometheus.GaugeOpts{
			Name: "qff_disk_usage_percent",
			Help: "Current disk usage percentage",
		}),
		connections: prometheus.NewGauge(prometheus.GaugeOpts{
			Name: "qff_active_connections",
			Help: "Number of active connections",
		}),
	}

	if err := prometheus.Register(metrics.cpuUsage); err != nil {
		return nil, err
	}
	if err := prometheus.Register(metrics.memoryUsage); err != nil {
		return nil, err
	}
	if err := prometheus.Register(metrics.diskUsage); err != nil {
		return nil, err
	}
	if err := prometheus.Register(metrics.connections); err != nil {
		return nil, err
	}

	ctx, cancel := context.WithCancel(context.Background())

	return &SystemMonitor{
		config:        cfg,
		notifier:      notifier,
		metrics:       metrics,
		ctx:           ctx,
		cancel:        cancel,
		alertCooldown: &sync.Map{},
	}, nil
}

func (m *SystemMonitor) Start() {
	if !m.config.EnableResourceMonitoring {
		logger.Debug("monitor", "Resource monitoring disabled in config")
		return
	}

	interval := defaultCollectionInterval

	logger.Info("monitor", "Starting system monitor", "interval", interval)

	m.wg.Add(1)
	go m.runMonitoringLoop(interval)
}

func (m *SystemMonitor) runMonitoringLoop(interval time.Duration) {
	defer m.wg.Done()

	ticker := time.NewTicker(interval)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			m.collectAndAlert()
		case <-m.ctx.Done():
			logger.Info("monitor", "Stopping monitoring loop")
			return
		}
	}
}

func (m *SystemMonitor) collectAndAlert() {
	var wg sync.WaitGroup

	if m.config.CPUAlert {
		wg.Add(1)
		go func() {
			defer wg.Done()
			m.checkCPUUsage()
		}()
	}

	if m.config.MemoryAlert {
		wg.Add(1)
		go func() {
			defer wg.Done()
			m.checkMemoryUsage()
		}()
	}

	if m.config.DiskAlert {
		wg.Add(1)
		go func() {
			defer wg.Done()
			m.checkDiskUsage()
		}()
	}

	wg.Wait()
}

func (m *SystemMonitor) checkCPUUsage() {
	cpuUsage, err := m.getCPUUsage()
	if err != nil {
		logger.Error("monitor", "Failed to get CPU usage", "error", err)
		return
	}

	m.metrics.cpuUsage.Set(cpuUsage)

	if cpuUsage > m.config.CPUThreshold && m.shouldAlert("cpu") {
		m.notifier.SendAlert("High CPU Usage", map[string]interface{}{
			"cpu_usage": cpuUsage,
			"threshold": m.config.CPUThreshold,
		})
		m.alertCooldown.Store("cpu", time.Now())
	}
}

func (m *SystemMonitor) checkMemoryUsage() {
	memUsage, err := m.getMemoryUsage()
	if err != nil {
		logger.Error("monitor", "Failed to get memory usage", "error", err)
		return
	}

	m.metrics.memoryUsage.Set(memUsage)

	if memUsage > m.config.MemoryThreshold && m.shouldAlert("memory") {
		m.notifier.SendAlert("High Memory Usage", map[string]interface{}{
			"memory_usage": memUsage,
			"threshold":    m.config.MemoryThreshold,
		})
		m.alertCooldown.Store("memory", time.Now())
	}
}

func (m *SystemMonitor) checkDiskUsage() {
	diskUsage, err := m.getDiskUsage()
	if err != nil {
		logger.Error("monitor", "Failed to get disk usage", "error", err)
		return
	}

	m.metrics.diskUsage.Set(diskUsage)

	if diskUsage > m.config.DiskThreshold && m.shouldAlert("disk") {
		m.notifier.SendAlert("High Disk Usage", map[string]interface{}{
			"disk_usage": diskUsage,
			"threshold":  m.config.DiskThreshold,
		})
		m.alertCooldown.Store("disk", time.Now())
	}
}

func (m *SystemMonitor) shouldAlert(alertType string) bool {
	lastAlert, exists := m.alertCooldown.Load(alertType)
	if !exists {
		return true
	}

	return time.Since(lastAlert.(time.Time)) > defaultAlertCooldown
}

func (m *SystemMonitor) getCPUUsage() (float64, error) {
	var rusage syscall.Rusage
	if err := syscall.Getrusage(syscall.RUSAGE_SELF, &rusage); err != nil {
		return 0, err
	}

	userTime := float64(rusage.Utime.Sec) + float64(rusage.Utime.Usec)/1e6
	sysTime := float64(rusage.Stime.Sec) + float64(rusage.Stime.Usec)/1e6

	// Calculate percentage of CPU used in the last interval
	return (userTime + sysTime) * 100 / defaultCollectionInterval.Seconds(), nil
}

func (m *SystemMonitor) getMemoryUsage() (float64, error) {
	var memStats runtime.MemStats
	runtime.ReadMemStats(&memStats)

	var sysinfo syscall.Sysinfo_t
	if err := syscall.Sysinfo(&sysinfo); err != nil {
		return 0, err
	}

	totalMem := float64(sysinfo.Totalram)
	usedMem := float64(memStats.Sys)

	if totalMem == 0 {
		return 0, ErrZeroTotalMemory
	}

	return (usedMem / totalMem) * 100, nil
}

func (m *SystemMonitor) getDiskUsage() (float64, error) {
	var stat syscall.Statfs_t
	if err := syscall.Statfs("/", &stat); err != nil {
		return 0, err
	}

	total := float64(stat.Blocks * uint64(stat.Bsize))
	free := float64(stat.Bavail * uint64(stat.Bsize))

	if total == 0 {
		return 0, ErrZeroTotalDisk
	}

	return ((total - free) / total) * 100, nil
}

func (m *SystemMonitor) Stop() {
	m.cancel()
	m.wg.Wait()
	logger.Info("monitor", "System monitor stopped")
}

func (m *SystemMonitor) GetMetrics() (map[string]float64, error) {
	var wg sync.WaitGroup
	var mu sync.Mutex
	metrics := make(map[string]float64)
	var errs []error

	collect := func(name string, fn func() (float64, error)) {
		defer wg.Done()
		value, err := fn()
		if err != nil {
			mu.Lock()
			errs = append(errs, err)
			mu.Unlock()
			return
		}
		mu.Lock()
		metrics[name] = value
		mu.Unlock()
	}

	wg.Add(3)
	go collect("cpu_usage", m.getCPUUsage)
	go collect("memory_usage", m.getMemoryUsage)
	go collect("disk_usage", m.getDiskUsage)
	wg.Wait()

	if len(errs) > 0 {
		return metrics, ErrPartialMetrics{Errors: errs}
	}

	return metrics, nil
}

// Custom errors for better error handling
var (
	ErrNilConfig       = errors.New("monitor config cannot be nil")
	ErrNilNotifier     = errors.New("notifier cannot be nil")
	ErrZeroTotalMemory = errors.New("total memory reported as zero")
	ErrZeroTotalDisk   = errors.New("total disk space reported as zero")
)

type ErrPartialMetrics struct {
	Errors []error
}

func (e ErrPartialMetrics) Error() string {
	return fmt.Sprintf("partial metrics collected with %d errors", len(e.Errors))
}
// internal/notify/notify.go
package notify

import (
	"bytes"
	"context"
	"crypto/hmac"
	"crypto/sha256"
	"crypto/tls"
	"encoding/hex"
	"encoding/json"
	"fmt"
	"html/template"
	"io"
	"net/http"
	"net/smtp"
	"net/url"
	"os"
	"sort"
	"strings"
	"sync"
	"time"

	"qff/internal/config"
	"qff/internal/logger"
)

const (
	// Default configuration
	DefaultEmailTimeout   = 30 * time.Second
	DefaultWebhookTimeout = 10 * time.Second
	DefaultRetryAttempts  = 3
	DefaultRetryDelay     = 5 * time.Second
	DefaultMaxPayloadSize = 1024 * 1024 // 1MB
	DefaultRateLimit      = 100         // messages per hour

	// Alert levels
	AlertLevelInfo     = "info"
	AlertLevelWarning  = "warning"
	AlertLevelError    = "error"
	AlertLevelCritical = "critical"

	// Notification types
	NotificationTypeEmail   = "email"
	NotificationTypeWebhook = "webhook"
	NotificationTypeSlack   = "slack"
	NotificationTypeDiscord = "discord"
	NotificationTypeSMS     = "sms"
)

// Notifier handles sending notifications via multiple channels
type Notifier struct {
	config    *Config
	stats     *NotificationStats
	templates *template.Template
	client    *http.Client

	// Rate limiting
	rateLimiter *RateLimiter

	// Synchronization
	mu sync.RWMutex

	// Context for graceful shutdown
	ctx    context.Context
	cancel context.CancelFunc
	wg     sync.WaitGroup
}

// Config holds notification configuration
type Config struct {
	// Global settings
	Enabled      bool          `json:"enabled"`
	DefaultLevel string        `json:"default_level"`
	RateLimit    int           `json:"rate_limit"`
	MaxRetries   int           `json:"max_retries"`
	RetryDelay   time.Duration `json:"retry_delay"`

	// Email configuration
	Email *EmailConfig `json:"email"`

	// Webhook configuration
	Webhooks []*WebhookConfig `json:"webhooks"`

	// Template configuration
	Templates *TemplateConfig `json:"templates"`

	// Security settings
	Security *SecurityConfig `json:"security"`
}

// EmailConfig holds email notification settings
type EmailConfig struct {
	Enabled            bool          `json:"enabled"`
	SMTPServer         string        `json:"smtp_server"`
	SMTPPort           int           `json:"smtp_port"`
	Username           string        `json:"username"`
	Password           string        `json:"password"`
	From               string        `json:"from"`
	To                 []string      `json:"to"`
	CC                 []string      `json:"cc,omitempty"`
	BCC                []string      `json:"bcc,omitempty"`
	UseTLS             bool          `json:"use_tls"`
	UseStartTLS        bool          `json:"use_starttls"`
	Timeout            time.Duration `json:"timeout"`
	InsecureSkipVerify bool          `json:"insecure_skip_verify"`
	Template           string        `json:"template"`
}

// WebhookConfig holds webhook notification settings
type WebhookConfig struct {
	Name            string            `json:"name"`
	Enabled         bool              `json:"enabled"`
	URL             string            `json:"url"`
	Method          string            `json:"method"`
	Headers         map[string]string `json:"headers"`
	Timeout         time.Duration     `json:"timeout"`
	Secret          string            `json:"secret,omitempty"`
	Template        string            `json:"template"`
	RetryAttempts   int               `json:"retry_attempts"`
	MinLevel        string            `json:"min_level"`
	MaxPayloadSize  int64             `json:"max_payload_size"`
	SignatureHeader string            `json:"signature_header"`
}

// TemplateConfig holds template settings
type TemplateConfig struct {
	EmailSubject    string            `json:"email_subject"`
	EmailBody       string            `json:"email_body"`
	WebhookPayload  string            `json:"webhook_payload"`
	SlackPayload    string            `json:"slack_payload"`
	CustomTemplates map[string]string `json:"custom_templates"`
}

// SecurityConfig holds security settings
type SecurityConfig struct {
	EnableSignatures bool     `json:"enable_signatures"`
	AllowedHosts     []string `json:"allowed_hosts"`
	MaxPayloadSize   int64    `json:"max_payload_size"`
	RequireHTTPS     bool     `json:"require_https"`
}

// NotificationStats tracks notification statistics
type NotificationStats struct {
	TotalSent      int64                    `json:"total_sent"`
	TotalFailed    int64                    `json:"total_failed"`
	EmailsSent     int64                    `json:"emails_sent"`
	EmailsFailed   int64                    `json:"emails_failed"`
	WebhooksSent   int64                    `json:"webhooks_sent"`
	WebhooksFailed int64                    `json:"webhooks_failed"`
	LastSent       time.Time                `json:"last_sent"`
	ChannelStats   map[string]*ChannelStats `json:"channel_stats"`
	RateLimited    int64                    `json:"rate_limited"`
}

// ChannelStats tracks per-channel statistics
type ChannelStats struct {
	Name           string        `json:"name"`
	Type           string        `json:"type"`
	MessagesSent   int64         `json:"messages_sent"`
	MessagesFailed int64         `json:"messages_failed"`
	LastSuccess    time.Time     `json:"last_success"`
	LastFailure    time.Time     `json:"last_failure"`
	LastError      string        `json:"last_error,omitempty"`
	AverageLatency time.Duration `json:"average_latency"`
	SuccessRate    float64       `json:"success_rate"`
}

// Alert represents a notification message
type Alert struct {
	ID        string                 `json:"id"`
	Level     string                 `json:"level"`
	Title     string                 `json:"title"`
	Message   string                 `json:"message"`
	Source    string                 `json:"source"`
	Timestamp time.Time              `json:"timestamp"`
	Data      map[string]interface{} `json:"data,omitempty"`
	Tags      []string               `json:"tags,omitempty"`
	Priority  int                    `json:"priority"`
	Retries   int                    `json:"retries"`
}

// WebhookPayload represents the webhook payload structure
type WebhookPayload struct {
	Alert       *Alert    `json:"alert"`
	Service     string    `json:"service"`
	Version     string    `json:"version"`
	Hostname    string    `json:"hostname"`
	Environment string    `json:"environment"`
	Timestamp   time.Time `json:"timestamp"`
	Signature   string    `json:"signature,omitempty"`
}

// RateLimiter implements rate limiting for notifications
type RateLimiter struct {
	limit  int
	window time.Duration
	tokens map[string][]time.Time
	mu     sync.Mutex
}

func NewNotifier(cfg *config.NotificationConfig) *Notifier {
	ctx, cancel := context.WithCancel(context.Background())

	// Convert old config to new config format
	newConfig := convertConfig(cfg)

	// Create HTTP client with sensible defaults
	client := &http.Client{
		Timeout: DefaultWebhookTimeout,
		Transport: &http.Transport{
			MaxIdleConns:       10,
			IdleConnTimeout:    30 * time.Second,
			DisableCompression: false,
			MaxConnsPerHost:    5,
			TLSClientConfig: &tls.Config{
				InsecureSkipVerify: false,
			},
		},
	}

	// Initialize rate limiter
	rateLimiter := &RateLimiter{
		limit:  newConfig.RateLimit,
		window: time.Hour,
		tokens: make(map[string][]time.Time),
	}

	// Load templates
	templates := loadDefaultTemplates()

	return &Notifier{
		config:      newConfig,
		stats:       &NotificationStats{ChannelStats: make(map[string]*ChannelStats)},
		templates:   templates,
		client:      client,
		rateLimiter: rateLimiter,
		ctx:         ctx,
		cancel:      cancel,
	}
}

func convertConfig(oldCfg *config.NotificationConfig) *Config {
	if oldCfg == nil {
		return getDefaultConfig()
	}

	config := &Config{
		Enabled:      true,
		DefaultLevel: AlertLevelInfo,
		RateLimit:    DefaultRateLimit,
		MaxRetries:   DefaultRetryAttempts,
		RetryDelay:   DefaultRetryDelay,
		Templates:    getDefaultTemplateConfig(),
		Security:     getDefaultSecurityConfig(),
	}

	// Convert email config
	if oldCfg.EnableEmail {
		config.Email = &EmailConfig{
			Enabled:    true,
			SMTPServer: oldCfg.EmailServer,
			SMTPPort:   oldCfg.EmailPort,
			Username:   oldCfg.EmailUser,
			Password:   oldCfg.EmailPassword,
			To:         []string{oldCfg.EmailTo},
			UseTLS:     true,
			Timeout:    DefaultEmailTimeout,
			Template:   "default_email",
		}
	}

	// Convert webhook config
	if oldCfg.EnableWebhooks && len(oldCfg.WebhookURLs) > 0 {
		config.Webhooks = make([]*WebhookConfig, len(oldCfg.WebhookURLs))
		for i, url := range oldCfg.WebhookURLs {
			config.Webhooks[i] = &WebhookConfig{
				Name:           fmt.Sprintf("webhook_%d", i+1),
				Enabled:        true,
				URL:            url,
				Method:         "POST",
				Timeout:        time.Duration(oldCfg.WebhookTimeout) * time.Second,
				RetryAttempts:  DefaultRetryAttempts,
				MinLevel:       AlertLevelInfo,
				MaxPayloadSize: DefaultMaxPayloadSize,
				Template:       "default_webhook",
			}
		}
	}

	return config
}

func getDefaultConfig() *Config {
	return &Config{
		Enabled:      false,
		DefaultLevel: AlertLevelInfo,
		RateLimit:    DefaultRateLimit,
		MaxRetries:   DefaultRetryAttempts,
		RetryDelay:   DefaultRetryDelay,
		Templates:    getDefaultTemplateConfig(),
		Security:     getDefaultSecurityConfig(),
	}
}

func getDefaultTemplateConfig() *TemplateConfig {
	return &TemplateConfig{
		EmailSubject:    "QFF Alert: {{.Alert.Title}}",
		EmailBody:       defaultEmailTemplate,
		WebhookPayload:  defaultWebhookTemplate,
		SlackPayload:    defaultSlackTemplate,
		CustomTemplates: make(map[string]string),
	}
}

func getDefaultSecurityConfig() *SecurityConfig {
	return &SecurityConfig{
		EnableSignatures: true,
		AllowedHosts:     []string{},
		MaxPayloadSize:   DefaultMaxPayloadSize,
		RequireHTTPS:     true,
	}
}

const defaultEmailTemplate = `
Alert Level: {{.Alert.Level | upper}}
Source: {{.Alert.Source}}
Time: {{.Alert.Timestamp.Format "2006-01-02 15:04:05 UTC"}}

Message:
{{.Alert.Message}}

{{if .Alert.Data}}
Additional Data:
{{range $key, $value := .Alert.Data}}
  {{$key}}: {{$value}}
{{end}}
{{end}}

{{if .Alert.Tags}}
Tags: {{join .Alert.Tags ", "}}
{{end}}

--
QFF Notification System
`

const defaultWebhookTemplate = `{
  "alert": {
    "id": "{{.Alert.ID}}",
    "level": "{{.Alert.Level}}",
    "title": "{{.Alert.Title}}",
    "message": "{{.Alert.Message}}",
    "source": "{{.Alert.Source}}",
    "timestamp": "{{.Alert.Timestamp.Format "2006-01-02T15:04:05Z07:00"}}",
    "priority": {{.Alert.Priority}}
    {{if .Alert.Data}},"data": {{marshal .Alert.Data}}{{end}}
    {{if .Alert.Tags}},"tags": {{marshal .Alert.Tags}}{{end}}
  },
  "service": "{{.Service}}",
  "version": "{{.Version}}",
  "hostname": "{{.Hostname}}",
  "timestamp": "{{.Timestamp.Format "2006-01-02T15:04:05Z07:00"}}"
}`

const defaultSlackTemplate = `{
  "text": "QFF Alert: {{.Alert.Title}}",
  "attachments": [
    {
      "color": "{{if eq .Alert.Level "critical"}}danger{{else if eq .Alert.Level "error"}}warning{{else}}good{{end}}",
      "fields": [
        {
          "title": "Level",
          "value": "{{.Alert.Level | upper}}",
          "short": true
        },
        {
          "title": "Source",
          "value": "{{.Alert.Source}}",
          "short": true
        },
        {
          "title": "Message",
          "value": "{{.Alert.Message}}",
          "short": false
        }
      ],
      "ts": {{.Alert.Timestamp.Unix}}
    }
  ]
}`

func loadDefaultTemplates() *template.Template {
	tmpl := template.New("notifications")

	// Add custom functions
	tmpl.Funcs(template.FuncMap{
		"upper": strings.ToUpper,
		"lower": strings.ToLower,
		"join":  strings.Join,
		"marshal": func(v interface{}) string {
			data, _ := json.Marshal(v)
			return string(data)
		},
	})

	// Parse default templates
	template.Must(tmpl.New("default_email").Parse(defaultEmailTemplate))
	template.Must(tmpl.New("default_webhook").Parse(defaultWebhookTemplate))
	template.Must(tmpl.New("default_slack").Parse(defaultSlackTemplate))

	return tmpl
}

// SendAlertWithDetails sends an alert through all configured notification channels
func (n *Notifier) SendAlertWithDetails(level, title, message, source string, data map[string]interface{}) error {
	if !n.config.Enabled {
		return nil
	}

	// Check rate limiting
	if !n.rateLimiter.Allow(source) {
		n.mu.Lock()
		n.stats.RateLimited++
		n.mu.Unlock()

		logger.Warn("notify", "Rate limit exceeded", "source", source)
		return fmt.Errorf("rate limit exceeded for source: %s", source)
	}

	// Create alert
	alert := &Alert{
		ID:        generateAlertID(),
		Level:     level,
		Title:     title,
		Message:   message,
		Source:    source,
		Timestamp: time.Now(),
		Data:      data,
		Priority:  getLevelPriority(level),
	}

	logger.Info("notify", "Sending alert", "level", level, "title", title, "source", source)

	// Send through all channels concurrently
	var wg sync.WaitGroup
	errors := make(chan error, 10)

	// Send email if configured
	if n.config.Email != nil && n.config.Email.Enabled {
		wg.Add(1)
		go func() {
			defer wg.Done()
			if err := n.sendEmail(alert); err != nil {
				errors <- fmt.Errorf("email failed: %w", err)
			}
		}()
	}

	// Send webhooks if configured
	for _, webhook := range n.config.Webhooks {
		if webhook.Enabled && n.shouldSendToWebhook(webhook, level) {
			wg.Add(1)
			go func(wh *WebhookConfig) {
				defer wg.Done()
				if err := n.sendWebhook(alert, wh); err != nil {
					errors <- fmt.Errorf("webhook %s failed: %w", wh.Name, err)
				}
			}(webhook)
		}
	}

	// Wait for all notifications to complete
	go func() {
		wg.Wait()
		close(errors)
	}()

	// Collect any errors
	var allErrors []string
	for err := range errors {
		allErrors = append(allErrors, err.Error())
		logger.Error("notify", "Notification failed", "error", err.Error())
	}

	// Update statistics
	n.updateStats(alert, len(allErrors) == 0)

	if len(allErrors) > 0 {
		return fmt.Errorf("notification errors: %s", strings.Join(allErrors, "; "))
	}

	return nil
}

func (n *Notifier) sendEmail(alert *Alert) error {
	if n.config.Email == nil || !n.config.Email.Enabled {
		return fmt.Errorf("email not configured")
	}

	startTime := time.Now()
	channelName := "email"

	// Render email content
	subject, body, err := n.renderEmailTemplate(alert)
	if err != nil {
		n.updateChannelStats(channelName, false, time.Since(startTime), err.Error())
		return fmt.Errorf("template rendering failed: %w", err)
	}

	// Prepare email message
	message := n.buildEmailMessage(subject, body)

	// Setup SMTP authentication
	auth := smtp.PlainAuth("", n.config.Email.Username, n.config.Email.Password, n.config.Email.SMTPServer)

	// Prepare recipients
	recipients := append(n.config.Email.To, n.config.Email.CC...)
	recipients = append(recipients, n.config.Email.BCC...)

	// Send email with retry logic
	addr := fmt.Sprintf("%s:%d", n.config.Email.SMTPServer, n.config.Email.SMTPPort)

	var lastErr error
	for attempt := 1; attempt <= n.config.MaxRetries; attempt++ {
		err := smtp.SendMail(addr, auth, n.config.Email.From, recipients, []byte(message))
		if err == nil {
			n.updateChannelStats(channelName, true, time.Since(startTime), "")
			logger.Info("notify", "Email sent successfully", "recipients", len(recipients))
			return nil
		}

		lastErr = err
		if attempt < n.config.MaxRetries {
			time.Sleep(n.config.RetryDelay)
		}
	}

	n.updateChannelStats(channelName, false, time.Since(startTime), lastErr.Error())
	return fmt.Errorf("failed after %d attempts: %w", n.config.MaxRetries, lastErr)
}

func (n *Notifier) sendWebhook(alert *Alert, webhook *WebhookConfig) error {
	startTime := time.Now()
	channelName := webhook.Name

	// Render webhook payload
	payload, err := n.renderWebhookTemplate(alert, webhook)
	if err != nil {
		n.updateChannelStats(channelName, false, time.Since(startTime), err.Error())
		return fmt.Errorf("template rendering failed: %w", err)
	}

	// Validate payload size
	if int64(len(payload)) > webhook.MaxPayloadSize {
		err := fmt.Errorf("payload too large: %d bytes (max: %d)", len(payload), webhook.MaxPayloadSize)
		n.updateChannelStats(channelName, false, time.Since(startTime), err.Error())
		return err
	}

	// Send webhook with retry logic
	var lastErr error
	for attempt := 1; attempt <= webhook.RetryAttempts; attempt++ {
		err := n.sendWebhookRequest(payload, webhook)
		if err == nil {
			n.updateChannelStats(channelName, true, time.Since(startTime), "")
			logger.Info("notify", "Webhook sent successfully", "webhook", webhook.Name, "url", webhook.URL)
			return nil
		}

		lastErr = err
		if attempt < webhook.RetryAttempts {
			time.Sleep(n.config.RetryDelay)
		}
	}

	n.updateChannelStats(channelName, false, time.Since(startTime), lastErr.Error())
	return fmt.Errorf("failed after %d attempts: %w", webhook.RetryAttempts, lastErr)
}

func (n *Notifier) sendWebhookRequest(payload []byte, webhook *WebhookConfig) error {
	ctx, cancel := context.WithTimeout(n.ctx, webhook.Timeout)
	defer cancel()

	// Create request
	req, err := http.NewRequestWithContext(ctx, webhook.Method, webhook.URL, bytes.NewBuffer(payload))
	if err != nil {
		return fmt.Errorf("failed to create request: %w", err)
	}

	// Set headers
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("User-Agent", "QFF-Notifier/1.0")

	// Add custom headers
	for key, value := range webhook.Headers {
		req.Header.Set(key, value)
	}

	// Add signature if secret is configured
	if webhook.Secret != "" {
		signature := n.generateSignature(payload, webhook.Secret)
		headerName := webhook.SignatureHeader
		if headerName == "" {
			headerName = "X-QFF-Signature"
		}
		req.Header.Set(headerName, signature)
	}

	// Send request
	resp, err := n.client.Do(req)
	if err != nil {
		return fmt.Errorf("request failed: %w", err)
	}
	defer resp.Body.Close()

	// Check response status
	if resp.StatusCode >= 400 {
		body, _ := io.ReadAll(io.LimitReader(resp.Body, 1024))
		return fmt.Errorf("webhook returned status %d: %s", resp.StatusCode, string(body))
	}

	return nil
}

func (n *Notifier) renderEmailTemplate(alert *Alert) (string, string, error) {
	templateName := "default_email"
	if n.config.Email.Template != "" {
		templateName = n.config.Email.Template
	}

	data := n.buildTemplateData(alert)

	// Create function map
	funcMap := template.FuncMap{
		"upper": strings.ToUpper,
		"lower": strings.ToLower,
		"join":  strings.Join,
		"marshal": func(v interface{}) string {
			data, _ := json.Marshal(v)
			return string(data)
		},
	}

	// Render subject
	var subjectBuf bytes.Buffer
	subjectTemplate := n.config.Templates.EmailSubject
	if subjectTemplate == "" {
		subjectTemplate = "QFF Alert: {{.Alert.Title}}"
	}

	tmpl, err := template.New("subject").Funcs(funcMap).Parse(subjectTemplate)
	if err != nil {
		return "", "", fmt.Errorf("subject template parse error: %w", err)
	}

	if err := tmpl.Execute(&subjectBuf, data); err != nil {
		return "", "", fmt.Errorf("subject template execution error: %w", err)
	}

	// Render body
	var bodyBuf bytes.Buffer
	if err := n.templates.ExecuteTemplate(&bodyBuf, templateName, data); err != nil {
		return "", "", fmt.Errorf("body template execution error: %w", err)
	}

	return subjectBuf.String(), bodyBuf.String(), nil
}

func (n *Notifier) renderWebhookTemplate(alert *Alert, webhook *WebhookConfig) ([]byte, error) {
	templateName := webhook.Template
	if templateName == "" {
		templateName = "default_webhook"
	}

	data := n.buildTemplateData(alert)

	var buf bytes.Buffer
	if err := n.templates.ExecuteTemplate(&buf, templateName, data); err != nil {
		return nil, fmt.Errorf("template execution error: %w", err)
	}

	return buf.Bytes(), nil
}

func (n *Notifier) buildTemplateData(alert *Alert) map[string]interface{} {
	hostname, _ := os.Hostname()

	return map[string]interface{}{
		"Alert":       alert,
		"Service":     "QFF",
		"Version":     "1.0.0",
		"Hostname":    hostname,
		"Environment": os.Getenv("QFF_ENV"),
		"Timestamp":   time.Now(),
	}
}

func (n *Notifier) buildEmailMessage(subject, body string) string {
	headers := make(map[string]string)
	headers["From"] = n.config.Email.From
	headers["To"] = strings.Join(n.config.Email.To, ", ")
	if len(n.config.Email.CC) > 0 {
		headers["CC"] = strings.Join(n.config.Email.CC, ", ")
	}
	headers["Subject"] = subject
	headers["MIME-Version"] = "1.0"
	headers["Content-Type"] = "text/plain; charset=\"utf-8\""
	headers["Date"] = time.Now().Format(time.RFC1123Z)

	var msg strings.Builder
	for key, value := range headers {
		msg.WriteString(fmt.Sprintf("%s: %s\r\n", key, value))
	}
	msg.WriteString("\r\n")
	msg.WriteString(body)

	return msg.String()
}

func (n *Notifier) generateSignature(payload []byte, secret string) string {
	h := hmac.New(sha256.New, []byte(secret))
	h.Write(payload)
	return "sha256=" + hex.EncodeToString(h.Sum(nil))
}

func (n *Notifier) shouldSendToWebhook(webhook *WebhookConfig, level string) bool {
	if webhook.MinLevel == "" {
		return true
	}

	return getLevelPriority(level) >= getLevelPriority(webhook.MinLevel)
}

func (n *Notifier) updateStats(alert *Alert, success bool) {
	n.mu.Lock()
	defer n.mu.Unlock()

	n.stats.TotalSent++
	if !success {
		n.stats.TotalFailed++
	}
	n.stats.LastSent = time.Now()
}

func (n *Notifier) updateChannelStats(channelName string, success bool, latency time.Duration, errorMsg string) {
	n.mu.Lock()
	defer n.mu.Unlock()

	stats := n.stats.ChannelStats[channelName]
	if stats == nil {
		stats = &ChannelStats{
			Name: channelName,
			Type: getChannelType(channelName),
		}
		n.stats.ChannelStats[channelName] = stats
	}

	if success {
		stats.MessagesSent++
		stats.LastSuccess = time.Now()

		// Update email-specific stats
		if strings.Contains(channelName, "email") {
			n.stats.EmailsSent++
		} else {
			n.stats.WebhooksSent++
		}
	} else {
		stats.MessagesFailed++
		stats.LastFailure = time.Now()
		stats.LastError = errorMsg

		// Update email-specific stats
		if strings.Contains(channelName, "email") {
			n.stats.EmailsFailed++
		} else {
			n.stats.WebhooksFailed++
		}
	}

	// Calculate success rate
	total := stats.MessagesSent + stats.MessagesFailed
	if total > 0 {
		stats.SuccessRate = float64(stats.MessagesSent) / float64(total) * 100
	}

	// Update average latency
	if success {
		if stats.AverageLatency == 0 {
			stats.AverageLatency = latency
		} else {
			stats.AverageLatency = (stats.AverageLatency + latency) / 2
		}
	}
}

// RateLimiter methods
func (rl *RateLimiter) Allow(key string) bool {
	rl.mu.Lock()
	defer rl.mu.Unlock()

	now := time.Now()

	// Clean old tokens
	if tokens, exists := rl.tokens[key]; exists {
		var validTokens []time.Time
		for _, token := range tokens {
			if now.Sub(token) < rl.window {
				validTokens = append(validTokens, token)
			}
		}
		rl.tokens[key] = validTokens
	}

	// Check if under limit
	if len(rl.tokens[key]) >= rl.limit {
		return false
	}

	// Add new token
	rl.tokens[key] = append(rl.tokens[key], now)
	return true
}

// Utility functions
func generateAlertID() string {
	return fmt.Sprintf("qff_%d", time.Now().UnixNano())
}

func getLevelPriority(level string) int {
	switch strings.ToLower(level) {
	case AlertLevelCritical:
		return 4
	case AlertLevelError:
		return 3
	case AlertLevelWarning:
		return 2
	case AlertLevelInfo:
		return 1
	default:
		return 0
	}
}

func getChannelType(channelName string) string {
	if strings.Contains(channelName, "email") {
		return NotificationTypeEmail
	}
	if strings.Contains(channelName, "slack") {
		return NotificationTypeSlack
	}
	if strings.Contains(channelName, "discord") {
		return NotificationTypeDiscord
	}
	return NotificationTypeWebhook
}

// Public API methods
func (n *Notifier) SendInfo(title, message, source string, data map[string]interface{}) error {
	return n.SendAlertWithDetails(AlertLevelInfo, title, message, source, data)
}

func (n *Notifier) SendWarning(title, message, source string, data map[string]interface{}) error {
	return n.SendAlertWithDetails(AlertLevelWarning, title, message, source, data)
}

func (n *Notifier) SendError(title, message, source string, data map[string]interface{}) error {
	return n.SendAlertWithDetails(AlertLevelError, title, message, source, data)
}

func (n *Notifier) SendCritical(title, message, source string, data map[string]interface{}) error {
	return n.SendAlertWithDetails(AlertLevelCritical, title, message, source, data)
}

// GetStats returns current notification statistics
func (n *Notifier) GetStats() *NotificationStats {
	n.mu.RLock()
	defer n.mu.RUnlock()

	// Create a deep copy to avoid race conditions
	stats := &NotificationStats{
		TotalSent:      n.stats.TotalSent,
		TotalFailed:    n.stats.TotalFailed,
		EmailsSent:     n.stats.EmailsSent,
		EmailsFailed:   n.stats.EmailsFailed,
		WebhooksSent:   n.stats.WebhooksSent,
		WebhooksFailed: n.stats.WebhooksFailed,
		LastSent:       n.stats.LastSent,
		RateLimited:    n.stats.RateLimited,
		ChannelStats:   make(map[string]*ChannelStats),
	}

	// Deep copy channel stats
	for name, channelStats := range n.stats.ChannelStats {
		stats.ChannelStats[name] = &ChannelStats{
			Name:           channelStats.Name,
			Type:           channelStats.Type,
			MessagesSent:   channelStats.MessagesSent,
			MessagesFailed: channelStats.MessagesFailed,
			LastSuccess:    channelStats.LastSuccess,
			LastFailure:    channelStats.LastFailure,
			LastError:      channelStats.LastError,
			AverageLatency: channelStats.AverageLatency,
			SuccessRate:    channelStats.SuccessRate,
		}
	}

	return stats
}

// TestNotification sends a test notification to verify configuration
func (n *Notifier) TestNotification() error {
	data := map[string]interface{}{
		"test":      true,
		"timestamp": time.Now(),
	}

	return n.SendInfo("Test Notification", "This is a test notification from QFF", "system", data)
}

// UpdateConfig updates the notification configuration
func (n *Notifier) UpdateConfig(newConfig *Config) error {
	if newConfig == nil {
		return fmt.Errorf("config cannot be nil")
	}

	// Validate configuration
	if err := n.validateConfig(newConfig); err != nil {
		return fmt.Errorf("invalid configuration: %w", err)
	}

	n.mu.Lock()
	defer n.mu.Unlock()

	n.config = newConfig

	// Update rate limiter
	n.rateLimiter.limit = newConfig.RateLimit

	// Update HTTP client timeout if webhooks are configured
	if len(newConfig.Webhooks) > 0 {
		maxTimeout := DefaultWebhookTimeout
		for _, webhook := range newConfig.Webhooks {
			if webhook.Timeout > maxTimeout {
				maxTimeout = webhook.Timeout
			}
		}
		n.client.Timeout = maxTimeout
	}

	logger.Info("notify", "Notification configuration updated")
	return nil
}

func (n *Notifier) validateConfig(config *Config) error {
	if config.RateLimit < 1 || config.RateLimit > 10000 {
		return fmt.Errorf("rate limit must be between 1 and 10000")
	}

	if config.MaxRetries < 1 || config.MaxRetries > 10 {
		return fmt.Errorf("max retries must be between 1 and 10")
	}

	if config.RetryDelay < time.Second || config.RetryDelay > time.Minute {
		return fmt.Errorf("retry delay must be between 1 second and 1 minute")
	}

	// Validate email config
	if config.Email != nil && config.Email.Enabled {
		if config.Email.SMTPServer == "" {
			return fmt.Errorf("email SMTP server is required")
		}
		if config.Email.From == "" {
			return fmt.Errorf("email from address is required")
		}
		if len(config.Email.To) == 0 {
			return fmt.Errorf("at least one email recipient is required")
		}
		if config.Email.SMTPPort < 1 || config.Email.SMTPPort > 65535 {
			return fmt.Errorf("email SMTP port must be between 1 and 65535")
		}
	}

	// Validate webhook configs
	for i, webhook := range config.Webhooks {
		if webhook.Enabled {
			if webhook.URL == "" {
				return fmt.Errorf("webhook %d URL is required", i)
			}

			// Validate URL
			if _, err := url.Parse(webhook.URL); err != nil {
				return fmt.Errorf("webhook %d has invalid URL: %w", i, err)
			}

			// Check HTTPS requirement
			if config.Security.RequireHTTPS && !strings.HasPrefix(webhook.URL, "https://") {
				return fmt.Errorf("webhook %d must use HTTPS", i)
			}

			if webhook.Method == "" {
				webhook.Method = "POST"
			}

			if webhook.Timeout < time.Second || webhook.Timeout > 5*time.Minute {
				return fmt.Errorf("webhook %d timeout must be between 1 second and 5 minutes", i)
			}

			if webhook.MaxPayloadSize < 1024 || webhook.MaxPayloadSize > 10*1024*1024 {
				return fmt.Errorf("webhook %d max payload size must be between 1KB and 10MB", i)
			}
		}
	}

	return nil
}

// AddTemplate adds a custom notification template
func (n *Notifier) AddTemplate(name, content string) error {
	if name == "" || content == "" {
		return fmt.Errorf("template name and content are required")
	}

	// Create function map
	funcMap := template.FuncMap{
		"upper": strings.ToUpper,
		"lower": strings.ToLower,
		"join":  strings.Join,
		"marshal": func(v interface{}) string {
			data, _ := json.Marshal(v)
			return string(data)
		},
	}

	// Parse template to validate syntax
	_, err := template.New(name).Funcs(funcMap).Parse(content)
	if err != nil {
		return fmt.Errorf("template syntax error: %w", err)
	}

	// Add to templates
	template.Must(n.templates.New(name).Parse(content))

	// Store in config
	n.mu.Lock()
	n.config.Templates.CustomTemplates[name] = content
	n.mu.Unlock()

	logger.Info("notify", "Added custom template", "name", name)
	return nil
}

// RemoveTemplate removes a custom notification template
func (n *Notifier) RemoveTemplate(name string) error {
	n.mu.Lock()
	defer n.mu.Unlock()

	delete(n.config.Templates.CustomTemplates, name)

	// Note: We can't remove from template.Template, but we can remove from config
	logger.Info("notify", "Removed custom template", "name", name)
	return nil
}

// ListTemplates returns a list of available templates
func (n *Notifier) ListTemplates() []string {
	var templates []string

	// Add default templates
	templates = append(templates, "default_email", "default_webhook", "default_slack")

	// Add custom templates
	n.mu.RLock()
	for name := range n.config.Templates.CustomTemplates {
		templates = append(templates, name)
	}
	n.mu.RUnlock()

	sort.Strings(templates)
	return templates
}

// GetChannelHealth returns health status for all notification channels
func (n *Notifier) GetChannelHealth() map[string]bool {
	n.mu.RLock()
	defer n.mu.RUnlock()

	health := make(map[string]bool)

	for name, stats := range n.stats.ChannelStats {
		// Consider healthy if success rate > 80% and last success within 24 hours
		isHealthy := stats.SuccessRate > 80.0 &&
			time.Since(stats.LastSuccess) < 24*time.Hour
		health[name] = isHealthy
	}

	return health
}

// ResetStats resets all notification statistics
func (n *Notifier) ResetStats() {
	n.mu.Lock()
	defer n.mu.Unlock()

	n.stats = &NotificationStats{
		ChannelStats: make(map[string]*ChannelStats),
	}

	logger.Info("notify", "Notification statistics reset")
}

// IsEnabled returns whether notifications are enabled
func (n *Notifier) IsEnabled() bool {
	return n.config.Enabled
}

// GetConfigSummary returns a summary of the current configuration
func (n *Notifier) GetConfigSummary() map[string]interface{} {
	n.mu.RLock()
	defer n.mu.RUnlock()

	summary := map[string]interface{}{
		"enabled":          n.config.Enabled,
		"default_level":    n.config.DefaultLevel,
		"rate_limit":       n.config.RateLimit,
		"max_retries":      n.config.MaxRetries,
		"retry_delay":      n.config.RetryDelay.String(),
		"email_enabled":    n.config.Email != nil && n.config.Email.Enabled,
		"webhook_count":    len(n.config.Webhooks),
		"custom_templates": len(n.config.Templates.CustomTemplates),
	}

	if n.config.Email != nil && n.config.Email.Enabled {
		summary["email_recipients"] = len(n.config.Email.To)
		summary["email_server"] = n.config.Email.SMTPServer
	}

	var enabledWebhooks int
	for _, webhook := range n.config.Webhooks {
		if webhook.Enabled {
			enabledWebhooks++
		}
	}
	summary["enabled_webhooks"] = enabledWebhooks

	return summary
}

// Stop gracefully shuts down the notifier
func (n *Notifier) Stop() error {
	logger.Info("notify", "Stopping notification manager")

	n.cancel()
	n.wg.Wait()

	logger.Info("notify", "Notification manager stopped")
	return nil
}

// Legacy compatibility method for backward compatibility
func (n *Notifier) SendAlert(message string, data map[string]interface{}) {
	// Extract level from message or use default
	level := n.config.DefaultLevel
	if strings.Contains(strings.ToLower(message), "critical") {
		level = AlertLevelCritical
	} else if strings.Contains(strings.ToLower(message), "error") {
		level = AlertLevelError
	} else if strings.Contains(strings.ToLower(message), "warning") {
		level = AlertLevelWarning
	}

	// Send using new interface
	err := n.SendAlertWithDetails(level, message, message, "legacy", data)
	if err != nil {
		logger.Error("notify", "Legacy alert failed", "error", err.Error())
	}
}
// internal/security/bogon.go
package security

import (
	"bufio"
	"context"
	"crypto/sha256"
	"encoding/hex"
	"fmt"
	"io"
	"net"
	"net/http"
	"os"
	"path/filepath"
	"sort"
	"strings"
	"sync"
	"time"

	"qff/internal/config"
	"qff/internal/logger"

	"github.com/google/nftables"
)

const (
	// Default configuration
	DefaultUpdateInterval  = 24 * time.Hour // Daily updates
	DefaultDownloadTimeout = 5 * time.Minute
	DefaultMaxFileSize     = 10 * 1024 * 1024 // 10MB max
	DefaultRetryAttempts   = 3
	DefaultRetryDelay      = 30 * time.Second

	// Set names
	BOGONIPv4Set      = "bogon_ipv4_nets"
	BOGONIPv6Set      = "bogon_ipv6_nets"
	BOGONWhitelistSet = "bogon_whitelist"

	// Cache settings
	DefaultCacheDir = "/var/lib/qff/bogon"
	CacheFileFormat = "bogon_%s_%s.cache"

	// Well-known BOGON list URLs
	TeamCymruIPv4URL = "https://www.team-cymru.org/Services/Bogons/fullbogons-ipv4.txt"
	TeamCymruIPv6URL = "https://www.team-cymru.org/Services/Bogons/fullbogons-ipv6.txt"
	SpamhausIPv4URL  = "https://www.spamhaus.org/drop/drop.txt"
	SpamhausIPv6URL  = "https://www.spamhaus.org/drop/dropv6.txt"
)

// BOGONManager handles BOGON (Bogus IP) filtering using nftables
type BOGONManager struct {
	// Core components
	config *Config
	conn   *nftables.Conn
	table  *nftables.Table

	// State management
	mu        sync.RWMutex
	bogonNets map[string][]net.IPNet // Keyed by source (ipv4/ipv6)
	stats     *BOGONStats

	// HTTP client for downloads
	client *http.Client

	// Lifecycle management
	ctx    context.Context
	cancel context.CancelFunc
	wg     sync.WaitGroup
}

// Config holds BOGON filtering configuration
type Config struct {
	// Enable/disable BOGON filtering
	EnableBogonFilter bool `json:"enable_bogon_filter"`
	EnableIPv6        bool `json:"enable_ipv6"`

	// Update settings
	UpdateInterval  time.Duration `json:"update_interval"`
	DownloadTimeout time.Duration `json:"download_timeout"`
	MaxFileSize     int64         `json:"max_file_size"`
	RetryAttempts   int           `json:"retry_attempts"`
	RetryDelay      time.Duration `json:"retry_delay"`

	// Sources
	IPv4Sources []BOGONSource `json:"ipv4_sources"`
	IPv6Sources []BOGONSource `json:"ipv6_sources"`

	// Cache settings
	EnableCache    bool          `json:"enable_cache"`
	CacheDirectory string        `json:"cache_directory"`
	CacheExpiry    time.Duration `json:"cache_expiry"`

	// Whitelist settings
	WhitelistedNetworks []string `json:"whitelisted_networks"`

	// Action settings
	DefaultAction   string `json:"default_action"` // drop, reject, log
	LogBogonPackets bool   `json:"log_bogon_packets"`
	CounterEnabled  bool   `json:"counter_enabled"`
}

// BOGONSource represents a source for BOGON network lists
type BOGONSource struct {
	Name        string `json:"name"`
	URL         string `json:"url"`
	Enabled     bool   `json:"enabled"`
	Format      string `json:"format"` // cidr, spamhaus, cymru
	Description string `json:"description"`
}

// BOGONStats provides statistics about BOGON filtering
type BOGONStats struct {
	// Network counts
	IPv4Networks        int `json:"ipv4_networks"`
	IPv6Networks        int `json:"ipv6_networks"`
	WhitelistedNetworks int `json:"whitelisted_networks"`

	// Update statistics
	LastUpdate         time.Time     `json:"last_update"`
	LastUpdateDuration time.Duration `json:"last_update_duration"`
	UpdateCount        int64         `json:"update_count"`
	FailedUpdates      int64         `json:"failed_updates"`

	// Traffic statistics (if counters enabled)
	BlockedPackets int64 `json:"blocked_packets"`
	BlockedBytes   int64 `json:"blocked_bytes"`

	// Source statistics
	SourceStats map[string]*SourceStats `json:"source_stats"`
}

// SourceStats tracks statistics for individual BOGON sources
type SourceStats struct {
	Name         string        `json:"name"`
	LastFetch    time.Time     `json:"last_fetch"`
	LastSuccess  time.Time     `json:"last_success"`
	FetchCount   int64         `json:"fetch_count"`
	FailureCount int64         `json:"failure_count"`
	NetworkCount int           `json:"network_count"`
	LastError    string        `json:"last_error,omitempty"`
	ResponseTime time.Duration `json:"response_time"`
	ContentHash  string        `json:"content_hash"`
}

func NewBOGONManager(cfg *config.SecurityConfig, conn *nftables.Conn, table *nftables.Table) *BOGONManager {
	ctx, cancel := context.WithCancel(context.Background())

	// Convert old config to new config format
	newConfig := convertConfig(cfg)

	// Create HTTP client with timeout
	client := &http.Client{
		Timeout: newConfig.DownloadTimeout,
		Transport: &http.Transport{
			MaxIdleConns:       5,
			IdleConnTimeout:    30 * time.Second,
			DisableCompression: false,
			MaxConnsPerHost:    2,
		},
	}

	return &BOGONManager{
		config:    newConfig,
		conn:      conn,
		table:     table,
		bogonNets: make(map[string][]net.IPNet),
		stats:     &BOGONStats{SourceStats: make(map[string]*SourceStats)},
		client:    client,
		ctx:       ctx,
		cancel:    cancel,
	}
}

func convertConfig(oldCfg *config.SecurityConfig) *Config {
	if oldCfg == nil {
		return getDefaultConfig()
	}

	config := &Config{
		EnableBogonFilter:   oldCfg.EnableBogonFilter,
		EnableIPv6:          true,
		UpdateInterval:      getUpdateInterval(oldCfg.BogonUpdateInterval),
		DownloadTimeout:     DefaultDownloadTimeout,
		MaxFileSize:         DefaultMaxFileSize,
		RetryAttempts:       DefaultRetryAttempts,
		RetryDelay:          DefaultRetryDelay,
		EnableCache:         true,
		CacheDirectory:      DefaultCacheDir,
		CacheExpiry:         24 * time.Hour,
		DefaultAction:       "drop",
		LogBogonPackets:     false,
		CounterEnabled:      true,
		WhitelistedNetworks: []string{},
	}

	// Add default sources
	config.IPv4Sources = getDefaultIPv4Sources()
	config.IPv6Sources = getDefaultIPv6Sources()

	// Add custom URL if provided
	if oldCfg.BogonIPv4URL != "" {
		config.IPv4Sources = append(config.IPv4Sources, BOGONSource{
			Name:        "custom_ipv4",
			URL:         oldCfg.BogonIPv4URL,
			Enabled:     true,
			Format:      "cidr",
			Description: "Custom IPv4 BOGON source",
		})
	}

	return config
}

func getDefaultConfig() *Config {
	return &Config{
		EnableBogonFilter:   false,
		EnableIPv6:          true,
		UpdateInterval:      DefaultUpdateInterval,
		DownloadTimeout:     DefaultDownloadTimeout,
		MaxFileSize:         DefaultMaxFileSize,
		RetryAttempts:       DefaultRetryAttempts,
		RetryDelay:          DefaultRetryDelay,
		EnableCache:         true,
		CacheDirectory:      DefaultCacheDir,
		CacheExpiry:         24 * time.Hour,
		DefaultAction:       "drop",
		LogBogonPackets:     false,
		CounterEnabled:      true,
		IPv4Sources:         getDefaultIPv4Sources(),
		IPv6Sources:         getDefaultIPv6Sources(),
		WhitelistedNetworks: []string{},
	}
}

func getUpdateInterval(oldInterval time.Duration) time.Duration {
	if oldInterval > 0 {
		return oldInterval
	}
	return DefaultUpdateInterval
}

func getDefaultIPv4Sources() []BOGONSource {
	return []BOGONSource{
		{
			Name:        "team_cymru_ipv4",
			URL:         TeamCymruIPv4URL,
			Enabled:     true,
			Format:      "cidr",
			Description: "Team Cymru IPv4 BOGON list",
		},
		{
			Name:        "spamhaus_drop",
			URL:         SpamhausIPv4URL,
			Enabled:     true,
			Format:      "spamhaus",
			Description: "Spamhaus DROP list",
		},
	}
}

func getDefaultIPv6Sources() []BOGONSource {
	return []BOGONSource{
		{
			Name:        "team_cymru_ipv6",
			URL:         TeamCymruIPv6URL,
			Enabled:     true,
			Format:      "cidr",
			Description: "Team Cymru IPv6 BOGON list",
		},
		{
			Name:        "spamhaus_dropv6",
			URL:         SpamhausIPv6URL,
			Enabled:     true,
			Format:      "spamhaus",
			Description: "Spamhaus DROPv6 list",
		},
	}
}

func (b *BOGONManager) Initialize() error {
	if !b.config.EnableBogonFilter {
		logger.Info("bogon", "BOGON filtering is disabled")
		return nil
	}

	logger.Info("bogon", "Initializing BOGON filtering",
		"ipv4_sources", len(b.config.IPv4Sources),
		"ipv6_sources", len(b.config.IPv6Sources),
		"cache_enabled", b.config.EnableCache)

	// Create cache directory
	if b.config.EnableCache {
		if err := os.MkdirAll(b.config.CacheDirectory, 0755); err != nil {
			logger.Warn("bogon", "Failed to create cache directory", "error", err.Error())
		}
	}

	// Create nftables sets
	if err := b.createNFTablesSets(); err != nil {
		return fmt.Errorf("failed to create nftables sets: %w", err)
	}

	// Load default BOGON networks first
	if err := b.loadDefaultBogonNetworks(); err != nil {
		logger.Warn("bogon", "Failed to load default BOGON networks", "error", err.Error())
	}

	// Initialize whitelisted networks
	if err := b.initializeWhitelistedNetworks(); err != nil {
		logger.Warn("bogon", "Failed to initialize whitelisted networks", "error", err.Error())
	}

	// Load from cache if available
	if b.config.EnableCache {
		b.loadFromCache()
	}

	// Start periodic updates
	if b.config.UpdateInterval > 0 {
		b.startBogonUpdater()
	}

	// Initial update if no cached data
	if b.shouldPerformInitialUpdate() {
		go b.updateAllSources()
	}

	return nil
}

func (b *BOGONManager) createNFTablesSets() error {
	// Define set configurations
	sets := []struct {
		name     string
		keyType  nftables.SetDatatype
		interval bool
		isIPv6   bool
	}{
		{
			name:     BOGONIPv4Set,
			keyType:  nftables.TypeIPAddr,
			interval: true,
			isIPv6:   false,
		},
		{
			name:     BOGONWhitelistSet,
			keyType:  nftables.TypeIPAddr,
			interval: true,
			isIPv6:   false,
		},
	}

	// Add IPv6 set if enabled
	if b.config.EnableIPv6 {
		sets = append(sets, struct {
			name     string
			keyType  nftables.SetDatatype
			interval bool
			isIPv6   bool
		}{
			name:     BOGONIPv6Set,
			keyType:  nftables.TypeIP6Addr,
			interval: true,
			isIPv6:   true,
		})
	}

	// Create each set
	for _, setCfg := range sets {
		set := &nftables.Set{
			Name:     setCfg.name,
			Table:    b.table,
			KeyType:  setCfg.keyType,
			Interval: setCfg.interval,
		}

		if err := b.conn.AddSet(set, nil); err != nil {
			return fmt.Errorf("failed to create set %s: %w", setCfg.name, err)
		}
	}

	return nil
}

func (b *BOGONManager) loadDefaultBogonNetworks() error {
	// RFC-defined BOGON networks
	defaultBogonsIPv4 := []string{
		"0.0.0.0/8",          // "This network"
		"10.0.0.0/8",         // Private-Use
		"100.64.0.0/10",      // Shared Address Space
		"127.0.0.0/8",        // Loopback
		"169.254.0.0/16",     // Link Local
		"172.16.0.0/12",      // Private-Use
		"192.0.0.0/24",       // IETF Protocol Assignments
		"192.0.2.0/24",       // Documentation (TEST-NET-1)
		"192.168.0.0/16",     // Private-Use
		"198.18.0.0/15",      // Benchmarking
		"198.51.100.0/24",    // Documentation (TEST-NET-2)
		"203.0.113.0/24",     // Documentation (TEST-NET-3)
		"224.0.0.0/4",        // Multicast
		"240.0.0.0/4",        // Reserved for Future Use
		"255.255.255.255/32", // Broadcast
	}

	// Parse and store IPv4 networks
	var ipv4Networks []net.IPNet
	for _, cidr := range defaultBogonsIPv4 {
		_, network, err := net.ParseCIDR(cidr)
		if err != nil {
			logger.Warn("bogon", "Failed to parse default BOGON network", "cidr", cidr, "error", err.Error())
			continue
		}
		ipv4Networks = append(ipv4Networks, *network)
	}

	// Update nftables set
	if err := b.updateNFTablesSet(BOGONIPv4Set, ipv4Networks); err != nil {
		return fmt.Errorf("failed to update IPv4 BOGON set: %w", err)
	}

	b.mu.Lock()
	b.bogonNets["default_ipv4"] = ipv4Networks
	b.stats.IPv4Networks = len(ipv4Networks)
	b.mu.Unlock()

	logger.Info("bogon", "Loaded default IPv4 BOGON networks", "count", len(ipv4Networks))

	// Load IPv6 BOGONs if enabled
	if b.config.EnableIPv6 {
		defaultBogonsIPv6 := []string{
			"::/128",        // Unspecified
			"::1/128",       // Loopback
			"::ffff:0:0/96", // IPv4-mapped
			"64:ff9b::/96",  // IPv4-IPv6 Translation
			"100::/64",      // Discard-Only
			"2001::/23",     // IETF Protocol Assignments
			"2001:db8::/32", // Documentation
			"fc00::/7",      // Unique Local
			"fe80::/10",     // Link Local
			"ff00::/8",      // Multicast
		}

		var ipv6Networks []net.IPNet
		for _, cidr := range defaultBogonsIPv6 {
			_, network, err := net.ParseCIDR(cidr)
			if err != nil {
				logger.Warn("bogon", "Failed to parse default IPv6 BOGON network", "cidr", cidr, "error", err.Error())
				continue
			}
			ipv6Networks = append(ipv6Networks, *network)
		}

		if err := b.updateNFTablesSet(BOGONIPv6Set, ipv6Networks); err != nil {
			return fmt.Errorf("failed to update IPv6 BOGON set: %w", err)
		}

		b.mu.Lock()
		b.bogonNets["default_ipv6"] = ipv6Networks
		b.stats.IPv6Networks = len(ipv6Networks)
		b.mu.Unlock()

		logger.Info("bogon", "Loaded default IPv6 BOGON networks", "count", len(ipv6Networks))
	}

	return nil
}

func (b *BOGONManager) initializeWhitelistedNetworks() error {
	if len(b.config.WhitelistedNetworks) == 0 {
		return nil
	}

	var networks []net.IPNet
	for _, networkStr := range b.config.WhitelistedNetworks {
		_, network, err := net.ParseCIDR(networkStr)
		if err != nil {
			ip := net.ParseIP(networkStr)
			if ip == nil {
				logger.Warn("bogon", "Invalid whitelisted network", "network", networkStr)
				continue
			}
			// Convert single IP to /32 or /128 network
			if ip.To4() != nil {
				_, network, _ = net.ParseCIDR(networkStr + "/32")
			} else {
				_, network, _ = net.ParseCIDR(networkStr + "/128")
			}
		}
		networks = append(networks, *network)
	}

	if len(networks) > 0 {
		if err := b.updateNFTablesSet(BOGONWhitelistSet, networks); err != nil {
			return fmt.Errorf("failed to update whitelist set: %w", err)
		}

		b.mu.Lock()
		b.stats.WhitelistedNetworks = len(networks)
		b.mu.Unlock()

		logger.Info("bogon", "Initialized whitelisted networks", "count", len(networks))
	}

	return nil
}

func (b *BOGONManager) shouldPerformInitialUpdate() bool {
	b.mu.RLock()
	defer b.mu.RUnlock()

	// Perform initial update if we have no external BOGON data
	for sourceName := range b.stats.SourceStats {
		if sourceName != "default_ipv4" && sourceName != "default_ipv6" {
			return false // We have external data
		}
	}

	return true
}

func (b *BOGONManager) startBogonUpdater() {
	b.wg.Add(1)
	go func() {
		defer b.wg.Done()

		ticker := time.NewTicker(b.config.UpdateInterval)
		defer ticker.Stop()

		for {
			select {
			case <-ticker.C:
				b.updateAllSources()
			case <-b.ctx.Done():
				return
			}
		}
	}()
}

func (b *BOGONManager) updateAllSources() {
	startTime := time.Now()
	logger.Info("bogon", "Starting BOGON list update")

	var wg sync.WaitGroup

	// Update IPv4 sources
	for _, source := range b.config.IPv4Sources {
		if !source.Enabled {
			continue
		}

		wg.Add(1)
		go func(src BOGONSource) {
			defer wg.Done()
			b.updateSource(src, "ipv4")
		}(source)
	}

	// Update IPv6 sources if enabled
	if b.config.EnableIPv6 {
		for _, source := range b.config.IPv6Sources {
			if !source.Enabled {
				continue
			}

			wg.Add(1)
			go func(src BOGONSource) {
				defer wg.Done()
				b.updateSource(src, "ipv6")
			}(source)
		}
	}

	wg.Wait()

	duration := time.Since(startTime)

	b.mu.Lock()
	b.stats.LastUpdate = time.Now()
	b.stats.LastUpdateDuration = duration
	b.stats.UpdateCount++
	b.mu.Unlock()

	logger.Info("bogon", "BOGON list update completed", "duration", duration)
}

// calculateNetworksHash generates a consistent hash of the network list
func (b *BOGONManager) calculateNetworksHash(networks []net.IPNet) string {
	// Create a hash writer
	h := sha256.New()

	// Write each network to the hash in a consistent format
	for _, network := range networks {
		// Write both IP and mask to catch any changes
		h.Write(network.IP)
		h.Write(network.Mask)
	}

	// Return the hex-encoded hash
	return hex.EncodeToString(h.Sum(nil))
}

func (b *BOGONManager) updateSource(source BOGONSource, ipVersion string) {
	startTime := time.Now()

	b.mu.Lock()
	stats := b.stats.SourceStats[source.Name]
	if stats == nil {
		stats = &SourceStats{Name: source.Name}
		b.stats.SourceStats[source.Name] = stats
	}
	stats.FetchCount++
	stats.LastFetch = startTime
	b.mu.Unlock()

	networks, err := b.downloadAndParseBogonList(source)
	responseTime := time.Since(startTime)

	if err != nil {
		b.mu.Lock()
		stats.FailureCount++
		stats.LastError = err.Error()
		stats.ResponseTime = responseTime
		b.mu.Unlock()

		logger.Error("bogon", "Failed to update BOGON source",
			"source", source.Name, "error", err.Error())
		return
	}

	// Calculate content hash
	hash := b.calculateNetworksHash(networks)

	// Check if content changed
	b.mu.RLock()
	existingHash := stats.ContentHash
	b.mu.RUnlock()

	if hash == existingHash && existingHash != "" {
		logger.Info("bogon", "BOGON source unchanged", "source", source.Name)
		return
	}

	// Update nftables set
	setName := BOGONIPv4Set
	if ipVersion == "ipv6" {
		setName = BOGONIPv6Set
	}

	if err := b.updateNFTablesSet(setName, networks); err != nil {
		b.mu.Lock()
		stats.FailureCount++
		stats.LastError = fmt.Sprintf("nftables update failed: %v", err)
		b.mu.Unlock()

		logger.Error("bogon", "Failed to update nftables set",
			"source", source.Name, "error", err.Error())
		return
	}

	// Update statistics
	b.mu.Lock()
	stats.LastSuccess = time.Now()
	stats.NetworkCount = len(networks)
	stats.LastError = ""
	stats.ResponseTime = responseTime
	stats.ContentHash = hash

	// Store in memory
	b.bogonNets[source.Name] = networks

	// Update global counts
	if ipVersion == "ipv4" {
		totalIPv4 := 0
		for key, nets := range b.bogonNets {
			if strings.Contains(key, "ipv4") || key == "default_ipv4" || (!strings.Contains(key, "ipv6") && !strings.Contains(key, "default")) {
				totalIPv4 += len(nets)
			}
		}
		b.stats.IPv4Networks = totalIPv4
	} else {
		totalIPv6 := 0
		for key, nets := range b.bogonNets {
			if strings.Contains(key, "ipv6") || key == "default_ipv6" {
				totalIPv6 += len(nets)
			}
		}
		b.stats.IPv6Networks = totalIPv6
	}
	b.mu.Unlock()

	// Cache if enabled
	if b.config.EnableCache {
		b.saveToCache(source.Name, networks, hash)
	}

	logger.Info("bogon", "Updated BOGON source",
		"source", source.Name,
		"networks", len(networks),
		"response_time", responseTime)
}

// loadFromCacheSource loads networks for a specific source from cache
func (b *BOGONManager) loadFromCacheSource(sourceName string) ([]net.IPNet, error) {
	cacheFile := b.getCacheFilePath(sourceName)
	data, err := os.ReadFile(cacheFile)
	if err != nil {
		return nil, fmt.Errorf("failed to read cache file: %w", err)
	}

	var networks []net.IPNet
	for _, line := range strings.Split(string(data), "\n") {
		line = strings.TrimSpace(line)
		if line == "" {
			continue
		}
		_, network, err := net.ParseCIDR(line)
		if err != nil {
			continue // skip invalid entries
		}
		networks = append(networks, *network)
	}

	return networks, nil
}

// getCacheFilePath returns the full path to a cache file for a source
func (b *BOGONManager) getCacheFilePath(sourceName string) string {
	hash := sha256.Sum256([]byte(sourceName))
	hashStr := hex.EncodeToString(hash[:])
	return filepath.Join(b.config.CacheDirectory, fmt.Sprintf(CacheFileFormat, sourceName, hashStr[:8]))
}

// saveToCache saves networks for a source to cache
func (b *BOGONManager) saveToCache(sourceName string, networks []net.IPNet, hash string) {
	cacheFile := b.getCacheFilePath(sourceName)

	var builder strings.Builder
	for _, network := range networks {
		builder.WriteString(network.String())
		builder.WriteString("\n")
	}

	if err := os.WriteFile(cacheFile, []byte(builder.String()), 0644); err != nil {
		logger.Warn("bogon", "Failed to save cache", "source", sourceName, "error", err.Error())
	}
}

// loadFromCache loads all cached data (called during initialization)
func (b *BOGONManager) loadFromCache() {
	if !b.config.EnableCache {
		return
	}

	// Load cached IPv4 sources
	for _, source := range b.config.IPv4Sources {
		if !source.Enabled {
			continue
		}
		if networks, err := b.loadFromCacheSource(source.Name); err == nil {
			b.bogonNets[source.Name] = networks
			if stats := b.stats.SourceStats[source.Name]; stats != nil {
				stats.NetworkCount = len(networks)
			}
		}
	}

	// Load cached IPv6 sources if enabled
	if b.config.EnableIPv6 {
		for _, source := range b.config.IPv6Sources {
			if !source.Enabled {
				continue
			}
			if networks, err := b.loadFromCacheSource(source.Name); err == nil {
				b.bogonNets[source.Name] = networks
				if stats := b.stats.SourceStats[source.Name]; stats != nil {
					stats.NetworkCount = len(networks)
				}
			}
		}
	}
}

func (b *BOGONManager) downloadAndParseBogonList(source BOGONSource) ([]net.IPNet, error) {
	// Check cache first
	if b.config.EnableCache {
		if networks, err := b.loadFromCacheSource(source.Name); err == nil {
			return networks, nil
		}
	}

	// Download with retries
	var lastErr error
	for attempt := 1; attempt <= b.config.RetryAttempts; attempt++ {
		networks, err := b.downloadBogonList(source)
		if err == nil {
			return networks, nil
		}

		lastErr = err
		if attempt < b.config.RetryAttempts {
			logger.Warn("bogon", "Download attempt failed, retrying",
				"source", source.Name, "attempt", attempt, "error", err.Error())

			select {
			case <-time.After(b.config.RetryDelay):
			case <-b.ctx.Done():
				return nil, b.ctx.Err()
			}
		}
	}

	return nil, fmt.Errorf("failed after %d attempts: %w", b.config.RetryAttempts, lastErr)
}

func (b *BOGONManager) downloadBogonList(source BOGONSource) ([]net.IPNet, error) {
	ctx, cancel := context.WithTimeout(b.ctx, b.config.DownloadTimeout)
	defer cancel()

	req, err := http.NewRequestWithContext(ctx, "GET", source.URL, nil)
	if err != nil {
		return nil, fmt.Errorf("failed to create request: %w", err)
	}

	req.Header.Set("User-Agent", "QFF-BOGON-Manager/1.0")

	resp, err := b.client.Do(req)
	if err != nil {
		return nil, fmt.Errorf("failed to download: %w", err)
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return nil, fmt.Errorf("HTTP %d: %s", resp.StatusCode, resp.Status)
	}

	// Limit response size
	limitedReader := io.LimitReader(resp.Body, b.config.MaxFileSize)

	return b.parseBogonList(limitedReader, source.Format)
}

func (b *BOGONManager) parseBogonList(reader io.Reader, format string) ([]net.IPNet, error) {
	scanner := bufio.NewScanner(reader)
	var networks []net.IPNet

	for scanner.Scan() {
		line := strings.TrimSpace(scanner.Text())
		if line == "" || strings.HasPrefix(line, "#") || strings.HasPrefix(line, ";") {
			continue
		}

		// Parse based on format
		var cidr string
		switch format {
		case "spamhaus":
			// Spamhaus format: "1.2.3.0/24 ; SBL12345"
			parts := strings.Split(line, " ")
			if len(parts) > 0 {
				cidr = parts[0]
			}
		case "cymru", "cidr":
			// Simple CIDR format
			cidr = line
		default:
			cidr = line
		}

		if cidr == "" {
			continue
		}

		_, network, err := net.ParseCIDR(cidr)
		if err != nil {
			// Try parsing as single IP
			ip := net.ParseIP(cidr)
			if ip == nil {
				continue
			}
			// Convert to CIDR
			if ip.To4() != nil {
				_, network, _ = net.ParseCIDR(cidr + "/32")
			} else {
				_, network, _ = net.ParseCIDR(cidr + "/128")
			}
		}

		if network != nil {
			networks = append(networks, *network)
		}
	}

	if err := scanner.Err(); err != nil {
		return nil, fmt.Errorf("failed to scan input: %w", err)
	}

	// Sort networks for consistent ordering
	sort.Slice(networks, func(i, j int) bool {
		return networks[i].String() < networks[j].String()
	})

	return networks, nil
}

// getNetworkEnd calculates the last IP address in a network
func (b *BOGONManager) getNetworkEnd(network *net.IPNet) net.IP {
	// For IPv4 networks
	if ipv4 := network.IP.To4(); ipv4 != nil {
		end := make(net.IP, len(ipv4))
		copy(end, ipv4)
		for i := range end {
			end[i] |= ^network.Mask[i]
		}
		return end
	}

	// For IPv6 networks
	end := make(net.IP, len(network.IP))
	copy(end, network.IP)
	for i := range end {
		end[i] |= ^network.Mask[i]
	}
	return end
}

func (b *BOGONManager) updateNFTablesSet(setName string, networks []net.IPNet) error {
	set := &nftables.Set{Name: setName, Table: b.table}

	// Clear existing elements
	b.conn.FlushSet(set)

	if len(networks) == 0 {
		return nil
	}

	// Convert networks to set elements
	elements := make([]nftables.SetElement, 0, len(networks))
	for _, network := range networks {
		// For interval sets, we need to specify both start and end
		elements = append(elements, nftables.SetElement{
			Key:         network.IP,
			KeyEnd:      b.getNetworkEnd(&network),
			IntervalEnd: false,
		})
	}

	// Add elements in batches to avoid overwhelming nftables
	batchSize := 1000
	for i := 0; i < len(elements); i += batchSize {
		end := i + batchSize
		if end > len(elements) {
			end = len(elements)
		}

		batch := elements[i:end]
		b.conn.SetAddElements(set, batch)
	}

	// Flush changes
	if err := b.conn.Flush(); err != nil {
		return fmt.Errorf("failed to flush nftables changes: %w", err)
	}

	return nil
}
# QFF - qFibre Firewall Manager Configuration
# Complete configuration file with all available options

# ==============================================================================
# CONFIGURATION NOTES:
# ==============================================================================
#
# Time Duration Formats:
# - Use Go duration format: 1h, 30m, 45s, 1h30m, etc.
# - Examples: 5m (5 minutes), 1h (1 hour), 24h (24 hours)
#
# IP Address Formats:
# - Single IPs: 192.168.1.100
# - CIDR ranges: 192.168.1.0/24, 10.0.0.0/8
# - Multiple entries: comma-separated
#
# Log File Paths:
# - Absolute paths required
# - Wildcards supported in some contexts: /var/log/nginx/*/access.log
# - Multiple files: comma-separated
#
# Service Rules (when enable_per_service_rules=true):
# - SSH service: Controls SSH access
# - Web service: Controls HTTP/HTTPS access  
# - cPanel service: Controls cPanel/WHM access
# - DirectAdmin service: Controls DirectAdmin access
# - Mail service: Controls mail server access
# - FTP service: Controls FTP access
#
# Country Codes:
# - Use ISO 3166-1 alpha-2 codes (US, CA, GB, DE, FR, etc.)
# - Common blocked countries: CN, RU, KP, IR, PK, BD
#
# Default Ports Reference:
# - SSH: 22
# - HTTP: 80
# - HTTPS: 443
# - DNS: 53 (TCP/UDP)
# - NTP: 123 (UDP)
# - SMTP: 25, 587, 465
# - POP3: 110, 995
# - IMAP: 143, 993
# - FTP: 21
# - Telnet: 23 (better to be blocked)
# - RDP: 3389 (should be blocked on public interfaces)
#
# Security Recommendations:
# - Keep default_policy=drop for maximum security
# - Enable IPS with appropriate thresholds
# - Configure email/webhook notifications
# - Use test mode when making significant changes
# - Regularly update GeoIP databases
# - Monitor logs and adjust thresholds as needed
# - Keep whitelist updated with trusted IPs
#
# ==============================================================================

[firewall]
# Basic firewall settings
default_policy=drop
enable_ipv6=true

# IP Lists (comma-separated)
whitelist=127.0.0.1,10.0.0.0/8,192.168.1.0/24
blacklist=

# Port configuration
allowed_ports=22,80,443,53,123,993,995,465,587
blocked_ports=23,135,139,445,1433,3389,137,138,161,1434

[server]
# HTTP API Server settings
address=localhost
port=8080
read_timeout=10s
enable_api=true

[ips]
# Intrusion Prevention System
enabled=true
log_check_interval=30s
block_duration=1h
failure_threshold=5
time_window=5m

# Log files to monitor (comma-separated)
log_files=/var/log/auth.log,/var/log/secure,/var/log/apache2/access.log,/var/log/nginx/access.log

# GeoIP blocking
enable_geo_blocking=false
blocked_countries=CN,RU,KP,IR

# cPanel specific settings
cpanel_failed_logins=3
cpanel_time_window=5m
cpanel_log_files=/usr/local/cpanel/logs/login_log,/usr/local/cpanel/logs/access_log

# DirectAdmin specific settings
directadmin_failed_logins=3
directadmin_time_window=5m
directadmin_log_files=/var/log/directadmin/security.log,/var/log/directadmin/login.log

# WordPress specific settings
wordpress_failed_logins=5
wordpress_time_window=5m

# Apache/Nginx log monitoring
apache_log_files=/var/log/apache2/access.log,/var/log/httpd/access_log,/home/*/logs/access.log
nginx_log_files=/var/log/nginx/access.log,/var/log/nginx/*/access.log

# Mail server monitoring
mail_log_files=/var/log/mail.log,/var/log/maillog,/var/log/postfix.log

# FTP server monitoring
ftp_log_files=/var/log/vsftpd.log,/var/log/proftpd/proftpd.log

# System auth logs
auth_log_files=/var/log/auth.log,/var/log/secure

# Advanced IPS features
enable_block_notifications=true
notify_cpanel_blocks=true
notify_web_blocks=true
notification_cooldown=5m

# Auto-whitelist SSH sessions to prevent lockout
auto_whitelist_ssh_sessions=true
ssh_whitelist_duration=24h

# Permanent block threshold (after X temp blocks, make permanent)
perm_block_threshold=3

# Port scan detection
enable_port_scan_detection=true
port_scan_threshold=10
port_scan_time_window=1m

# File system monitoring
enable_filesystem_monitor=true
critical_files=/etc/passwd,/etc/shadow,/etc/sudoers,/etc/hosts,/etc/ssh/sshd_config,/etc/crontab,/root/.ssh/authorized_keys
critical_directories=/bin,/sbin,/usr/bin,/usr/sbin
file_check_interval=5m

# Process monitoring
enable_process_monitor=true
suspicious_process_patterns=perl /tmp/.*\.pl,php.*mailer,wget http.*\.php,curl.*\.sh,python.*backdoor,nc -l.*,/tmp/.*\.py,bash.*reverse,sh.*shell,.*\.php.*system
max_process_memory=1GB
process_check_interval=1m

# External blocklists
enable_external_blocklists=true
spamhaus_enabled=true
dshield_enabled=true
blocklist_update_interval=24h

[monitor]
# System resource monitoring
enabled=true
check_interval=30s

# CPU monitoring
cpu_threshold=80.0
cpu_duration=5m

# Memory monitoring
mem_threshold=80.0

# Disk monitoring
disk_threshold=85.0

[geoip]
# GeoIP database configuration
mmdb_path=/etc/qff/GeoLite2-Country.mmdb
country_block_file=/etc/qff/countries.block
country_allow_file=/etc/qff/countries.allow
maxmind_api_key=YOUR_MAXMIND_LICENSE_KEY
auto_download=false

# Enhanced GeoIP features
enable_per_service_rules=false
enable_vpn_detection=false
vpn_detection_api=ipqualityscore
vpn_api_key=
vpn_blocklists=https://raw.githubusercontent.com/X4BNet/lists_vpn/main/ipv4.txt,https://raw.githubusercontent.com/platformbuilds/Tor-IP-Addresses/refs/heads/master/tor-exit-nodes.lst
cache_vpn_results=true
cache_expiration=24h

# Service-specific GeoIP rules (requires enable_per_service_rules=true)
# Format: service_name_allowed_countries or service_name_blocked_countries
ssh_allowed_countries=US,CA,GB,DE,FR,AU,JP
ssh_blocked_countries=
ssh_block_vpns=true
ssh_block_proxies=true

web_allowed_countries=
web_blocked_countries=CN,RU,KP,IR
web_block_vpns=false
web_block_proxies=false

cpanel_allowed_countries=US,CA,GB
cpanel_blocked_countries=
cpanel_block_vpns=true
cpanel_block_proxies=true

[dns]
# Dynamic DNS support
enable_dynamic_dns=false
hostnames=
update_interval=5m

[ratelimit]
# Connection rate limiting
enable_rate_limit=false
global_conn_limit=100
global_conn_window=1m
port_specific_limits=22:5/1m:tcp,80:50/1m:tcp,443:50/1m:tcp

[synflood]
# SYN flood protection
enable_protection=false
syn_rate_limit=10
syn_burst=5
conntrack_max=100

[security]
# Enhanced security features
enable_bogon_filter=false
enable_martian_filter=false
bogon_update_interval=24h
bogon_ipv4_url=https://www.team-cymru.org/Services/Bogons/fullbogons-ipv4.txt
bogon_ipv6_url=https://www.team-cymru.org/Services/Bogons/fullbogons-ipv6.txt

[notification]
# Email notifications
enable_email=false
email_server=smtp.gmail.com
email_port=587
email_user=your-email@gmail.com
email_password=your-app-password
email_to=admin@yourdomain.com

# Webhook notifications (Slack, Discord, etc.)
enable_webhooks=false
webhook_urls=https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK
webhook_timeout=10

[testmode]
# Safe testing mode - automatically reverts changes if connectivity is lost
enable_test_mode=false
test_duration=5m
revert_on_failure=true
test_connections=8.8.8.8,1.1.1.1,google.com

[ports]
# Detailed port configuration (legacy format for compatibility)
tcp_in=22,80,443
tcp_out=53,80,443,993,995,465,587
udp_in=53,123
udp_out=53,123

# Explicitly denied ports
tcp_deny=23,135,139,445,1433,3389
udp_deny=137,138,161,1434
[Unit]
Description=QFF - qFibre Firewall
Documentation=https://github.com/qfiber/qff
After=network-online.target
Wants=network-online.target
Requires=network-online.target
AssertPathExists=/etc/qff/qff.conf

[Service]
Type=simple
User=root
Group=root
ExecStart=/usr/local/bin/qff -config /etc/qff/qff.conf
ExecReload=/bin/kill -HUP $MAINPID
ExecStop=/bin/kill -TERM $MAINPID
Restart=on-failure
RestartSec=10s
StartLimitIntervalSec=60s
StartLimitBurst=3

# Logging
StandardOutput=journal
StandardError=journal
SyslogIdentifier=qff
SyslogFacility=local0
LogLevelMax=info

# Security Hardening
CapabilityBoundingSet=CAP_NET_ADMIN CAP_NET_RAW CAP_NET_BIND_SERVICE CAP_SYS_MODULE CAP_SYS_ADMIN
AmbientCapabilities=CAP_NET_ADMIN CAP_NET_RAW  # Pass caps to child processes
NoNewPrivileges=true
ProtectSystem=strict
ProtectHome=read-only
PrivateTmp=true
PrivateDevices=false
RestrictAddressFamilies=AF_UNIX AF_INET AF_INET6 AF_NETLINK AF_PACKET
RestrictNamespaces=false
MemoryDenyWriteExecute=true
LockPersonality=true
SystemCallFilter=@system-service @privileged
SystemCallArchitectures=native

# Resource Limits
LimitNOFILE=16384
LimitMEMLOCK=infinity

[Install]
WantedBy=multi-user.target